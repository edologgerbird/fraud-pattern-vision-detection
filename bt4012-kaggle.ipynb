{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT4012 Kaggle Competition\n",
    "\n",
    "Author: Loh Hong Tak Edmund\n",
    "\n",
    "Python Version: 3.8.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plan:\n",
    "\n",
    "- EDA\n",
    "- Train-Test Split\n",
    "- Oversampling \n",
    "    - SMOTE-EN\n",
    "    - ADASYN\n",
    "    - BorderlineSMOTE\n",
    "    - SVMSMOTE\n",
    "- Neural Networks\n",
    "    - Vanila NN\n",
    "    - CNN (3 layer)\n",
    "    - CNN (5 layer)\n",
    "- Ensemble Methods\n",
    "    - XGBoost\n",
    "    - RandomForest\n",
    "    - Logistic Regression\n",
    "    - MNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.4.2-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\edmun\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\edmun\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Packages\n",
    "\n",
    "# EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, log_loss, roc_auc_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Settings\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRFEfeatures(model, x, y, n_features_to_select):\n",
    "    rfe = RFE(model, n_features_to_select)\n",
    "    rfe = rfe.fit(x,y)\n",
    "    selected_features = list(x.columns[rfe.support_])\n",
    "    print('Selected features: %s' % selected_features)\n",
    "    return selected_features\n",
    "\n",
    "def get_auc(model, x, y):\n",
    "    y_pred_proba = model.predict_proba(x)[:,1]\n",
    "    [fpr, tpr, thr] = roc_curve(y, y_pred_proba)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "def get_logloss(model, x, y):\n",
    "    y_pred_proba = model.predict_proba(x)[:,1]\n",
    "    return log_loss(y, y_pred_proba)\n",
    "\n",
    "def print_train_score(model, x_train, y_train, auc=True):\n",
    "    pred = model.predict(x_train)\n",
    "    model_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "    print(\"TRAIN RESULT:\\n================================================\")\n",
    "    print(f\"ACCURACY SCORE: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{model_report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CONFUSION MATRIX: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "    if auc:\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"AUC Score: \\n {get_auc(model, x_train, y_train)}\\n\")\n",
    "    \n",
    "def print_test_score(model, x_test, y_test, auc=True):\n",
    "    pred = model.predict(x_test)\n",
    "    model_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "    print(\"TEST RESULT:\\n================================================\")\n",
    "    print(f\"ACCURACY SCORE: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{model_report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CONFUSION MATRIX: \\n {confusion_matrix(y_test, pred)}\\n\")\n",
    "    if auc:\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"AUC Score: \\n {get_auc(model, x_test, y_test)}\\n\")\n",
    "\n",
    "def predict_to_csv(model,ds,name):\n",
    "    pred = model.predict(ds)\n",
    "    pred_df = pd.DataFrame({'Id':Id, 'Predicted':pred}, columns=['Id', 'Predicted'])\n",
    "    pred_df.to_csv('%s.csv'%(name), index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('train.csv')\n",
    "ds = ds.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0c0</th>\n",
       "      <th>r0c1</th>\n",
       "      <th>r0c2</th>\n",
       "      <th>r0c3</th>\n",
       "      <th>r0c4</th>\n",
       "      <th>r0c5</th>\n",
       "      <th>r0c6</th>\n",
       "      <th>r0c7</th>\n",
       "      <th>r0c8</th>\n",
       "      <th>r0c9</th>\n",
       "      <th>...</th>\n",
       "      <th>r19c11</th>\n",
       "      <th>r19c12</th>\n",
       "      <th>r19c13</th>\n",
       "      <th>r19c14</th>\n",
       "      <th>r19c15</th>\n",
       "      <th>r19c16</th>\n",
       "      <th>r19c17</th>\n",
       "      <th>r19c18</th>\n",
       "      <th>r19c19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>52</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>141</td>\n",
       "      <td>172</td>\n",
       "      <td>197</td>\n",
       "      <td>223</td>\n",
       "      <td>233</td>\n",
       "      <td>246</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>169</td>\n",
       "      <td>147</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0c0  r0c1  r0c2  r0c3  r0c4  r0c5  r0c6  r0c7  r0c8  r0c9  ...  r19c11  \\\n",
       "0     1     1     1     1    28    43    52   255   255   255  ...     191   \n",
       "1     1     1     1     1     1     1     1     1     1     1  ...       1   \n",
       "2     1     1   128   255   255   255   255   255   255   255  ...     255   \n",
       "3    53    54    61    91   141   172   197   223   233   246  ...     184   \n",
       "4    46    46    46    46    36    36    41    41    41    41  ...      38   \n",
       "\n",
       "   r19c12  r19c13  r19c14  r19c15  r19c16  r19c17  r19c18  r19c19  label  \n",
       "0     255      52      34       1       1       1       1       1      0  \n",
       "1       1       1       1       1       1       1       1       1      0  \n",
       "2     255     255     255     255     255     128       1       1      0  \n",
       "3     185     187     169     147     106      82      34      23      1  \n",
       "4      65      65      95      95     149     149     205     205      0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "72134    0\n",
       "72135    0\n",
       "72136    0\n",
       "72137    0\n",
       "72138    0\n",
       "Name: label, Length: 71967, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 65581, 1: 6558})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter\n",
    "counter(ds.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0c0</th>\n",
       "      <th>r0c1</th>\n",
       "      <th>r0c2</th>\n",
       "      <th>r0c3</th>\n",
       "      <th>r0c4</th>\n",
       "      <th>r0c5</th>\n",
       "      <th>r0c6</th>\n",
       "      <th>r0c7</th>\n",
       "      <th>r0c8</th>\n",
       "      <th>r0c9</th>\n",
       "      <th>...</th>\n",
       "      <th>r19c11</th>\n",
       "      <th>r19c12</th>\n",
       "      <th>r19c13</th>\n",
       "      <th>r19c14</th>\n",
       "      <th>r19c15</th>\n",
       "      <th>r19c16</th>\n",
       "      <th>r19c17</th>\n",
       "      <th>r19c18</th>\n",
       "      <th>r19c19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.125383</td>\n",
       "      <td>51.473308</td>\n",
       "      <td>70.855279</td>\n",
       "      <td>82.032354</td>\n",
       "      <td>86.869142</td>\n",
       "      <td>96.391730</td>\n",
       "      <td>101.608728</td>\n",
       "      <td>108.712333</td>\n",
       "      <td>115.257752</td>\n",
       "      <td>119.014680</td>\n",
       "      <td>...</td>\n",
       "      <td>105.187416</td>\n",
       "      <td>101.996327</td>\n",
       "      <td>98.175689</td>\n",
       "      <td>94.994663</td>\n",
       "      <td>83.791611</td>\n",
       "      <td>79.024744</td>\n",
       "      <td>67.467084</td>\n",
       "      <td>49.497775</td>\n",
       "      <td>37.186349</td>\n",
       "      <td>0.090908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.769428</td>\n",
       "      <td>83.545299</td>\n",
       "      <td>93.468985</td>\n",
       "      <td>99.787787</td>\n",
       "      <td>100.295541</td>\n",
       "      <td>103.128587</td>\n",
       "      <td>104.129642</td>\n",
       "      <td>103.806258</td>\n",
       "      <td>106.480366</td>\n",
       "      <td>107.572306</td>\n",
       "      <td>...</td>\n",
       "      <td>106.387324</td>\n",
       "      <td>102.402083</td>\n",
       "      <td>103.242319</td>\n",
       "      <td>102.317456</td>\n",
       "      <td>98.440790</td>\n",
       "      <td>97.781003</td>\n",
       "      <td>90.884177</td>\n",
       "      <td>82.706445</td>\n",
       "      <td>72.454911</td>\n",
       "      <td>0.287480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               r0c0          r0c1          r0c2          r0c3          r0c4  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      36.125383     51.473308     70.855279     82.032354     86.869142   \n",
       "std       70.769428     83.545299     93.468985     99.787787    100.295541   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000      2.000000     18.000000     33.000000   \n",
       "75%       30.000000     80.000000    128.000000    171.000000    181.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "               r0c5          r0c6          r0c7          r0c8          r0c9  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      96.391730    101.608728    108.712333    115.257752    119.014680   \n",
       "std      103.128587    104.129642    103.806258    106.480366    107.572306   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%       52.000000     67.000000     91.000000     96.000000    104.000000   \n",
       "75%      208.000000    219.000000    226.000000    248.000000    255.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "       ...        r19c11        r19c12        r19c13        r19c14  \\\n",
       "count  ...  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean   ...    105.187416    101.996327     98.175689     94.994663   \n",
       "std    ...    106.387324    102.402083    103.242319    102.317456   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "50%    ...     69.000000     73.000000     60.000000     52.000000   \n",
       "75%    ...    236.000000    213.000000    207.000000    199.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "             r19c15        r19c16        r19c17        r19c18        r19c19  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      83.791611     79.024744     67.467084     49.497775     37.186349   \n",
       "std       98.440790     97.781003     90.884177     82.706445     72.454911   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%       26.000000      7.000000      1.000000      1.000000      1.000000   \n",
       "75%      172.000000    163.000000    128.000000     73.000000     24.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "              label  \n",
       "count  72139.000000  \n",
       "mean       0.090908  \n",
       "std        0.287480  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 401 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('label', axis=1)\n",
    "y = ds.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size=0.10,random_state=42)\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255\n",
    "x_test= x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13070, 1: 1324})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "x_train_smenn, y_train_smenn = SMOTEENN().fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "x_train_tomek, y_train_tomek = SMOTETomek().fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "x_train_adasyn, y_train_adasyn = ADASYN().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "x_train_borderline, y_train_borderline = BorderlineSMOTE().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "x_train_svmsmote, y_train_svmsmote = SVMSMOTE().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "x_train_oversam, y_train_oversam = RandomOverSampler(random_state=42).fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 47196, 1: 47196})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mat(X):\n",
    "    X_mat = []\n",
    "    for i in range(X.shape[0]):\n",
    "        X_mat.append(np.reshape(X.iloc[i].tolist(), (20,20)).T)\n",
    "    X_mat_arr = np.array(X_mat)\n",
    "    X_mat_arr_ex = X_mat_arr[:,:,:,None]\n",
    "    return X_mat_arr_ex\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    r = reshape_mat(image_batch)\n",
    "    for n in range(100):\n",
    "        ax = plt.subplot(10,10,n+1)\n",
    "        plt.imshow(r[n])\n",
    "        plt.title(str(label_batch[n]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_batch(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "def model_score(model, x, y):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'AUC', 'Recall', 'Precision']\n",
    "    )\n",
    "\n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "                EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=12, restore_best_weights=True)]\n",
    "    \n",
    "    print(\"\\n MODEL BUILDING ============================================================================ \\n\")\n",
    "\n",
    "    history = model.fit(\n",
    "        x, y, \n",
    "        epochs=128, \n",
    "        batch_size = 32, \n",
    "        validation_data=(x_val,y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    print(\"\\n MODEL EVALUATION ON TEST SET ============================================================================ \\n\")\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "    return [model, history, score]\n",
    "\n",
    "\n",
    "def pred_test_to_csv(model, name):\n",
    "    test_ds = pd.read_csv(\"test.csv\")\n",
    "    Id = test_ds['Id'][:]\n",
    "    test_ds = test_ds.drop(\"Id\", axis=1)\n",
    "    test_ds = test_ds/255\n",
    "    pred = model.predict(test_ds)\n",
    "    pred_df = pd.DataFrame({'Id':Id.values, 'Predicted':pred.flatten()}, columns=['Id', 'Predicted'])\n",
    "    print(pred_df)\n",
    "    pred_df.to_csv(f'{name}.csv', index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters, (3, 3), activation = 'relu', padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        tf.keras.layers.Conv2D(filters, (3, 3), activation = 'relu', padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
    "    ])\n",
    "    return block\n",
    "\n",
    "def conv_layer(filters):\n",
    "    return tf.keras.Sequential([layers.Conv2D(filters, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same')])\n",
    "\n",
    "def pool_layer(size):\n",
    "    return tf.keras.Sequential([layers.MaxPooling2D(pool_size=(size, size), strides=(2, 2), padding='same')])\n",
    "\n",
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (4-layers) with SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2888/2888 [==============================] - 93s 32ms/step - loss: 0.2734 - accuracy: 0.8899 - auc: 0.9593 - recall: 0.8876 - precision: 0.8959 - val_loss: 0.2019 - val_accuracy: 0.9340 - val_auc: 0.9749 - val_recall: 0.9179 - val_precision: 0.5935\n",
      "Epoch 2/32\n",
      "2888/2888 [==============================] - 124s 43ms/step - loss: 0.1327 - accuracy: 0.9571 - auc: 0.9912 - recall: 0.9601 - precision: 0.9561 - val_loss: 0.1529 - val_accuracy: 0.9534 - val_auc: 0.9798 - val_recall: 0.9104 - val_precision: 0.6883\n",
      "Epoch 3/32\n",
      "2888/2888 [==============================] - 145s 50ms/step - loss: 0.1060 - accuracy: 0.9680 - auc: 0.9948 - recall: 0.9719 - precision: 0.9657 - val_loss: 0.1655 - val_accuracy: 0.9525 - val_auc: 0.9656 - val_recall: 0.8358 - val_precision: 0.7066\n",
      "Epoch 4/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.0891 - accuracy: 0.9750 - auc: 0.9967 - recall: 0.9780 - precision: 0.9732 - val_loss: 0.1625 - val_accuracy: 0.9569 - val_auc: 0.9806 - val_recall: 0.9179 - val_precision: 0.7059\n",
      "Epoch 5/32\n",
      "2888/2888 [==============================] - 146s 51ms/step - loss: 0.0819 - accuracy: 0.9777 - auc: 0.9971 - recall: 0.9802 - precision: 0.9763 - val_loss: 0.1486 - val_accuracy: 0.9567 - val_auc: 0.9809 - val_recall: 0.9216 - val_precision: 0.7037\n",
      "Epoch 6/32\n",
      "2888/2888 [==============================] - 137s 47ms/step - loss: 0.0737 - accuracy: 0.9808 - auc: 0.9978 - recall: 0.9840 - precision: 0.9785 - val_loss: 0.1352 - val_accuracy: 0.9683 - val_auc: 0.9776 - val_recall: 0.8657 - val_precision: 0.8070\n",
      "Epoch 7/32\n",
      "2888/2888 [==============================] - 169s 59ms/step - loss: 0.0684 - accuracy: 0.9830 - auc: 0.9982 - recall: 0.9857 - precision: 0.9812 - val_loss: 0.1548 - val_accuracy: 0.9584 - val_auc: 0.9798 - val_recall: 0.9216 - val_precision: 0.7139\n",
      "Epoch 8/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0662 - accuracy: 0.9842 - auc: 0.9982 - recall: 0.9868 - precision: 0.9823 - val_loss: 0.1312 - val_accuracy: 0.9681 - val_auc: 0.9798 - val_recall: 0.8993 - val_precision: 0.7876\n",
      "Epoch 9/32\n",
      "2888/2888 [==============================] - 166s 57ms/step - loss: 0.0604 - accuracy: 0.9858 - auc: 0.9985 - recall: 0.9883 - precision: 0.9840 - val_loss: 0.2002 - val_accuracy: 0.9567 - val_auc: 0.9759 - val_recall: 0.9179 - val_precision: 0.7049\n",
      "Epoch 10/32\n",
      "2888/2888 [==============================] - 144s 50ms/step - loss: 0.0576 - accuracy: 0.9871 - auc: 0.9986 - recall: 0.9887 - precision: 0.9860 - val_loss: 0.1479 - val_accuracy: 0.9624 - val_auc: 0.9837 - val_recall: 0.9160 - val_precision: 0.7406\n",
      "Epoch 11/32\n",
      "2888/2888 [==============================] - 140s 48ms/step - loss: 0.0553 - accuracy: 0.9874 - auc: 0.9988 - recall: 0.9898 - precision: 0.9857 - val_loss: 0.1407 - val_accuracy: 0.9659 - val_auc: 0.9740 - val_recall: 0.8899 - val_precision: 0.7756\n",
      "Epoch 12/32\n",
      "2888/2888 [==============================] - 107s 37ms/step - loss: 0.0538 - accuracy: 0.9876 - auc: 0.9988 - recall: 0.9895 - precision: 0.9862 - val_loss: 0.1536 - val_accuracy: 0.9648 - val_auc: 0.9834 - val_recall: 0.9347 - val_precision: 0.7489\n",
      "Epoch 13/32\n",
      "2888/2888 [==============================] - 79s 28ms/step - loss: 0.0502 - accuracy: 0.9885 - auc: 0.9991 - recall: 0.9902 - precision: 0.9874 - val_loss: 0.1704 - val_accuracy: 0.9666 - val_auc: 0.9693 - val_recall: 0.8750 - val_precision: 0.7882\n",
      "Epoch 14/32\n",
      "2888/2888 [==============================] - 77s 27ms/step - loss: 0.0343 - accuracy: 0.9945 - auc: 0.9997 - recall: 0.9961 - precision: 0.9931 - val_loss: 0.1723 - val_accuracy: 0.9723 - val_auc: 0.9736 - val_recall: 0.9049 - val_precision: 0.8165\n",
      "Epoch 15/32\n",
      "2888/2888 [==============================] - 79s 27ms/step - loss: 0.0302 - accuracy: 0.9957 - auc: 0.9998 - recall: 0.9974 - precision: 0.9941 - val_loss: 0.1809 - val_accuracy: 0.9712 - val_auc: 0.9743 - val_recall: 0.9216 - val_precision: 0.7994\n",
      "Epoch 16/32\n",
      "2888/2888 [==============================] - 76s 26ms/step - loss: 0.0284 - accuracy: 0.9960 - auc: 0.9998 - recall: 0.9977 - precision: 0.9944 - val_loss: 0.1858 - val_accuracy: 0.9719 - val_auc: 0.9734 - val_recall: 0.9086 - val_precision: 0.8117\n",
      "1444/1444 [==============================] - 23s 16ms/step - loss: 0.0184 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# predictions_CNN_prob_1 - SUBMIT THISISSISISISISISISIS\n",
    "#  0.98813\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_1 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/32\n",
      "2888/2888 [==============================] - 170s 58ms/step - loss: 0.4688 - accuracy: 0.7657 - auc: 0.8603 - recall: 0.7909 - precision: 0.7601 - val_loss: 0.2494 - val_accuracy: 0.9092 - val_auc: 0.8979 - val_recall: 0.6903 - val_precision: 0.5082\n",
      "Epoch 2/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.2901 - accuracy: 0.8858 - auc: 0.9513 - recall: 0.8869 - precision: 0.8891 - val_loss: 0.2143 - val_accuracy: 0.9165 - val_auc: 0.9375 - val_recall: 0.7985 - val_precision: 0.5337\n",
      "Epoch 3/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.2420 - accuracy: 0.9090 - auc: 0.9668 - recall: 0.9115 - precision: 0.9105 - val_loss: 0.2316 - val_accuracy: 0.9092 - val_auc: 0.9390 - val_recall: 0.8022 - val_precision: 0.5071\n",
      "Epoch 4/32\n",
      "2888/2888 [==============================] - 168s 58ms/step - loss: 0.2168 - accuracy: 0.9213 - auc: 0.9741 - recall: 0.9236 - precision: 0.9223 - val_loss: 0.2500 - val_accuracy: 0.9002 - val_auc: 0.9427 - val_recall: 0.8377 - val_precision: 0.4787\n",
      "Epoch 5/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.2014 - accuracy: 0.9282 - auc: 0.9781 - recall: 0.9307 - precision: 0.9288 - val_loss: 0.1968 - val_accuracy: 0.9278 - val_auc: 0.9402 - val_recall: 0.7743 - val_precision: 0.5837\n",
      "Epoch 6/32\n",
      "2888/2888 [==============================] - 161s 56ms/step - loss: 0.1923 - accuracy: 0.9326 - auc: 0.9804 - recall: 0.9358 - precision: 0.9325 - val_loss: 0.1975 - val_accuracy: 0.9267 - val_auc: 0.9449 - val_recall: 0.7892 - val_precision: 0.5771\n",
      "Epoch 7/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.1832 - accuracy: 0.9367 - auc: 0.9826 - recall: 0.9400 - precision: 0.9363 - val_loss: 0.1693 - val_accuracy: 0.9425 - val_auc: 0.9566 - val_recall: 0.8060 - val_precision: 0.6545\n",
      "Epoch 8/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.1780 - accuracy: 0.9394 - auc: 0.9838 - recall: 0.9421 - precision: 0.9393 - val_loss: 0.1860 - val_accuracy: 0.9345 - val_auc: 0.9559 - val_recall: 0.8209 - val_precision: 0.6094\n",
      "Epoch 9/32\n",
      "2888/2888 [==============================] - 157s 55ms/step - loss: 0.1710 - accuracy: 0.9423 - auc: 0.9854 - recall: 0.9455 - precision: 0.9417 - val_loss: 0.1720 - val_accuracy: 0.9409 - val_auc: 0.9556 - val_recall: 0.7854 - val_precision: 0.6507\n",
      "Epoch 10/32\n",
      "2888/2888 [==============================] - 154s 53ms/step - loss: 0.1675 - accuracy: 0.9443 - auc: 0.9862 - recall: 0.9472 - precision: 0.9439 - val_loss: 0.2052 - val_accuracy: 0.9271 - val_auc: 0.9565 - val_recall: 0.8377 - val_precision: 0.5734\n",
      "Epoch 11/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.1646 - accuracy: 0.9458 - auc: 0.9868 - recall: 0.9488 - precision: 0.9452 - val_loss: 0.1724 - val_accuracy: 0.9432 - val_auc: 0.9529 - val_recall: 0.7780 - val_precision: 0.6661\n",
      "Epoch 12/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.1594 - accuracy: 0.9488 - auc: 0.9878 - recall: 0.9530 - precision: 0.9471 - val_loss: 0.1551 - val_accuracy: 0.9506 - val_auc: 0.9569 - val_recall: 0.7649 - val_precision: 0.7206\n",
      "Epoch 13/32\n",
      "2888/2888 [==============================] - 160s 56ms/step - loss: 0.1566 - accuracy: 0.9498 - auc: 0.9884 - recall: 0.9538 - precision: 0.9482 - val_loss: 0.1627 - val_accuracy: 0.9440 - val_auc: 0.9591 - val_recall: 0.7929 - val_precision: 0.6672\n",
      "Epoch 14/32\n",
      "2888/2888 [==============================] - 169s 59ms/step - loss: 0.1556 - accuracy: 0.9505 - auc: 0.9887 - recall: 0.9532 - precision: 0.9502 - val_loss: 0.1559 - val_accuracy: 0.9513 - val_auc: 0.9590 - val_recall: 0.7631 - val_precision: 0.7265\n",
      "Epoch 15/32\n",
      "2888/2888 [==============================] - 163s 57ms/step - loss: 0.1516 - accuracy: 0.9524 - auc: 0.9893 - recall: 0.9560 - precision: 0.9511 - val_loss: 0.1727 - val_accuracy: 0.9435 - val_auc: 0.9609 - val_recall: 0.8302 - val_precision: 0.6544\n",
      "Epoch 16/32\n",
      "2888/2888 [==============================] - 157s 54ms/step - loss: 0.1477 - accuracy: 0.9537 - auc: 0.9901 - recall: 0.9575 - precision: 0.9521 - val_loss: 0.1733 - val_accuracy: 0.9453 - val_auc: 0.9666 - val_recall: 0.8470 - val_precision: 0.6599\n",
      "Epoch 17/32\n",
      "2888/2888 [==============================] - 166s 57ms/step - loss: 0.1477 - accuracy: 0.9540 - auc: 0.9901 - recall: 0.9572 - precision: 0.9530 - val_loss: 0.1495 - val_accuracy: 0.9558 - val_auc: 0.9630 - val_recall: 0.7910 - val_precision: 0.7478\n",
      "Epoch 18/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.1457 - accuracy: 0.9563 - auc: 0.9904 - recall: 0.9592 - precision: 0.9553 - val_loss: 0.1643 - val_accuracy: 0.9468 - val_auc: 0.9672 - val_recall: 0.8433 - val_precision: 0.6696\n",
      "Epoch 19/32\n",
      "2888/2888 [==============================] - 157s 54ms/step - loss: 0.1450 - accuracy: 0.9561 - auc: 0.9906 - recall: 0.9589 - precision: 0.9553 - val_loss: 0.1623 - val_accuracy: 0.9492 - val_auc: 0.9606 - val_recall: 0.8190 - val_precision: 0.6913\n",
      "Epoch 20/32\n",
      "2888/2888 [==============================] - 183s 63ms/step - loss: 0.1415 - accuracy: 0.9571 - auc: 0.9913 - recall: 0.9597 - precision: 0.9564 - val_loss: 0.1648 - val_accuracy: 0.9428 - val_auc: 0.9642 - val_recall: 0.8358 - val_precision: 0.6493\n",
      "Epoch 21/32\n",
      "2888/2888 [==============================] - 166s 58ms/step - loss: 0.1409 - accuracy: 0.9573 - auc: 0.9914 - recall: 0.9603 - precision: 0.9563 - val_loss: 0.1661 - val_accuracy: 0.9487 - val_auc: 0.9607 - val_recall: 0.8153 - val_precision: 0.6893\n",
      "Epoch 22/32\n",
      "2888/2888 [==============================] - 163s 57ms/step - loss: 0.1376 - accuracy: 0.9591 - auc: 0.9918 - recall: 0.9623 - precision: 0.9577 - val_loss: 0.1688 - val_accuracy: 0.9437 - val_auc: 0.9645 - val_recall: 0.8284 - val_precision: 0.6558\n",
      "Epoch 23/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.1082 - accuracy: 0.9708 - auc: 0.9954 - recall: 0.9735 - precision: 0.9693 - val_loss: 0.1589 - val_accuracy: 0.9475 - val_auc: 0.9684 - val_recall: 0.8563 - val_precision: 0.6701\n",
      "Epoch 24/32\n",
      "2888/2888 [==============================] - 160s 55ms/step - loss: 0.0994 - accuracy: 0.9736 - auc: 0.9961 - recall: 0.9765 - precision: 0.9721 - val_loss: 0.1477 - val_accuracy: 0.9556 - val_auc: 0.9662 - val_recall: 0.8358 - val_precision: 0.7273\n",
      "Epoch 25/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.0967 - accuracy: 0.9743 - auc: 0.9964 - recall: 0.9770 - precision: 0.9729 - val_loss: 0.1471 - val_accuracy: 0.9556 - val_auc: 0.9640 - val_recall: 0.8321 - val_precision: 0.7288\n",
      "Epoch 26/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0950 - accuracy: 0.9750 - auc: 0.9965 - recall: 0.9777 - precision: 0.9734 - val_loss: 0.1454 - val_accuracy: 0.9555 - val_auc: 0.9671 - val_recall: 0.8078 - val_precision: 0.7376\n",
      "Epoch 27/32\n",
      "2888/2888 [==============================] - 153s 53ms/step - loss: 0.0941 - accuracy: 0.9753 - auc: 0.9965 - recall: 0.9777 - precision: 0.9740 - val_loss: 0.1468 - val_accuracy: 0.9541 - val_auc: 0.9668 - val_recall: 0.8396 - val_precision: 0.7154\n",
      "Epoch 28/32\n",
      "2888/2888 [==============================] - 152s 53ms/step - loss: 0.0918 - accuracy: 0.9761 - auc: 0.9967 - recall: 0.9785 - precision: 0.9749 - val_loss: 0.1443 - val_accuracy: 0.9569 - val_auc: 0.9670 - val_recall: 0.8265 - val_precision: 0.7396\n",
      "Epoch 29/32\n",
      "2888/2888 [==============================] - 153s 53ms/step - loss: 0.0922 - accuracy: 0.9755 - auc: 0.9968 - recall: 0.9778 - precision: 0.9744 - val_loss: 0.1399 - val_accuracy: 0.9589 - val_auc: 0.9648 - val_recall: 0.8172 - val_precision: 0.7591\n",
      "Epoch 30/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0887 - accuracy: 0.9775 - auc: 0.9969 - recall: 0.9804 - precision: 0.9756 - val_loss: 0.1415 - val_accuracy: 0.9581 - val_auc: 0.9667 - val_recall: 0.8284 - val_precision: 0.7475\n",
      "Epoch 31/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.0887 - accuracy: 0.9776 - auc: 0.9969 - recall: 0.9802 - precision: 0.9761 - val_loss: 0.1423 - val_accuracy: 0.9576 - val_auc: 0.9652 - val_recall: 0.7892 - val_precision: 0.7622\n",
      "Epoch 32/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.0871 - accuracy: 0.9780 - auc: 0.9970 - recall: 0.9803 - precision: 0.9767 - val_loss: 0.1355 - val_accuracy: 0.9593 - val_auc: 0.9685 - val_recall: 0.8172 - val_precision: 0.7617\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 8s 32ms/step - loss: 0.1398 - accuracy: 0.9601 - auc: 0.9627 - recall: 0.8038 - precision: 0.7663\n"
     ]
    }
   ],
   "source": [
    "# predictions_CNN_prob_2 \n",
    "# SMOTE EN sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_2 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/32\n",
      "1624/1624 [==============================] - 93s 56ms/step - loss: 0.2617 - accuracy: 0.9210 - auc: 0.7793 - recall: 0.1982 - precision: 0.7438 - val_loss: 0.2422 - val_accuracy: 0.9397 - val_auc: 0.9067 - val_recall: 0.4944 - val_precision: 0.7749\n",
      "Epoch 2/32\n",
      "1624/1624 [==============================] - 100s 62ms/step - loss: 0.1812 - accuracy: 0.9435 - auc: 0.9053 - recall: 0.4986 - precision: 0.8044 - val_loss: 0.1912 - val_accuracy: 0.9494 - val_auc: 0.9451 - val_recall: 0.5634 - val_precision: 0.8389\n",
      "Epoch 3/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1584 - accuracy: 0.9493 - auc: 0.9349 - recall: 0.5720 - precision: 0.8141 - val_loss: 0.1366 - val_accuracy: 0.9572 - val_auc: 0.9592 - val_recall: 0.6828 - val_precision: 0.8262\n",
      "Epoch 4/32\n",
      "1624/1624 [==============================] - 90s 56ms/step - loss: 0.1436 - accuracy: 0.9546 - auc: 0.9497 - recall: 0.6178 - precision: 0.8400 - val_loss: 0.1339 - val_accuracy: 0.9586 - val_auc: 0.9696 - val_recall: 0.5989 - val_precision: 0.9304\n",
      "Epoch 5/32\n",
      "1624/1624 [==============================] - 90s 55ms/step - loss: 0.1323 - accuracy: 0.9584 - auc: 0.9574 - recall: 0.6621 - precision: 0.8461 - val_loss: 0.1343 - val_accuracy: 0.9624 - val_auc: 0.9768 - val_recall: 0.7463 - val_precision: 0.8316\n",
      "Epoch 6/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1264 - accuracy: 0.9602 - auc: 0.9623 - recall: 0.6809 - precision: 0.8513 - val_loss: 0.1416 - val_accuracy: 0.9605 - val_auc: 0.9736 - val_recall: 0.7015 - val_precision: 0.8468\n",
      "Epoch 7/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1175 - accuracy: 0.9641 - auc: 0.9691 - recall: 0.7130 - precision: 0.8681 - val_loss: 0.1138 - val_accuracy: 0.9643 - val_auc: 0.9737 - val_recall: 0.6978 - val_precision: 0.8947\n",
      "Epoch 8/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1159 - accuracy: 0.9647 - auc: 0.9691 - recall: 0.7199 - precision: 0.8692 - val_loss: 0.1123 - val_accuracy: 0.9648 - val_auc: 0.9765 - val_recall: 0.6866 - val_precision: 0.9132\n",
      "Epoch 9/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1136 - accuracy: 0.9649 - auc: 0.9721 - recall: 0.7305 - precision: 0.8619 - val_loss: 0.1284 - val_accuracy: 0.9650 - val_auc: 0.9785 - val_recall: 0.6959 - val_precision: 0.9053\n",
      "Epoch 10/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1052 - accuracy: 0.9671 - auc: 0.9772 - recall: 0.7543 - precision: 0.8661 - val_loss: 0.1029 - val_accuracy: 0.9695 - val_auc: 0.9827 - val_recall: 0.7948 - val_precision: 0.8659\n",
      "Epoch 11/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1032 - accuracy: 0.9674 - auc: 0.9785 - recall: 0.7551 - precision: 0.8692 - val_loss: 0.1236 - val_accuracy: 0.9688 - val_auc: 0.9813 - val_recall: 0.8116 - val_precision: 0.8463\n",
      "Epoch 12/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.1001 - accuracy: 0.9696 - auc: 0.9793 - recall: 0.7670 - precision: 0.8829 - val_loss: 0.1027 - val_accuracy: 0.9683 - val_auc: 0.9834 - val_recall: 0.7201 - val_precision: 0.9212\n",
      "Epoch 13/32\n",
      "1624/1624 [==============================] - 95s 59ms/step - loss: 0.0978 - accuracy: 0.9707 - auc: 0.9795 - recall: 0.7761 - precision: 0.8869 - val_loss: 0.1050 - val_accuracy: 0.9681 - val_auc: 0.9841 - val_recall: 0.7239 - val_precision: 0.9151\n",
      "Epoch 14/32\n",
      "1624/1624 [==============================] - 123s 76ms/step - loss: 0.0953 - accuracy: 0.9716 - auc: 0.9820 - recall: 0.7925 - precision: 0.8831 - val_loss: 0.1189 - val_accuracy: 0.9678 - val_auc: 0.9803 - val_recall: 0.7649 - val_precision: 0.8723\n",
      "Epoch 15/32\n",
      "1624/1624 [==============================] - 106s 65ms/step - loss: 0.0943 - accuracy: 0.9714 - auc: 0.9824 - recall: 0.7920 - precision: 0.8809 - val_loss: 0.1085 - val_accuracy: 0.9697 - val_auc: 0.9821 - val_recall: 0.7556 - val_precision: 0.9020\n",
      "Epoch 16/32\n",
      "1624/1624 [==============================] - 96s 59ms/step - loss: 0.0935 - accuracy: 0.9723 - auc: 0.9832 - recall: 0.7990 - precision: 0.8843 - val_loss: 0.1009 - val_accuracy: 0.9711 - val_auc: 0.9866 - val_recall: 0.7929 - val_precision: 0.8836\n",
      "Epoch 17/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.0903 - accuracy: 0.9732 - auc: 0.9837 - recall: 0.8084 - precision: 0.8861 - val_loss: 0.1060 - val_accuracy: 0.9718 - val_auc: 0.9859 - val_recall: 0.8134 - val_precision: 0.8737\n",
      "Epoch 18/32\n",
      "1624/1624 [==============================] - 95s 58ms/step - loss: 0.0877 - accuracy: 0.9743 - auc: 0.9843 - recall: 0.8086 - precision: 0.8987 - val_loss: 0.1287 - val_accuracy: 0.9711 - val_auc: 0.9833 - val_recall: 0.8545 - val_precision: 0.8373\n",
      "Epoch 19/32\n",
      "1624/1624 [==============================] - 93s 57ms/step - loss: 0.0874 - accuracy: 0.9749 - auc: 0.9851 - recall: 0.8196 - precision: 0.8953 - val_loss: 0.1013 - val_accuracy: 0.9761 - val_auc: 0.9883 - val_recall: 0.8489 - val_precision: 0.8887\n",
      "Epoch 20/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.0861 - accuracy: 0.9749 - auc: 0.9852 - recall: 0.8190 - precision: 0.8961 - val_loss: 0.0899 - val_accuracy: 0.9719 - val_auc: 0.9874 - val_recall: 0.7668 - val_precision: 0.9174\n",
      "Epoch 21/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.0832 - accuracy: 0.9756 - auc: 0.9871 - recall: 0.8257 - precision: 0.8979 - val_loss: 0.0950 - val_accuracy: 0.9738 - val_auc: 0.9847 - val_recall: 0.7948 - val_precision: 0.9122\n",
      "Epoch 22/32\n",
      "1624/1624 [==============================] - 93s 57ms/step - loss: 0.0855 - accuracy: 0.9751 - auc: 0.9861 - recall: 0.8281 - precision: 0.8902 - val_loss: 0.1086 - val_accuracy: 0.9645 - val_auc: 0.9798 - val_recall: 0.6642 - val_precision: 0.9344\n",
      "Epoch 23/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.0818 - accuracy: 0.9761 - auc: 0.9873 - recall: 0.8321 - precision: 0.8978 - val_loss: 0.0967 - val_accuracy: 0.9704 - val_auc: 0.9854 - val_recall: 0.7593 - val_precision: 0.9065\n",
      "Epoch 24/32\n",
      "1624/1624 [==============================] - 93s 58ms/step - loss: 0.0824 - accuracy: 0.9759 - auc: 0.9866 - recall: 0.8353 - precision: 0.8928 - val_loss: 0.0958 - val_accuracy: 0.9742 - val_auc: 0.9849 - val_recall: 0.8097 - val_precision: 0.9023\n",
      "Epoch 25/32\n",
      "1624/1624 [==============================] - 95s 58ms/step - loss: 0.0810 - accuracy: 0.9764 - auc: 0.9877 - recall: 0.8387 - precision: 0.8946 - val_loss: 0.0936 - val_accuracy: 0.9745 - val_auc: 0.9891 - val_recall: 0.8116 - val_precision: 0.9044\n",
      "Epoch 26/32\n",
      "1624/1624 [==============================] - 89s 55ms/step - loss: 0.0645 - accuracy: 0.9824 - auc: 0.9937 - recall: 0.8773 - precision: 0.9251 - val_loss: 0.0842 - val_accuracy: 0.9768 - val_auc: 0.9890 - val_recall: 0.8396 - val_precision: 0.9036\n",
      "Epoch 27/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0574 - accuracy: 0.9849 - auc: 0.9949 - recall: 0.9012 - precision: 0.9300 - val_loss: 0.0811 - val_accuracy: 0.9773 - val_auc: 0.9875 - val_recall: 0.8433 - val_precision: 0.9058\n",
      "Epoch 28/32\n",
      "1624/1624 [==============================] - 86s 53ms/step - loss: 0.0561 - accuracy: 0.9849 - auc: 0.9951 - recall: 0.9052 - precision: 0.9266 - val_loss: 0.0799 - val_accuracy: 0.9773 - val_auc: 0.9868 - val_recall: 0.8265 - val_precision: 0.9210\n",
      "Epoch 29/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0543 - accuracy: 0.9853 - auc: 0.9949 - recall: 0.9105 - precision: 0.9258 - val_loss: 0.0807 - val_accuracy: 0.9777 - val_auc: 0.9872 - val_recall: 0.8340 - val_precision: 0.9179\n",
      "Epoch 30/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0532 - accuracy: 0.9864 - auc: 0.9956 - recall: 0.9150 - precision: 0.9342 - val_loss: 0.0801 - val_accuracy: 0.9778 - val_auc: 0.9879 - val_recall: 0.8377 - val_precision: 0.9163\n",
      "Epoch 31/32\n",
      "1624/1624 [==============================] - 87s 54ms/step - loss: 0.0521 - accuracy: 0.9861 - auc: 0.9957 - recall: 0.9144 - precision: 0.9309 - val_loss: 0.0791 - val_accuracy: 0.9783 - val_auc: 0.9861 - val_recall: 0.8489 - val_precision: 0.9118\n",
      "Epoch 32/32\n",
      "1624/1624 [==============================] - 87s 54ms/step - loss: 0.0504 - accuracy: 0.9868 - auc: 0.9956 - recall: 0.9182 - precision: 0.9354 - val_loss: 0.0830 - val_accuracy: 0.9773 - val_auc: 0.9883 - val_recall: 0.8619 - val_precision: 0.8902\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 7s 30ms/step - loss: 0.0866 - accuracy: 0.9777 - auc: 0.9858 - recall: 0.8659 - precision: 0.8849\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set.\n",
    "# predictions_CNN_prob_3 - SUBMIT THISISSISISISISISISIS\n",
    "# 0.99060 on kaggle\n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_3 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/64\n",
      "1624/1624 [==============================] - 167s 101ms/step - loss: 0.4036 - accuracy: 0.9200 - auc: 0.7902 - recall: 0.2610 - precision: 0.6482 - val_loss: 0.4930 - val_accuracy: 0.8820 - val_auc: 0.8621 - val_recall: 0.6493 - val_precision: 0.4138\n",
      "Epoch 2/64\n",
      "1624/1624 [==============================] - 156s 96ms/step - loss: 0.2805 - accuracy: 0.9348 - auc: 0.8776 - recall: 0.4469 - precision: 0.7302 - val_loss: 0.6525 - val_accuracy: 0.5035 - val_auc: 0.8335 - val_recall: 0.9627 - val_precision: 0.1535\n",
      "Epoch 3/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.2445 - accuracy: 0.9364 - auc: 0.8879 - recall: 0.4861 - precision: 0.7224 - val_loss: 0.2242 - val_accuracy: 0.9390 - val_auc: 0.9155 - val_recall: 0.6343 - val_precision: 0.6855\n",
      "Epoch 4/64\n",
      "1624/1624 [==============================] - 153s 94ms/step - loss: 0.2495 - accuracy: 0.9325 - auc: 0.8813 - recall: 0.4950 - precision: 0.6747 - val_loss: 0.4194 - val_accuracy: 0.9203 - val_auc: 0.8129 - val_recall: 0.1493 - val_precision: 0.9524\n",
      "Epoch 5/64\n",
      "1624/1624 [==============================] - 152s 94ms/step - loss: 0.2307 - accuracy: 0.9389 - auc: 0.8931 - recall: 0.4974 - precision: 0.7452 - val_loss: 0.9866 - val_accuracy: 0.7152 - val_auc: 0.8617 - val_recall: 0.8433 - val_precision: 0.2247\n",
      "Epoch 6/64\n",
      "1624/1624 [==============================] - 152s 93ms/step - loss: 0.2206 - accuracy: 0.9410 - auc: 0.9048 - recall: 0.5207 - precision: 0.7538 - val_loss: 0.2717 - val_accuracy: 0.9276 - val_auc: 0.9115 - val_recall: 0.2761 - val_precision: 0.8315\n",
      "Epoch 7/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.1993 - accuracy: 0.9455 - auc: 0.9238 - recall: 0.5624 - precision: 0.7760 - val_loss: 0.1855 - val_accuracy: 0.9494 - val_auc: 0.9334 - val_recall: 0.5653 - val_precision: 0.8370\n",
      "Epoch 8/64\n",
      "1624/1624 [==============================] - 152s 94ms/step - loss: 0.1825 - accuracy: 0.9485 - auc: 0.9347 - recall: 0.6044 - precision: 0.7792 - val_loss: 0.1801 - val_accuracy: 0.9473 - val_auc: 0.9310 - val_recall: 0.6026 - val_precision: 0.7802\n",
      "Epoch 9/64\n",
      "1624/1624 [==============================] - 150s 93ms/step - loss: 0.1633 - accuracy: 0.9518 - auc: 0.9448 - recall: 0.6415 - precision: 0.7888 - val_loss: 0.2104 - val_accuracy: 0.9269 - val_auc: 0.9443 - val_recall: 0.8153 - val_precision: 0.5750\n",
      "Epoch 10/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.1562 - accuracy: 0.9540 - auc: 0.9482 - recall: 0.6515 - precision: 0.8047 - val_loss: 0.2696 - val_accuracy: 0.9023 - val_auc: 0.9458 - val_recall: 0.8489 - val_precision: 0.4851\n",
      "Epoch 11/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1446 - accuracy: 0.9560 - auc: 0.9572 - recall: 0.6750 - precision: 0.8087 - val_loss: 0.1512 - val_accuracy: 0.9560 - val_auc: 0.9628 - val_recall: 0.7780 - val_precision: 0.7554\n",
      "Epoch 12/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.1408 - accuracy: 0.9575 - auc: 0.9594 - recall: 0.6896 - precision: 0.8145 - val_loss: 0.1590 - val_accuracy: 0.9463 - val_auc: 0.9559 - val_recall: 0.7836 - val_precision: 0.6840\n",
      "Epoch 13/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1378 - accuracy: 0.9585 - auc: 0.9606 - recall: 0.6990 - precision: 0.8175 - val_loss: 0.1575 - val_accuracy: 0.9525 - val_auc: 0.9556 - val_recall: 0.7369 - val_precision: 0.7481\n",
      "Epoch 14/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1314 - accuracy: 0.9596 - auc: 0.9652 - recall: 0.7117 - precision: 0.8202 - val_loss: 0.1435 - val_accuracy: 0.9548 - val_auc: 0.9596 - val_recall: 0.7668 - val_precision: 0.7514\n",
      "Epoch 15/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1275 - accuracy: 0.9614 - auc: 0.9663 - recall: 0.7132 - precision: 0.8372 - val_loss: 0.2033 - val_accuracy: 0.9264 - val_auc: 0.9600 - val_recall: 0.8377 - val_precision: 0.5705\n",
      "Epoch 16/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1264 - accuracy: 0.9614 - auc: 0.9683 - recall: 0.7098 - precision: 0.8399 - val_loss: 0.1341 - val_accuracy: 0.9551 - val_auc: 0.9700 - val_recall: 0.5840 - val_precision: 0.8968\n",
      "Epoch 17/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.1197 - accuracy: 0.9629 - auc: 0.9718 - recall: 0.7223 - precision: 0.8467 - val_loss: 0.1259 - val_accuracy: 0.9608 - val_auc: 0.9708 - val_recall: 0.7108 - val_precision: 0.8429\n",
      "Epoch 18/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1175 - accuracy: 0.9642 - auc: 0.9732 - recall: 0.7403 - precision: 0.8457 - val_loss: 0.1501 - val_accuracy: 0.9499 - val_auc: 0.9713 - val_recall: 0.8396 - val_precision: 0.6891\n",
      "Epoch 19/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1133 - accuracy: 0.9652 - auc: 0.9758 - recall: 0.7532 - precision: 0.8468 - val_loss: 0.1341 - val_accuracy: 0.9563 - val_auc: 0.9649 - val_recall: 0.7313 - val_precision: 0.7840\n",
      "Epoch 20/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1085 - accuracy: 0.9663 - auc: 0.9774 - recall: 0.7630 - precision: 0.8502 - val_loss: 0.2365 - val_accuracy: 0.9099 - val_auc: 0.9656 - val_recall: 0.9030 - val_precision: 0.5084\n",
      "Epoch 21/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1063 - accuracy: 0.9682 - auc: 0.9780 - recall: 0.7717 - precision: 0.8640 - val_loss: 0.1662 - val_accuracy: 0.9567 - val_auc: 0.9498 - val_recall: 0.5914 - val_precision: 0.9109\n",
      "Epoch 22/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1033 - accuracy: 0.9685 - auc: 0.9799 - recall: 0.7755 - precision: 0.8642 - val_loss: 0.1333 - val_accuracy: 0.9621 - val_auc: 0.9639 - val_recall: 0.6735 - val_precision: 0.8914\n",
      "Epoch 23/64\n",
      "1624/1624 [==============================] - 149s 91ms/step - loss: 0.0837 - accuracy: 0.9745 - auc: 0.9877 - recall: 0.8283 - precision: 0.8835 - val_loss: 0.0985 - val_accuracy: 0.9679 - val_auc: 0.9823 - val_recall: 0.8321 - val_precision: 0.8244\n",
      "Epoch 24/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.0784 - accuracy: 0.9761 - auc: 0.9890 - recall: 0.8480 - precision: 0.8844 - val_loss: 0.0963 - val_accuracy: 0.9695 - val_auc: 0.9814 - val_recall: 0.8060 - val_precision: 0.8571\n",
      "Epoch 25/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0758 - accuracy: 0.9777 - auc: 0.9898 - recall: 0.8554 - precision: 0.8945 - val_loss: 0.0974 - val_accuracy: 0.9685 - val_auc: 0.9812 - val_recall: 0.8041 - val_precision: 0.8484\n",
      "Epoch 26/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0733 - accuracy: 0.9784 - auc: 0.9902 - recall: 0.8603 - precision: 0.8972 - val_loss: 0.0960 - val_accuracy: 0.9676 - val_auc: 0.9839 - val_recall: 0.8302 - val_precision: 0.8226\n",
      "Epoch 27/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0717 - accuracy: 0.9781 - auc: 0.9908 - recall: 0.8586 - precision: 0.8964 - val_loss: 0.0952 - val_accuracy: 0.9705 - val_auc: 0.9822 - val_recall: 0.8172 - val_precision: 0.8588\n",
      "Epoch 28/64\n",
      "1624/1624 [==============================] - 147s 90ms/step - loss: 0.0690 - accuracy: 0.9794 - auc: 0.9910 - recall: 0.8609 - precision: 0.9073 - val_loss: 0.0933 - val_accuracy: 0.9714 - val_auc: 0.9819 - val_recall: 0.8116 - val_precision: 0.8717\n",
      "Epoch 29/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.0663 - accuracy: 0.9809 - auc: 0.9923 - recall: 0.8690 - precision: 0.9162 - val_loss: 0.0985 - val_accuracy: 0.9681 - val_auc: 0.9839 - val_recall: 0.8619 - val_precision: 0.8077\n",
      "Epoch 30/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.0655 - accuracy: 0.9811 - auc: 0.9918 - recall: 0.8692 - precision: 0.9178 - val_loss: 0.0976 - val_accuracy: 0.9707 - val_auc: 0.9799 - val_recall: 0.8041 - val_precision: 0.8707\n",
      "Epoch 31/64\n",
      "1624/1624 [==============================] - 147s 90ms/step - loss: 0.0631 - accuracy: 0.9821 - auc: 0.9920 - recall: 0.8760 - precision: 0.9229 - val_loss: 0.1009 - val_accuracy: 0.9707 - val_auc: 0.9792 - val_recall: 0.7985 - val_precision: 0.8753\n",
      "Epoch 32/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0623 - accuracy: 0.9820 - auc: 0.9926 - recall: 0.8743 - precision: 0.9230 - val_loss: 0.0973 - val_accuracy: 0.9686 - val_auc: 0.9817 - val_recall: 0.8414 - val_precision: 0.8245\n",
      "Epoch 33/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0600 - accuracy: 0.9832 - auc: 0.9929 - recall: 0.8826 - precision: 0.9288 - val_loss: 0.0968 - val_accuracy: 0.9707 - val_auc: 0.9822 - val_recall: 0.8358 - val_precision: 0.8469\n",
      "Epoch 34/64\n",
      "1624/1624 [==============================] - 147s 91ms/step - loss: 0.0559 - accuracy: 0.9850 - auc: 0.9941 - recall: 0.8942 - precision: 0.9373 - val_loss: 0.0943 - val_accuracy: 0.9723 - val_auc: 0.9821 - val_recall: 0.8340 - val_precision: 0.8629\n",
      "Epoch 35/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0552 - accuracy: 0.9851 - auc: 0.9941 - recall: 0.8934 - precision: 0.9398 - val_loss: 0.0956 - val_accuracy: 0.9719 - val_auc: 0.9818 - val_recall: 0.8321 - val_precision: 0.8610\n",
      "Epoch 36/64\n",
      "1624/1624 [==============================] - 152s 93ms/step - loss: 0.0547 - accuracy: 0.9854 - auc: 0.9942 - recall: 0.8961 - precision: 0.9408 - val_loss: 0.0968 - val_accuracy: 0.9714 - val_auc: 0.9817 - val_recall: 0.8228 - val_precision: 0.8630\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 13s 56ms/step - loss: 0.1058 - accuracy: 0.9728 - auc: 0.9747 - recall: 0.8383 - precision: 0.8574\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #keras.layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    conv_block(32),\n",
    "    conv_block(64),\n",
    "    conv_block(128),\n",
    "    conv_block(256),\n",
    "    conv_block(256),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_4 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 29s 17ms/step - loss: 0.1688 - accuracy: 0.9479 - auc: 0.9219 - recall: 0.5610 - precision: 0.8138 - val_loss: 0.1664 - val_accuracy: 0.9574 - val_auc: 0.9582 - val_recall: 0.7167 - val_precision: 0.7954\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.1108 - accuracy: 0.9655 - auc: 0.9712 - recall: 0.7255 - precision: 0.8775 - val_loss: 0.1071 - val_accuracy: 0.9683 - val_auc: 0.9720 - val_recall: 0.7605 - val_precision: 0.8753\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0924 - accuracy: 0.9729 - auc: 0.9810 - recall: 0.7869 - precision: 0.9054 - val_loss: 0.1032 - val_accuracy: 0.9747 - val_auc: 0.9829 - val_recall: 0.7643 - val_precision: 0.9481\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0808 - accuracy: 0.9778 - auc: 0.9859 - recall: 0.8240 - precision: 0.9264 - val_loss: 0.0988 - val_accuracy: 0.9721 - val_auc: 0.9850 - val_recall: 0.7947 - val_precision: 0.8875\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0767 - accuracy: 0.9804 - auc: 0.9886 - recall: 0.8496 - precision: 0.9306 - val_loss: 0.1099 - val_accuracy: 0.9688 - val_auc: 0.9839 - val_recall: 0.8346 - val_precision: 0.8252\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0687 - accuracy: 0.9836 - auc: 0.9923 - recall: 0.8752 - precision: 0.9422 - val_loss: 0.1115 - val_accuracy: 0.9711 - val_auc: 0.9819 - val_recall: 0.8384 - val_precision: 0.8432\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0647 - accuracy: 0.9857 - auc: 0.9943 - recall: 0.8922 - precision: 0.9489 - val_loss: 0.0955 - val_accuracy: 0.9773 - val_auc: 0.9833 - val_recall: 0.8308 - val_precision: 0.9123\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0618 - accuracy: 0.9866 - auc: 0.9951 - recall: 0.9037 - precision: 0.9479 - val_loss: 0.1028 - val_accuracy: 0.9747 - val_auc: 0.9791 - val_recall: 0.8365 - val_precision: 0.8800\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 32s 19ms/step - loss: 0.0575 - accuracy: 0.9890 - auc: 0.9959 - recall: 0.9251 - precision: 0.9535 - val_loss: 0.1045 - val_accuracy: 0.9761 - val_auc: 0.9845 - val_recall: 0.8498 - val_precision: 0.8834\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0577 - accuracy: 0.9894 - auc: 0.9957 - recall: 0.9279 - precision: 0.9559 - val_loss: 0.1104 - val_accuracy: 0.9723 - val_auc: 0.9849 - val_recall: 0.8631 - val_precision: 0.8376\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0551 - accuracy: 0.9902 - auc: 0.9968 - recall: 0.9365 - precision: 0.9559 - val_loss: 0.2460 - val_accuracy: 0.9430 - val_auc: 0.9741 - val_recall: 0.9144 - val_precision: 0.6288\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0526 - accuracy: 0.9912 - auc: 0.9974 - recall: 0.9396 - precision: 0.9632 - val_loss: 0.1166 - val_accuracy: 0.9742 - val_auc: 0.9719 - val_recall: 0.7490 - val_precision: 0.9586\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0396 - accuracy: 0.9960 - auc: 0.9989 - recall: 0.9719 - precision: 0.9843 - val_loss: 0.0973 - val_accuracy: 0.9806 - val_auc: 0.9838 - val_recall: 0.8612 - val_precision: 0.9207\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0333 - accuracy: 0.9978 - auc: 0.9993 - recall: 0.9870 - precision: 0.9895 - val_loss: 0.1112 - val_accuracy: 0.9808 - val_auc: 0.9795 - val_recall: 0.8631 - val_precision: 0.9209\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0301 - accuracy: 0.9986 - auc: 0.9997 - recall: 0.9920 - precision: 0.9922 - val_loss: 0.1129 - val_accuracy: 0.9815 - val_auc: 0.9744 - val_recall: 0.8688 - val_precision: 0.9232\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0278 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9941 - precision: 0.9937 - val_loss: 0.1215 - val_accuracy: 0.9816 - val_auc: 0.9730 - val_recall: 0.8669 - val_precision: 0.9268\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0268 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9937 - precision: 0.9935 - val_loss: 0.1383 - val_accuracy: 0.9813 - val_auc: 0.9682 - val_recall: 0.8688 - val_precision: 0.9214\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0253 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9983 - precision: 0.9935 - val_loss: 0.1400 - val_accuracy: 0.9816 - val_auc: 0.9649 - val_recall: 0.8631 - val_precision: 0.9303\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0248 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9977 - precision: 0.9956 - val_loss: 0.1439 - val_accuracy: 0.9811 - val_auc: 0.9646 - val_recall: 0.8707 - val_precision: 0.9178\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0246 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9981 - precision: 0.9950 - val_loss: 0.1498 - val_accuracy: 0.9815 - val_auc: 0.9639 - val_recall: 0.8726 - val_precision: 0.9198\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0243 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9979 - precision: 0.9958 - val_loss: 0.1602 - val_accuracy: 0.9813 - val_auc: 0.9611 - val_recall: 0.8669 - val_precision: 0.9231\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0240 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9990 - precision: 0.9958 - val_loss: 0.1659 - val_accuracy: 0.9813 - val_auc: 0.9618 - val_recall: 0.8707 - val_precision: 0.9197\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0239 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9985 - precision: 0.9962 - val_loss: 0.1678 - val_accuracy: 0.9813 - val_auc: 0.9619 - val_recall: 0.8688 - val_precision: 0.9214\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.0958 - accuracy: 0.9766 - auc: 0.9859 - recall: 0.8157 - precision: 0.9076\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set.\n",
    "# predictions_CNN_prob_6 \n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(96, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_6 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 29s 17ms/step - loss: 0.1820 - accuracy: 0.9436 - auc: 0.9062 - recall: 0.5161 - precision: 0.7870 - val_loss: 0.1933 - val_accuracy: 0.9589 - val_auc: 0.9688 - val_recall: 0.6736 - val_precision: 0.8480\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.1162 - accuracy: 0.9647 - auc: 0.9660 - recall: 0.7164 - precision: 0.8704 - val_loss: 0.1910 - val_accuracy: 0.9674 - val_auc: 0.9828 - val_recall: 0.8566 - val_precision: 0.8021\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0971 - accuracy: 0.9713 - auc: 0.9779 - recall: 0.7686 - precision: 0.8989 - val_loss: 0.1558 - val_accuracy: 0.9556 - val_auc: 0.9654 - val_recall: 0.6962 - val_precision: 0.7953\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0847 - accuracy: 0.9759 - auc: 0.9849 - recall: 0.8146 - precision: 0.9094 - val_loss: 0.0968 - val_accuracy: 0.9731 - val_auc: 0.9836 - val_recall: 0.7623 - val_precision: 0.9330\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0794 - accuracy: 0.9796 - auc: 0.9867 - recall: 0.8399 - precision: 0.9282 - val_loss: 0.1193 - val_accuracy: 0.9730 - val_auc: 0.9868 - val_recall: 0.8377 - val_precision: 0.8638\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0709 - accuracy: 0.9826 - auc: 0.9921 - recall: 0.8667 - precision: 0.9359 - val_loss: 0.1211 - val_accuracy: 0.9756 - val_auc: 0.9900 - val_recall: 0.8868 - val_precision: 0.8530\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0655 - accuracy: 0.9850 - auc: 0.9932 - recall: 0.8895 - precision: 0.9414 - val_loss: 0.1748 - val_accuracy: 0.9648 - val_auc: 0.9858 - val_recall: 0.8943 - val_precision: 0.7633\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0639 - accuracy: 0.9858 - auc: 0.9944 - recall: 0.8970 - precision: 0.9427 - val_loss: 0.1090 - val_accuracy: 0.9742 - val_auc: 0.9871 - val_recall: 0.8623 - val_precision: 0.8574\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0597 - accuracy: 0.9874 - auc: 0.9963 - recall: 0.9136 - precision: 0.9449 - val_loss: 0.1074 - val_accuracy: 0.9731 - val_auc: 0.9808 - val_recall: 0.7906 - val_precision: 0.9050\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0414 - accuracy: 0.9949 - auc: 0.9988 - recall: 0.9627 - precision: 0.9801 - val_loss: 0.0890 - val_accuracy: 0.9811 - val_auc: 0.9870 - val_recall: 0.8792 - val_precision: 0.9119\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0329 - accuracy: 0.9972 - auc: 0.9996 - recall: 0.9828 - precision: 0.9867 - val_loss: 0.0992 - val_accuracy: 0.9816 - val_auc: 0.9803 - val_recall: 0.8849 - val_precision: 0.9125\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0291 - accuracy: 0.9984 - auc: 0.9997 - recall: 0.9908 - precision: 0.9913 - val_loss: 0.1220 - val_accuracy: 0.9813 - val_auc: 0.9679 - val_recall: 0.8736 - val_precision: 0.9187\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0271 - accuracy: 0.9987 - auc: 0.9999 - recall: 0.9932 - precision: 0.9923 - val_loss: 0.1309 - val_accuracy: 0.9822 - val_auc: 0.9662 - val_recall: 0.8830 - val_precision: 0.9194\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0257 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9932 - precision: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9816 - val_auc: 0.9675 - val_recall: 0.8792 - val_precision: 0.9173\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0243 - accuracy: 0.9991 - auc: 1.0000 - recall: 0.9957 - precision: 0.9947 - val_loss: 0.1586 - val_accuracy: 0.9820 - val_auc: 0.9630 - val_recall: 0.8811 - val_precision: 0.9193\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0228 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9972 - precision: 0.9970 - val_loss: 0.1606 - val_accuracy: 0.9813 - val_auc: 0.9630 - val_recall: 0.8811 - val_precision: 0.9121\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0228 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9972 - precision: 0.9960 - val_loss: 0.1626 - val_accuracy: 0.9815 - val_auc: 0.9639 - val_recall: 0.8811 - val_precision: 0.9139\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.0223 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9977 - precision: 0.9966 - val_loss: 0.1689 - val_accuracy: 0.9823 - val_auc: 0.9628 - val_recall: 0.8906 - val_precision: 0.9147\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0222 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9987 - precision: 0.9964 - val_loss: 0.1779 - val_accuracy: 0.9818 - val_auc: 0.9630 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0218 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9991 - precision: 0.9964 - val_loss: 0.1863 - val_accuracy: 0.9822 - val_auc: 0.9611 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9991 - precision: 0.9958 - val_loss: 0.1888 - val_accuracy: 0.9818 - val_auc: 0.9603 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9981 - precision: 0.9966 - val_loss: 0.1881 - val_accuracy: 0.9822 - val_auc: 0.9603 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0218 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9991 - precision: 0.9960 - val_loss: 0.1897 - val_accuracy: 0.9818 - val_auc: 0.9611 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 24/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0216 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9991 - precision: 0.9970 - val_loss: 0.1914 - val_accuracy: 0.9822 - val_auc: 0.9603 - val_recall: 0.8849 - val_precision: 0.9178\n",
      "Epoch 25/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0217 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9996 - precision: 0.9968 - val_loss: 0.1942 - val_accuracy: 0.9818 - val_auc: 0.9603 - val_recall: 0.8811 - val_precision: 0.9175\n",
      "Epoch 26/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0216 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9998 - precision: 0.9966 - val_loss: 0.1926 - val_accuracy: 0.9822 - val_auc: 0.9593 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.0849 - accuracy: 0.9816 - auc: 0.9872 - recall: 0.8723 - precision: 0.9236\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. => to submit\n",
    "# predictions_CNN_prob_7\n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_7 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  8.565439e-06\n",
      "1          1  6.351068e-05\n",
      "2          2  2.352402e-05\n",
      "3          3  2.126926e-09\n",
      "4          4  1.668296e-07\n",
      "...      ...           ...\n",
      "30912  30912  1.296144e-04\n",
      "30913  30913  3.701574e-03\n",
      "30914  30914  2.170700e-01\n",
      "30915  30915  8.016825e-06\n",
      "30916  30916  2.035295e-06\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_7[0], \"predictions_CNN_prob_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 30s 17ms/step - loss: 0.2661 - accuracy: 0.9128 - auc: 0.8316 - recall: 0.2470 - precision: 0.5385 - val_loss: 0.2039 - val_accuracy: 0.9463 - val_auc: 0.9604 - val_recall: 0.4736 - val_precision: 0.8901\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.1632 - accuracy: 0.9481 - auc: 0.9397 - recall: 0.5320 - precision: 0.8336 - val_loss: 0.2349 - val_accuracy: 0.9612 - val_auc: 0.9686 - val_recall: 0.7472 - val_precision: 0.8148\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.1337 - accuracy: 0.9596 - auc: 0.9597 - recall: 0.6445 - precision: 0.8759 - val_loss: 0.1656 - val_accuracy: 0.9633 - val_auc: 0.9681 - val_recall: 0.6887 - val_precision: 0.8859\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.1103 - accuracy: 0.9685 - auc: 0.9749 - recall: 0.7243 - precision: 0.9089 - val_loss: 0.2215 - val_accuracy: 0.9702 - val_auc: 0.9795 - val_recall: 0.7887 - val_precision: 0.8745\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.1054 - accuracy: 0.9700 - auc: 0.9789 - recall: 0.7432 - precision: 0.9089 - val_loss: 0.1399 - val_accuracy: 0.9645 - val_auc: 0.9751 - val_recall: 0.6660 - val_precision: 0.9265\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0941 - accuracy: 0.9752 - auc: 0.9843 - recall: 0.7941 - precision: 0.9210 - val_loss: 0.1393 - val_accuracy: 0.9707 - val_auc: 0.9850 - val_recall: 0.7321 - val_precision: 0.9349\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0849 - accuracy: 0.9781 - auc: 0.9886 - recall: 0.8235 - precision: 0.9258 - val_loss: 0.1368 - val_accuracy: 0.9754 - val_auc: 0.9844 - val_recall: 0.8245 - val_precision: 0.8992\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0838 - accuracy: 0.9798 - auc: 0.9893 - recall: 0.8384 - precision: 0.9316 - val_loss: 0.1353 - val_accuracy: 0.9770 - val_auc: 0.9895 - val_recall: 0.8528 - val_precision: 0.8915\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 33s 21ms/step - loss: 0.0771 - accuracy: 0.9818 - auc: 0.9919 - recall: 0.8584 - precision: 0.9346 - val_loss: 0.0935 - val_accuracy: 0.9763 - val_auc: 0.9857 - val_recall: 0.8415 - val_precision: 0.8938\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0733 - accuracy: 0.9837 - auc: 0.9930 - recall: 0.8750 - precision: 0.9405 - val_loss: 0.1120 - val_accuracy: 0.9773 - val_auc: 0.9837 - val_recall: 0.8528 - val_precision: 0.8950\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 35s 21ms/step - loss: 0.0679 - accuracy: 0.9853 - auc: 0.9941 - recall: 0.9067 - precision: 0.9293 - val_loss: 0.1766 - val_accuracy: 0.9543 - val_auc: 0.9579 - val_recall: 0.5264 - val_precision: 0.9555\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0704 - accuracy: 0.9859 - auc: 0.9938 - recall: 0.9102 - precision: 0.9326 - val_loss: 0.1050 - val_accuracy: 0.9735 - val_auc: 0.9881 - val_recall: 0.9038 - val_precision: 0.8244\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0645 - accuracy: 0.9870 - auc: 0.9954 - recall: 0.9176 - precision: 0.9374 - val_loss: 0.1038 - val_accuracy: 0.9754 - val_auc: 0.9855 - val_recall: 0.8038 - val_precision: 0.9181\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0643 - accuracy: 0.9879 - auc: 0.9958 - recall: 0.9189 - precision: 0.9461 - val_loss: 0.1071 - val_accuracy: 0.9745 - val_auc: 0.9791 - val_recall: 0.7925 - val_precision: 0.9190\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0477 - accuracy: 0.9933 - auc: 0.9987 - recall: 0.9606 - precision: 0.9653 - val_loss: 0.0926 - val_accuracy: 0.9802 - val_auc: 0.9869 - val_recall: 0.8792 - val_precision: 0.9031\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0399 - accuracy: 0.9963 - auc: 0.9992 - recall: 0.9804 - precision: 0.9783 - val_loss: 0.0992 - val_accuracy: 0.9811 - val_auc: 0.9828 - val_recall: 0.8811 - val_precision: 0.9103\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0360 - accuracy: 0.9969 - auc: 0.9999 - recall: 0.9855 - precision: 0.9803 - val_loss: 0.1137 - val_accuracy: 0.9799 - val_auc: 0.9806 - val_recall: 0.8887 - val_precision: 0.8920\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0336 - accuracy: 0.9977 - auc: 0.9998 - recall: 0.9902 - precision: 0.9843 - val_loss: 0.1296 - val_accuracy: 0.9809 - val_auc: 0.9767 - val_recall: 0.8925 - val_precision: 0.8992\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0328 - accuracy: 0.9979 - auc: 0.9998 - recall: 0.9898 - precision: 0.9866 - val_loss: 0.1333 - val_accuracy: 0.9801 - val_auc: 0.9733 - val_recall: 0.8849 - val_precision: 0.8967\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0308 - accuracy: 0.9981 - auc: 0.9998 - recall: 0.9949 - precision: 0.9846 - val_loss: 0.1486 - val_accuracy: 0.9813 - val_auc: 0.9663 - val_recall: 0.8830 - val_precision: 0.9105\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0291 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9970 - precision: 0.9903 - val_loss: 0.1512 - val_accuracy: 0.9815 - val_auc: 0.9673 - val_recall: 0.8868 - val_precision: 0.9091\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0288 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9966 - precision: 0.9894 - val_loss: 0.1557 - val_accuracy: 0.9818 - val_auc: 0.9664 - val_recall: 0.8811 - val_precision: 0.9175\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0287 - accuracy: 0.9988 - auc: 1.0000 - recall: 0.9974 - precision: 0.9894 - val_loss: 0.1615 - val_accuracy: 0.9816 - val_auc: 0.9654 - val_recall: 0.8868 - val_precision: 0.9109\n",
      "Epoch 24/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0287 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9979 - precision: 0.9892 - val_loss: 0.1694 - val_accuracy: 0.9813 - val_auc: 0.9635 - val_recall: 0.8811 - val_precision: 0.9121\n",
      "Epoch 25/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0281 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9981 - precision: 0.9901 - val_loss: 0.1731 - val_accuracy: 0.9813 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9073\n",
      "Epoch 26/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0281 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9979 - precision: 0.9903 - val_loss: 0.1740 - val_accuracy: 0.9816 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9109\n",
      "Epoch 27/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0283 - accuracy: 0.9990 - auc: 1.0000 - recall: 0.9977 - precision: 0.9909 - val_loss: 0.1747 - val_accuracy: 0.9815 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9091\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.0861 - accuracy: 0.9828 - auc: 0.9878 - recall: 0.8858 - precision: 0.9247\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_8\n",
    "# normally sampled\n",
    "#  0.99076\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_8 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  9.057642e-07\n",
      "1          1  5.331922e-02\n",
      "2          2  1.952135e-04\n",
      "3          3  2.256034e-07\n",
      "4          4  3.165077e-06\n",
      "...      ...           ...\n",
      "30912  30912  3.877303e-04\n",
      "30913  30913  2.209523e-03\n",
      "30914  30914  2.677908e-01\n",
      "30915  30915  1.394543e-02\n",
      "30916  30916  1.163967e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_8[0], \"predictions_CNN_prob_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 28s 16ms/step - loss: 0.1820 - accuracy: 0.9433 - auc: 0.9088 - recall: 0.4941 - precision: 0.8031 - val_loss: 0.1577 - val_accuracy: 0.9451 - val_auc: 0.9552 - val_recall: 0.4377 - val_precision: 0.9243\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 27s 16ms/step - loss: 0.1187 - accuracy: 0.9649 - auc: 0.9636 - recall: 0.7081 - precision: 0.8808 - val_loss: 0.1085 - val_accuracy: 0.9660 - val_auc: 0.9758 - val_recall: 0.7434 - val_precision: 0.8678\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 28s 17ms/step - loss: 0.0983 - accuracy: 0.9717 - auc: 0.9778 - recall: 0.7701 - precision: 0.9024 - val_loss: 0.0996 - val_accuracy: 0.9655 - val_auc: 0.9836 - val_recall: 0.6660 - val_precision: 0.9413\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.0877 - accuracy: 0.9766 - auc: 0.9833 - recall: 0.8126 - precision: 0.9189 - val_loss: 0.1133 - val_accuracy: 0.9693 - val_auc: 0.9770 - val_recall: 0.7717 - val_precision: 0.8796\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0791 - accuracy: 0.9788 - auc: 0.9883 - recall: 0.8324 - precision: 0.9261 - val_loss: 0.1038 - val_accuracy: 0.9726 - val_auc: 0.9860 - val_recall: 0.8075 - val_precision: 0.8843\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0708 - accuracy: 0.9826 - auc: 0.9927 - recall: 0.8657 - precision: 0.9371 - val_loss: 0.1017 - val_accuracy: 0.9749 - val_auc: 0.9747 - val_recall: 0.8000 - val_precision: 0.9158\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0676 - accuracy: 0.9851 - auc: 0.9932 - recall: 0.8882 - precision: 0.9439 - val_loss: 0.1372 - val_accuracy: 0.9579 - val_auc: 0.9864 - val_recall: 0.9094 - val_precision: 0.7120\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 38s 23ms/step - loss: 0.0627 - accuracy: 0.9871 - auc: 0.9941 - recall: 0.9042 - precision: 0.9507 - val_loss: 0.1030 - val_accuracy: 0.9754 - val_auc: 0.9856 - val_recall: 0.8717 - val_precision: 0.8619\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 41s 25ms/step - loss: 0.0428 - accuracy: 0.9941 - auc: 0.9990 - recall: 0.9585 - precision: 0.9759 - val_loss: 0.0886 - val_accuracy: 0.9835 - val_auc: 0.9858 - val_recall: 0.8962 - val_precision: 0.9223\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0345 - accuracy: 0.9967 - auc: 0.9993 - recall: 0.9785 - precision: 0.9848 - val_loss: 0.0954 - val_accuracy: 0.9839 - val_auc: 0.9824 - val_recall: 0.8925 - val_precision: 0.9293\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0297 - accuracy: 0.9979 - auc: 0.9995 - recall: 0.9851 - precision: 0.9912 - val_loss: 0.1114 - val_accuracy: 0.9830 - val_auc: 0.9779 - val_recall: 0.8981 - val_precision: 0.9154\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0276 - accuracy: 0.9982 - auc: 0.9997 - recall: 0.9896 - precision: 0.9906 - val_loss: 0.1139 - val_accuracy: 0.9837 - val_auc: 0.9723 - val_recall: 0.8868 - val_precision: 0.9325\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 45s 28ms/step - loss: 0.0256 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9932 - precision: 0.9919 - val_loss: 0.1197 - val_accuracy: 0.9841 - val_auc: 0.9687 - val_recall: 0.8774 - val_precision: 0.9451\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0247 - accuracy: 0.9986 - auc: 0.9999 - recall: 0.9921 - precision: 0.9923 - val_loss: 0.1319 - val_accuracy: 0.9830 - val_auc: 0.9649 - val_recall: 0.8792 - val_precision: 0.9320\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 35s 21ms/step - loss: 0.0227 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9966 - precision: 0.9949 - val_loss: 0.1354 - val_accuracy: 0.9835 - val_auc: 0.9642 - val_recall: 0.8811 - val_precision: 0.9359\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0223 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9983 - precision: 0.9958 - val_loss: 0.1410 - val_accuracy: 0.9839 - val_auc: 0.9632 - val_recall: 0.8811 - val_precision: 0.9396\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9979 - precision: 0.9966 - val_loss: 0.1452 - val_accuracy: 0.9832 - val_auc: 0.9640 - val_recall: 0.8849 - val_precision: 0.9287\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 47s 29ms/step - loss: 0.0218 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9985 - precision: 0.9958 - val_loss: 0.1487 - val_accuracy: 0.9841 - val_auc: 0.9632 - val_recall: 0.8849 - val_precision: 0.9380\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0215 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9981 - precision: 0.9966 - val_loss: 0.1547 - val_accuracy: 0.9834 - val_auc: 0.9595 - val_recall: 0.8868 - val_precision: 0.9289\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0213 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9985 - precision: 0.9970 - val_loss: 0.1552 - val_accuracy: 0.9834 - val_auc: 0.9605 - val_recall: 0.8868 - val_precision: 0.9289\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0216 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9974 - precision: 0.9955 - val_loss: 0.1561 - val_accuracy: 0.9835 - val_auc: 0.9586 - val_recall: 0.8868 - val_precision: 0.9307\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 0.0862 - accuracy: 0.9809 - auc: 0.9883 - recall: 0.8881 - precision: 0.9037\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_9\n",
    "# normally sampled\n",
    "#  Kaggle: 0.99249\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_9 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  4.721542e-06\n",
      "1          1  8.080629e-03\n",
      "2          2  3.323448e-07\n",
      "3          3  5.033775e-09\n",
      "4          4  1.272920e-08\n",
      "...      ...           ...\n",
      "30912  30912  2.600307e-05\n",
      "30913  30913  1.119968e-02\n",
      "30914  30914  2.807036e-01\n",
      "30915  30915  9.110881e-10\n",
      "30916  30916  4.104823e-08\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_9[0], \"predictions_CNN_prob_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2954/2954 [==============================] - 63s 21ms/step - loss: 0.2408 - accuracy: 0.9091 - auc: 0.9677 - recall: 0.9155 - precision: 0.9041 - val_loss: 0.1265 - val_accuracy: 0.9596 - val_auc: 0.9703 - val_recall: 0.8000 - val_precision: 0.7786\n",
      "Epoch 2/128\n",
      "2954/2954 [==============================] - 65s 22ms/step - loss: 0.1121 - accuracy: 0.9669 - auc: 0.9932 - recall: 0.9740 - precision: 0.9604 - val_loss: 0.1452 - val_accuracy: 0.9520 - val_auc: 0.9742 - val_recall: 0.8844 - val_precision: 0.6925\n",
      "Epoch 3/128\n",
      "2954/2954 [==============================] - 62s 21ms/step - loss: 0.0858 - accuracy: 0.9791 - auc: 0.9966 - recall: 0.9842 - precision: 0.9744 - val_loss: 0.1323 - val_accuracy: 0.9629 - val_auc: 0.9699 - val_recall: 0.8752 - val_precision: 0.7657\n",
      "Epoch 4/128\n",
      "2954/2954 [==============================] - 56s 19ms/step - loss: 0.0756 - accuracy: 0.9844 - auc: 0.9977 - recall: 0.9878 - precision: 0.9811 - val_loss: 0.1678 - val_accuracy: 0.9555 - val_auc: 0.9773 - val_recall: 0.9046 - val_precision: 0.7063\n",
      "Epoch 5/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0676 - accuracy: 0.9876 - auc: 0.9986 - recall: 0.9904 - precision: 0.9850 - val_loss: 0.1874 - val_accuracy: 0.9586 - val_auc: 0.9765 - val_recall: 0.9009 - val_precision: 0.7263\n",
      "Epoch 6/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0647 - accuracy: 0.9899 - auc: 0.9986 - recall: 0.9922 - precision: 0.9878 - val_loss: 0.1289 - val_accuracy: 0.9738 - val_auc: 0.9729 - val_recall: 0.8477 - val_precision: 0.8717\n",
      "Epoch 7/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0419 - accuracy: 0.9971 - auc: 0.9998 - recall: 0.9982 - precision: 0.9960 - val_loss: 0.1507 - val_accuracy: 0.9792 - val_auc: 0.9625 - val_recall: 0.8624 - val_precision: 0.9126\n",
      "Epoch 8/128\n",
      "2954/2954 [==============================] - 59s 20ms/step - loss: 0.0347 - accuracy: 0.9987 - auc: 0.9999 - recall: 0.9990 - precision: 0.9983 - val_loss: 0.1586 - val_accuracy: 0.9808 - val_auc: 0.9625 - val_recall: 0.8936 - val_precision: 0.9019\n",
      "Epoch 9/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0319 - accuracy: 0.9991 - auc: 1.0000 - recall: 0.9996 - precision: 0.9986 - val_loss: 0.1801 - val_accuracy: 0.9811 - val_auc: 0.9558 - val_recall: 0.8697 - val_precision: 0.9258\n",
      "Epoch 10/128\n",
      "2954/2954 [==============================] - 56s 19ms/step - loss: 0.0297 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.2028 - val_accuracy: 0.9804 - val_auc: 0.9505 - val_recall: 0.8569 - val_precision: 0.9303\n",
      "Epoch 11/128\n",
      "2954/2954 [==============================] - 65s 22ms/step - loss: 0.0286 - accuracy: 0.9993 - auc: 1.0000 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.1881 - val_accuracy: 0.9801 - val_auc: 0.9537 - val_recall: 0.8679 - val_precision: 0.9167\n",
      "Epoch 12/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0271 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1936 - val_accuracy: 0.9797 - val_auc: 0.9521 - val_recall: 0.8569 - val_precision: 0.9229\n",
      "Epoch 13/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0267 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1990 - val_accuracy: 0.9802 - val_auc: 0.9504 - val_recall: 0.8550 - val_precision: 0.9301\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1244 - accuracy: 0.9575 - auc: 0.9731 - recall: 0.8063 - precision: 0.7362\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_10\n",
    "# adasyn sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_10 = model_score(model, x_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.2203 - accuracy: 0.9206 - auc: 0.9730 - recall: 0.9299 - precision: 0.9128 - val_loss: 0.1348 - val_accuracy: 0.9548 - val_auc: 0.9692 - val_recall: 0.7688 - val_precision: 0.7563\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.1031 - accuracy: 0.9718 - auc: 0.9942 - recall: 0.9769 - precision: 0.9670 - val_loss: 0.1425 - val_accuracy: 0.9591 - val_auc: 0.9657 - val_recall: 0.7284 - val_precision: 0.8186\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0822 - accuracy: 0.9811 - auc: 0.9969 - recall: 0.9847 - precision: 0.9777 - val_loss: 0.1169 - val_accuracy: 0.9678 - val_auc: 0.9759 - val_recall: 0.7927 - val_precision: 0.8554\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0707 - accuracy: 0.9869 - auc: 0.9981 - recall: 0.9893 - precision: 0.9846 - val_loss: 0.1204 - val_accuracy: 0.9731 - val_auc: 0.9713 - val_recall: 0.8220 - val_precision: 0.8854\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0670 - accuracy: 0.9883 - auc: 0.9986 - recall: 0.9904 - precision: 0.9863 - val_loss: 0.1262 - val_accuracy: 0.9679 - val_auc: 0.9844 - val_recall: 0.9083 - val_precision: 0.7857\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0627 - accuracy: 0.9907 - auc: 0.9988 - recall: 0.9917 - precision: 0.9897 - val_loss: 0.1139 - val_accuracy: 0.9757 - val_auc: 0.9758 - val_recall: 0.8220 - val_precision: 0.9124\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0599 - accuracy: 0.9917 - auc: 0.9991 - recall: 0.9925 - precision: 0.9910 - val_loss: 0.1413 - val_accuracy: 0.9719 - val_auc: 0.9695 - val_recall: 0.8495 - val_precision: 0.8527\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0580 - accuracy: 0.9925 - auc: 0.9993 - recall: 0.9936 - precision: 0.9915 - val_loss: 0.1476 - val_accuracy: 0.9745 - val_auc: 0.9684 - val_recall: 0.8514 - val_precision: 0.8755\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0560 - accuracy: 0.9935 - auc: 0.9994 - recall: 0.9940 - precision: 0.9930 - val_loss: 0.1426 - val_accuracy: 0.9726 - val_auc: 0.9711 - val_recall: 0.8624 - val_precision: 0.8499\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0560 - accuracy: 0.9937 - auc: 0.9994 - recall: 0.9946 - precision: 0.9929 - val_loss: 0.1717 - val_accuracy: 0.9652 - val_auc: 0.9739 - val_recall: 0.8991 - val_precision: 0.7704\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0540 - accuracy: 0.9944 - auc: 0.9995 - recall: 0.9956 - precision: 0.9932 - val_loss: 0.1651 - val_accuracy: 0.9671 - val_auc: 0.9715 - val_recall: 0.8917 - val_precision: 0.7877\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0415 - accuracy: 0.9983 - auc: 0.9999 - recall: 0.9988 - precision: 0.9978 - val_loss: 0.1730 - val_accuracy: 0.9804 - val_auc: 0.9581 - val_recall: 0.8661 - val_precision: 0.9219\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0369 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9995 - precision: 0.9989 - val_loss: 0.1855 - val_accuracy: 0.9809 - val_auc: 0.9571 - val_recall: 0.8642 - val_precision: 0.9290\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0347 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.1935 - val_accuracy: 0.9801 - val_auc: 0.9563 - val_recall: 0.8716 - val_precision: 0.9135\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0331 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.2230 - val_accuracy: 0.9804 - val_auc: 0.9452 - val_recall: 0.8624 - val_precision: 0.9252\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0318 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.2265 - val_accuracy: 0.9804 - val_auc: 0.9473 - val_recall: 0.8624 - val_precision: 0.9252\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0306 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9999 - precision: 0.9994 - val_loss: 0.2325 - val_accuracy: 0.9799 - val_auc: 0.9465 - val_recall: 0.8514 - val_precision: 0.9299\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0303 - accuracy: 0.9997 - auc: 1.0000 - recall: 1.0000 - precision: 0.9994 - val_loss: 0.2342 - val_accuracy: 0.9804 - val_auc: 0.9448 - val_recall: 0.8569 - val_precision: 0.9303\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1184 - accuracy: 0.9766 - auc: 0.9742 - recall: 0.8339 - precision: 0.8929\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_11\n",
    "# borderline sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_11 = model_score(model, x_train_borderline, y_train_borderline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  8.629061e-08\n",
      "1          1  1.916419e-05\n",
      "2          2  5.860349e-04\n",
      "3          3  2.802911e-07\n",
      "4          4  7.559953e-08\n",
      "...      ...           ...\n",
      "30912  30912  2.332528e-04\n",
      "30913  30913  1.318149e-02\n",
      "30914  30914  1.473697e-01\n",
      "30915  30915  8.662563e-06\n",
      "30916  30916  8.383747e-03\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_11[0], \"predictions_CNN_prob_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 60s 20ms/step - loss: 0.2020 - accuracy: 0.9265 - auc: 0.9775 - recall: 0.9234 - precision: 0.9291 - val_loss: 0.1181 - val_accuracy: 0.9622 - val_auc: 0.9772 - val_recall: 0.8349 - val_precision: 0.7804\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.1017 - accuracy: 0.9701 - auc: 0.9948 - recall: 0.9726 - precision: 0.9677 - val_loss: 0.1255 - val_accuracy: 0.9662 - val_auc: 0.9782 - val_recall: 0.8385 - val_precision: 0.8103\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0837 - accuracy: 0.9798 - auc: 0.9970 - recall: 0.9816 - precision: 0.9781 - val_loss: 0.1262 - val_accuracy: 0.9622 - val_auc: 0.9744 - val_recall: 0.8569 - val_precision: 0.7694\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0753 - accuracy: 0.9840 - auc: 0.9980 - recall: 0.9851 - precision: 0.9830 - val_loss: 0.1249 - val_accuracy: 0.9664 - val_auc: 0.9835 - val_recall: 0.8789 - val_precision: 0.7891\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0708 - accuracy: 0.9868 - auc: 0.9984 - recall: 0.9876 - precision: 0.9860 - val_loss: 0.1125 - val_accuracy: 0.9716 - val_auc: 0.9806 - val_recall: 0.8110 - val_precision: 0.8787\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0663 - accuracy: 0.9893 - auc: 0.9987 - recall: 0.9899 - precision: 0.9887 - val_loss: 0.1274 - val_accuracy: 0.9711 - val_auc: 0.9829 - val_recall: 0.8972 - val_precision: 0.8150\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0626 - accuracy: 0.9907 - auc: 0.9990 - recall: 0.9906 - precision: 0.9907 - val_loss: 0.1134 - val_accuracy: 0.9768 - val_auc: 0.9800 - val_recall: 0.8642 - val_precision: 0.8870\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0604 - accuracy: 0.9916 - auc: 0.9991 - recall: 0.9917 - precision: 0.9914 - val_loss: 0.1231 - val_accuracy: 0.9737 - val_auc: 0.9805 - val_recall: 0.8972 - val_precision: 0.8359\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0573 - accuracy: 0.9928 - auc: 0.9993 - recall: 0.9934 - precision: 0.9922 - val_loss: 0.1543 - val_accuracy: 0.9692 - val_auc: 0.9746 - val_recall: 0.8679 - val_precision: 0.8169\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0568 - accuracy: 0.9929 - auc: 0.9992 - recall: 0.9931 - precision: 0.9927 - val_loss: 0.1282 - val_accuracy: 0.9768 - val_auc: 0.9731 - val_recall: 0.8459 - val_precision: 0.9022\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0417 - accuracy: 0.9980 - auc: 0.9999 - recall: 0.9982 - precision: 0.9977 - val_loss: 0.1360 - val_accuracy: 0.9811 - val_auc: 0.9697 - val_recall: 0.8734 - val_precision: 0.9225\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0369 - accuracy: 0.9990 - auc: 0.9999 - recall: 0.9992 - precision: 0.9987 - val_loss: 0.1653 - val_accuracy: 0.9808 - val_auc: 0.9586 - val_recall: 0.8642 - val_precision: 0.9272\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0344 - accuracy: 0.9993 - auc: 0.9999 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.1869 - val_accuracy: 0.9806 - val_auc: 0.9584 - val_recall: 0.8771 - val_precision: 0.9140\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0327 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.1975 - val_accuracy: 0.9806 - val_auc: 0.9528 - val_recall: 0.8661 - val_precision: 0.9237\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0317 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9991 - val_loss: 0.1996 - val_accuracy: 0.9808 - val_auc: 0.9488 - val_recall: 0.8550 - val_precision: 0.9357\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0304 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9997 - precision: 0.9995 - val_loss: 0.1943 - val_accuracy: 0.9811 - val_auc: 0.9538 - val_recall: 0.8697 - val_precision: 0.9258\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0301 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.1967 - val_accuracy: 0.9809 - val_auc: 0.9538 - val_recall: 0.8697 - val_precision: 0.9240\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1049 - accuracy: 0.9736 - auc: 0.9851 - recall: 0.8157 - precision: 0.8757\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_12\n",
    "# svm sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_12 = model_score(model, x_train_svmsmote, y_train_svmsmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  1.182344e-03\n",
      "1          1  3.673962e-04\n",
      "2          2  1.781049e-05\n",
      "3          3  9.008203e-07\n",
      "4          4  5.624769e-05\n",
      "...      ...           ...\n",
      "30912  30912  3.286622e-03\n",
      "30913  30913  8.990210e-02\n",
      "30914  30914  1.148125e-01\n",
      "30915  30915  2.370128e-05\n",
      "30916  30916  1.280994e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_12[0], \"predictions_CNN_prob_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.2286 - accuracy: 0.9138 - auc: 0.9713 - recall: 0.9092 - precision: 0.9176 - val_loss: 0.3274 - val_accuracy: 0.9007 - val_auc: 0.9711 - val_recall: 0.9321 - val_precision: 0.4866\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.1145 - accuracy: 0.9663 - auc: 0.9932 - recall: 0.9706 - precision: 0.9624 - val_loss: 0.1495 - val_accuracy: 0.9428 - val_auc: 0.9744 - val_recall: 0.8972 - val_precision: 0.6409\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0913 - accuracy: 0.9769 - auc: 0.9963 - recall: 0.9802 - precision: 0.9737 - val_loss: 0.1258 - val_accuracy: 0.9653 - val_auc: 0.9833 - val_recall: 0.8807 - val_precision: 0.7805\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0806 - accuracy: 0.9828 - auc: 0.9976 - recall: 0.9860 - precision: 0.9796 - val_loss: 0.1250 - val_accuracy: 0.9645 - val_auc: 0.9861 - val_recall: 0.9064 - val_precision: 0.7623\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0714 - accuracy: 0.9865 - auc: 0.9984 - recall: 0.9894 - precision: 0.9836 - val_loss: 0.1242 - val_accuracy: 0.9714 - val_auc: 0.9754 - val_recall: 0.8606 - val_precision: 0.8405\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0658 - accuracy: 0.9891 - auc: 0.9988 - recall: 0.9911 - precision: 0.9872 - val_loss: 0.1244 - val_accuracy: 0.9716 - val_auc: 0.9804 - val_recall: 0.8826 - val_precision: 0.8279\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0630 - accuracy: 0.9908 - auc: 0.9989 - recall: 0.9919 - precision: 0.9896 - val_loss: 0.1226 - val_accuracy: 0.9718 - val_auc: 0.9800 - val_recall: 0.9028 - val_precision: 0.8173\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0605 - accuracy: 0.9916 - auc: 0.9991 - recall: 0.9927 - precision: 0.9905 - val_loss: 0.1264 - val_accuracy: 0.9697 - val_auc: 0.9797 - val_recall: 0.9064 - val_precision: 0.7994\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0576 - accuracy: 0.9929 - auc: 0.9993 - recall: 0.9942 - precision: 0.9917 - val_loss: 0.1382 - val_accuracy: 0.9747 - val_auc: 0.9744 - val_recall: 0.8734 - val_precision: 0.8608\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0568 - accuracy: 0.9932 - auc: 0.9994 - recall: 0.9936 - precision: 0.9929 - val_loss: 0.1475 - val_accuracy: 0.9733 - val_auc: 0.9669 - val_recall: 0.8110 - val_precision: 0.8966\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0573 - accuracy: 0.9934 - auc: 0.9993 - recall: 0.9937 - precision: 0.9932 - val_loss: 0.1439 - val_accuracy: 0.9731 - val_auc: 0.9757 - val_recall: 0.8844 - val_precision: 0.8397\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0559 - accuracy: 0.9939 - auc: 0.9994 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.1597 - val_accuracy: 0.9714 - val_auc: 0.9654 - val_recall: 0.7706 - val_precision: 0.9130\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0428 - accuracy: 0.9981 - auc: 0.9999 - recall: 0.9985 - precision: 0.9978 - val_loss: 0.1598 - val_accuracy: 0.9782 - val_auc: 0.9652 - val_recall: 0.8587 - val_precision: 0.9052\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0383 - accuracy: 0.9991 - auc: 0.9999 - recall: 0.9994 - precision: 0.9987 - val_loss: 0.1771 - val_accuracy: 0.9796 - val_auc: 0.9638 - val_recall: 0.8514 - val_precision: 0.9261\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0355 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9992 - val_loss: 0.1960 - val_accuracy: 0.9782 - val_auc: 0.9610 - val_recall: 0.8514 - val_precision: 0.9116\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0341 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9992 - val_loss: 0.2065 - val_accuracy: 0.9811 - val_auc: 0.9585 - val_recall: 0.8716 - val_precision: 0.9241\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0329 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.1847 - val_accuracy: 0.9801 - val_auc: 0.9666 - val_recall: 0.8881 - val_precision: 0.8996\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0317 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1940 - val_accuracy: 0.9801 - val_auc: 0.9644 - val_recall: 0.8697 - val_precision: 0.9151\n",
      "Epoch 19/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0315 - accuracy: 0.9997 - auc: 1.0000 - recall: 1.0000 - precision: 0.9994 - val_loss: 0.1990 - val_accuracy: 0.9802 - val_auc: 0.9608 - val_recall: 0.8734 - val_precision: 0.9136\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1232 - accuracy: 0.9710 - auc: 0.9836 - recall: 0.9071 - precision: 0.7934\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_13\n",
    "# smotetomek sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_13 = model_score(model, x_train_tomek, y_train_tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2887/2887 [==============================] - 65s 22ms/step - loss: 0.2112 - accuracy: 0.9214 - auc: 0.9754 - recall: 0.9210 - precision: 0.9247 - val_loss: 0.1558 - val_accuracy: 0.9470 - val_auc: 0.9699 - val_recall: 0.8422 - val_precision: 0.6760\n",
      "Epoch 2/128\n",
      "2887/2887 [==============================] - 71s 24ms/step - loss: 0.0980 - accuracy: 0.9716 - auc: 0.9951 - recall: 0.9749 - precision: 0.9696 - val_loss: 0.1846 - val_accuracy: 0.9359 - val_auc: 0.9777 - val_recall: 0.9193 - val_precision: 0.6058\n",
      "Epoch 3/128\n",
      "2887/2887 [==============================] - 79s 27ms/step - loss: 0.0740 - accuracy: 0.9828 - auc: 0.9977 - recall: 0.9846 - precision: 0.9816 - val_loss: 0.2008 - val_accuracy: 0.9468 - val_auc: 0.9780 - val_recall: 0.9138 - val_precision: 0.6570\n",
      "Epoch 4/128\n",
      "2887/2887 [==============================] - 79s 28ms/step - loss: 0.0642 - accuracy: 0.9877 - auc: 0.9986 - recall: 0.9895 - precision: 0.9864 - val_loss: 0.1761 - val_accuracy: 0.9673 - val_auc: 0.9728 - val_recall: 0.8991 - val_precision: 0.7853\n",
      "Epoch 5/128\n",
      "2887/2887 [==============================] - 77s 27ms/step - loss: 0.0603 - accuracy: 0.9903 - auc: 0.9989 - recall: 0.9914 - precision: 0.9896 - val_loss: 0.1573 - val_accuracy: 0.9683 - val_auc: 0.9727 - val_recall: 0.8789 - val_precision: 0.8037\n",
      "Epoch 6/128\n",
      "2887/2887 [==============================] - 79s 27ms/step - loss: 0.0553 - accuracy: 0.9926 - auc: 0.9992 - recall: 0.9934 - precision: 0.9920 - val_loss: 0.2116 - val_accuracy: 0.9615 - val_auc: 0.9505 - val_recall: 0.8073 - val_precision: 0.7899\n",
      "Epoch 7/128\n",
      "2887/2887 [==============================] - 78s 27ms/step - loss: 0.0392 - accuracy: 0.9979 - auc: 0.9998 - recall: 0.9982 - precision: 0.9977 - val_loss: 0.1738 - val_accuracy: 0.9738 - val_auc: 0.9733 - val_recall: 0.8991 - val_precision: 0.8362\n",
      "Epoch 8/128\n",
      "2887/2887 [==============================] - 89s 31ms/step - loss: 0.0315 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9996 - precision: 0.9995 - val_loss: 0.2049 - val_accuracy: 0.9740 - val_auc: 0.9622 - val_recall: 0.8881 - val_precision: 0.8447\n",
      "Epoch 9/128\n",
      "2887/2887 [==============================] - 80s 28ms/step - loss: 0.0290 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.2154 - val_accuracy: 0.9733 - val_auc: 0.9574 - val_recall: 0.8789 - val_precision: 0.8448\n",
      "Epoch 10/128\n",
      "2887/2887 [==============================] - 80s 28ms/step - loss: 0.0269 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9998 - precision: 0.9997 - val_loss: 0.2415 - val_accuracy: 0.9740 - val_auc: 0.9568 - val_recall: 0.8881 - val_precision: 0.8447\n",
      "Epoch 11/128\n",
      "2887/2887 [==============================] - 69s 24ms/step - loss: 0.0252 - accuracy: 0.9998 - auc: 1.0000 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2547 - val_accuracy: 0.9738 - val_auc: 0.9547 - val_recall: 0.8826 - val_precision: 0.8468\n",
      "Epoch 12/128\n",
      "2887/2887 [==============================] - 62s 21ms/step - loss: 0.0240 - accuracy: 0.9999 - auc: 1.0000 - recall: 0.9999 - precision: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9747 - val_auc: 0.9502 - val_recall: 0.8826 - val_precision: 0.8544\n",
      "Epoch 13/128\n",
      "2887/2887 [==============================] - 58s 20ms/step - loss: 0.0237 - accuracy: 0.9999 - auc: 1.0000 - recall: 1.0000 - precision: 0.9999 - val_loss: 0.2668 - val_accuracy: 0.9742 - val_auc: 0.9502 - val_recall: 0.8844 - val_precision: 0.8486\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.1468 - accuracy: 0.9509 - auc: 0.9728 - recall: 0.8598 - precision: 0.6732\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_14\n",
    "# smoteen sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_14 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 90s 30ms/step - loss: 0.2235 - accuracy: 0.9153 - auc: 0.9727 - recall: 0.9169 - precision: 0.9140 - val_loss: 0.1617 - val_accuracy: 0.9563 - val_auc: 0.9795 - val_recall: 0.8734 - val_precision: 0.7223\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 82s 28ms/step - loss: 0.1070 - accuracy: 0.9695 - auc: 0.9940 - recall: 0.9779 - precision: 0.9619 - val_loss: 0.1793 - val_accuracy: 0.9534 - val_auc: 0.9851 - val_recall: 0.9450 - val_precision: 0.6830\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0812 - accuracy: 0.9809 - auc: 0.9972 - recall: 0.9862 - precision: 0.9758 - val_loss: 0.1336 - val_accuracy: 0.9619 - val_auc: 0.9846 - val_recall: 0.9119 - val_precision: 0.7429\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0710 - accuracy: 0.9864 - auc: 0.9982 - recall: 0.9893 - precision: 0.9835 - val_loss: 0.2116 - val_accuracy: 0.9508 - val_auc: 0.9807 - val_recall: 0.9358 - val_precision: 0.6719\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0668 - accuracy: 0.9890 - auc: 0.9986 - recall: 0.9920 - precision: 0.9860 - val_loss: 0.1391 - val_accuracy: 0.9631 - val_auc: 0.9846 - val_recall: 0.9211 - val_precision: 0.7470\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 68s 23ms/step - loss: 0.0627 - accuracy: 0.9908 - auc: 0.9989 - recall: 0.9928 - precision: 0.9888 - val_loss: 0.1424 - val_accuracy: 0.9700 - val_auc: 0.9767 - val_recall: 0.9229 - val_precision: 0.7934\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 69s 23ms/step - loss: 0.0596 - accuracy: 0.9926 - auc: 0.9991 - recall: 0.9943 - precision: 0.9910 - val_loss: 0.1418 - val_accuracy: 0.9714 - val_auc: 0.9762 - val_recall: 0.9101 - val_precision: 0.8105\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0606 - accuracy: 0.9924 - auc: 0.9991 - recall: 0.9941 - precision: 0.9907 - val_loss: 0.1420 - val_accuracy: 0.9764 - val_auc: 0.9702 - val_recall: 0.8991 - val_precision: 0.8581\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0420 - accuracy: 0.9985 - auc: 0.9999 - recall: 0.9996 - precision: 0.9974 - val_loss: 0.1722 - val_accuracy: 0.9816 - val_auc: 0.9586 - val_recall: 0.8734 - val_precision: 0.9279\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0374 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9997 - precision: 0.9990 - val_loss: 0.1856 - val_accuracy: 0.9806 - val_auc: 0.9530 - val_recall: 0.8642 - val_precision: 0.9253\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 62s 21ms/step - loss: 0.0348 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9997 - precision: 0.9991 - val_loss: 0.2047 - val_accuracy: 0.9799 - val_auc: 0.9478 - val_recall: 0.8532 - val_precision: 0.9281\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0328 - accuracy: 0.9995 - auc: 0.9999 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.1782 - val_accuracy: 0.9799 - val_auc: 0.9593 - val_recall: 0.8606 - val_precision: 0.9214\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0304 - accuracy: 0.9995 - auc: 0.9999 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.1842 - val_accuracy: 0.9808 - val_auc: 0.9489 - val_recall: 0.8532 - val_precision: 0.9375\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0292 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.1825 - val_accuracy: 0.9816 - val_auc: 0.9499 - val_recall: 0.8550 - val_precision: 0.9452\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0288 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9999 - precision: 0.9995 - val_loss: 0.1888 - val_accuracy: 0.9811 - val_auc: 0.9490 - val_recall: 0.8495 - val_precision: 0.9449\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 12ms/step - loss: 0.1329 - accuracy: 0.9622 - auc: 0.9865 - recall: 0.9134 - precision: 0.7268\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_15\n",
    "# random oversampled\n",
    "# \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_15 = model_score(model, x_train_oversam, y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Predicted\n",
      "0          0   0.000044\n",
      "1          1   0.000160\n",
      "2          2   0.027587\n",
      "3          3   0.000024\n",
      "4          4   0.003521\n",
      "...      ...        ...\n",
      "30912  30912   0.000028\n",
      "30913  30913   0.584994\n",
      "30914  30914   0.227613\n",
      "30915  30915   0.002541\n",
      "30916  30916   0.000012\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_15[0], \"predictions_CNN_prob_15_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 44s 14ms/step - loss: 0.2382 - accuracy: 0.9068 - auc: 0.9682 - recall: 0.9054 - precision: 0.9079 - val_loss: 0.1268 - val_accuracy: 0.9496 - val_auc: 0.9761 - val_recall: 0.8569 - val_precision: 0.6868\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 45s 15ms/step - loss: 0.1081 - accuracy: 0.9664 - auc: 0.9935 - recall: 0.9739 - precision: 0.9596 - val_loss: 0.1956 - val_accuracy: 0.9295 - val_auc: 0.9840 - val_recall: 0.9560 - val_precision: 0.5763\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 49s 16ms/step - loss: 0.0794 - accuracy: 0.9800 - auc: 0.9970 - recall: 0.9846 - precision: 0.9756 - val_loss: 0.1842 - val_accuracy: 0.9466 - val_auc: 0.9782 - val_recall: 0.9193 - val_precision: 0.6549\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 53s 18ms/step - loss: 0.0696 - accuracy: 0.9852 - auc: 0.9981 - recall: 0.9899 - precision: 0.9807 - val_loss: 0.1266 - val_accuracy: 0.9721 - val_auc: 0.9811 - val_recall: 0.9211 - val_precision: 0.8097\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 53s 18ms/step - loss: 0.0632 - accuracy: 0.9887 - auc: 0.9988 - recall: 0.9914 - precision: 0.9860 - val_loss: 0.1351 - val_accuracy: 0.9693 - val_auc: 0.9862 - val_recall: 0.9248 - val_precision: 0.7875\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 68s 23ms/step - loss: 0.0591 - accuracy: 0.9911 - auc: 0.9990 - recall: 0.9931 - precision: 0.9892 - val_loss: 0.1141 - val_accuracy: 0.9752 - val_auc: 0.9831 - val_recall: 0.8936 - val_precision: 0.8514\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 62s 21ms/step - loss: 0.0564 - accuracy: 0.9929 - auc: 0.9992 - recall: 0.9941 - precision: 0.9917 - val_loss: 0.1542 - val_accuracy: 0.9690 - val_auc: 0.9812 - val_recall: 0.9156 - val_precision: 0.7896\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0554 - accuracy: 0.9936 - auc: 0.9993 - recall: 0.9950 - precision: 0.9922 - val_loss: 0.1270 - val_accuracy: 0.9777 - val_auc: 0.9808 - val_recall: 0.9138 - val_precision: 0.8586\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 66s 22ms/step - loss: 0.0544 - accuracy: 0.9938 - auc: 0.9994 - recall: 0.9950 - precision: 0.9927 - val_loss: 0.1286 - val_accuracy: 0.9759 - val_auc: 0.9774 - val_recall: 0.8679 - val_precision: 0.8759\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0518 - accuracy: 0.9951 - auc: 0.9995 - recall: 0.9963 - precision: 0.9939 - val_loss: 0.1427 - val_accuracy: 0.9777 - val_auc: 0.9714 - val_recall: 0.9028 - val_precision: 0.8662\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 66s 22ms/step - loss: 0.0535 - accuracy: 0.9948 - auc: 0.9994 - recall: 0.9959 - precision: 0.9936 - val_loss: 0.1395 - val_accuracy: 0.9783 - val_auc: 0.9693 - val_recall: 0.8679 - val_precision: 0.8992\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0414 - accuracy: 0.9987 - auc: 0.9998 - recall: 0.9995 - precision: 0.9979 - val_loss: 0.1633 - val_accuracy: 0.9806 - val_auc: 0.9584 - val_recall: 0.8624 - val_precision: 0.9270\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 69s 23ms/step - loss: 0.0368 - accuracy: 0.9996 - auc: 0.9999 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.2036 - val_accuracy: 0.9804 - val_auc: 0.9461 - val_recall: 0.8514 - val_precision: 0.9355\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0345 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.2028 - val_accuracy: 0.9808 - val_auc: 0.9495 - val_recall: 0.8624 - val_precision: 0.9289\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0321 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.2135 - val_accuracy: 0.9804 - val_auc: 0.9513 - val_recall: 0.8642 - val_precision: 0.9235\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0302 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.2205 - val_accuracy: 0.9804 - val_auc: 0.9449 - val_recall: 0.8514 - val_precision: 0.9355\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0288 - accuracy: 0.9998 - auc: 1.0000 - recall: 1.0000 - precision: 0.9996 - val_loss: 0.2232 - val_accuracy: 0.9808 - val_auc: 0.9458 - val_recall: 0.8550 - val_precision: 0.9357\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0285 - accuracy: 0.9998 - auc: 1.0000 - recall: 0.9999 - precision: 0.9996 - val_loss: 0.2274 - val_accuracy: 0.9806 - val_auc: 0.9440 - val_recall: 0.8550 - val_precision: 0.9339\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1079 - accuracy: 0.9777 - auc: 0.9843 - recall: 0.9008 - precision: 0.8537\n"
     ]
    }
   ],
   "source": [
    "# 4-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_16\n",
    "# random over sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_16 = model_score(model, x_train_oversam, y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  1.243785e-11\n",
      "1          1  6.365884e-06\n",
      "2          2  9.675701e-10\n",
      "3          3  4.006355e-08\n",
      "4          4  1.434304e-04\n",
      "...      ...           ...\n",
      "30912  30912  1.194210e-06\n",
      "30913  30913  2.830749e-05\n",
      "30914  30914  5.575607e-01\n",
      "30915  30915  3.342547e-06\n",
      "30916  30916  1.045959e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_16[0], \"predictions_CNN_prob_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 34s 20ms/step - loss: 0.1737 - accuracy: 0.9439 - auc: 0.9111 - recall: 0.5144 - precision: 0.7992 - val_loss: 0.1902 - val_accuracy: 0.9387 - val_auc: 0.9436 - val_recall: 0.3743 - val_precision: 0.9401\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 35s 21ms/step - loss: 0.1084 - accuracy: 0.9639 - auc: 0.9653 - recall: 0.7063 - precision: 0.8742 - val_loss: 0.1138 - val_accuracy: 0.9579 - val_auc: 0.9661 - val_recall: 0.5817 - val_precision: 0.9548\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0842 - accuracy: 0.9719 - auc: 0.9785 - recall: 0.7793 - precision: 0.9001 - val_loss: 0.0912 - val_accuracy: 0.9695 - val_auc: 0.9778 - val_recall: 0.7468 - val_precision: 0.9146\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0692 - accuracy: 0.9764 - auc: 0.9853 - recall: 0.8164 - precision: 0.9164 - val_loss: 0.1081 - val_accuracy: 0.9674 - val_auc: 0.9755 - val_recall: 0.8220 - val_precision: 0.8312\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0583 - accuracy: 0.9804 - auc: 0.9893 - recall: 0.8471 - precision: 0.9318 - val_loss: 0.0750 - val_accuracy: 0.9777 - val_auc: 0.9825 - val_recall: 0.8110 - val_precision: 0.9444\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0501 - accuracy: 0.9843 - auc: 0.9915 - recall: 0.8830 - precision: 0.9420 - val_loss: 0.0846 - val_accuracy: 0.9709 - val_auc: 0.9834 - val_recall: 0.8275 - val_precision: 0.8590\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0434 - accuracy: 0.9856 - auc: 0.9944 - recall: 0.8935 - precision: 0.9458 - val_loss: 0.0797 - val_accuracy: 0.9778 - val_auc: 0.9851 - val_recall: 0.8697 - val_precision: 0.8927\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0375 - accuracy: 0.9883 - auc: 0.9962 - recall: 0.9144 - precision: 0.9557 - val_loss: 0.1016 - val_accuracy: 0.9751 - val_auc: 0.9686 - val_recall: 0.8330 - val_precision: 0.8955\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0340 - accuracy: 0.9895 - auc: 0.9963 - recall: 0.9230 - precision: 0.9607 - val_loss: 0.1102 - val_accuracy: 0.9685 - val_auc: 0.9790 - val_recall: 0.8991 - val_precision: 0.7942\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0326 - accuracy: 0.9909 - auc: 0.9970 - recall: 0.9382 - precision: 0.9609 - val_loss: 0.0874 - val_accuracy: 0.9806 - val_auc: 0.9704 - val_recall: 0.8514 - val_precision: 0.9374\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0166 - accuracy: 0.9965 - auc: 0.9990 - recall: 0.9758 - precision: 0.9853 - val_loss: 0.0848 - val_accuracy: 0.9808 - val_auc: 0.9795 - val_recall: 0.8844 - val_precision: 0.9094\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0113 - accuracy: 0.9981 - auc: 0.9996 - recall: 0.9892 - precision: 0.9897 - val_loss: 0.1054 - val_accuracy: 0.9820 - val_auc: 0.9698 - val_recall: 0.8881 - val_precision: 0.9184\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0097 - accuracy: 0.9986 - auc: 0.9998 - recall: 0.9916 - precision: 0.9932 - val_loss: 0.1266 - val_accuracy: 0.9816 - val_auc: 0.9638 - val_recall: 0.8697 - val_precision: 0.9312\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0086 - accuracy: 0.9988 - auc: 1.0000 - recall: 0.9933 - precision: 0.9937 - val_loss: 0.1351 - val_accuracy: 0.9828 - val_auc: 0.9611 - val_recall: 0.8789 - val_precision: 0.9355\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0081 - accuracy: 0.9991 - auc: 0.9999 - recall: 0.9949 - precision: 0.9951 - val_loss: 0.1484 - val_accuracy: 0.9822 - val_auc: 0.9619 - val_recall: 0.8807 - val_precision: 0.9266\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0078 - accuracy: 0.9994 - auc: 0.9998 - recall: 0.9973 - precision: 0.9958 - val_loss: 0.1487 - val_accuracy: 0.9830 - val_auc: 0.9618 - val_recall: 0.8862 - val_precision: 0.9306\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0069 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9983 - precision: 0.9964 - val_loss: 0.1488 - val_accuracy: 0.9825 - val_auc: 0.9616 - val_recall: 0.8862 - val_precision: 0.9253\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 12ms/step - loss: 0.0683 - accuracy: 0.9769 - auc: 0.9875 - recall: 0.8016 - precision: 0.9263\n"
     ]
    }
   ],
   "source": [
    "# CNN model 17\n",
    "# 5 layer CNN\n",
    "# Normally Sampled\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_17 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  1.504792e-07\n",
      "1          1  1.609468e-03\n",
      "2          2  7.392058e-04\n",
      "3          3  6.585059e-07\n",
      "4          4  2.530175e-05\n",
      "...      ...           ...\n",
      "30912  30912  6.021515e-03\n",
      "30913  30913  2.532866e-02\n",
      "30914  30914  6.700584e-02\n",
      "30915  30915  2.512855e-04\n",
      "30916  30916  3.985780e-06\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_17[0], \"predictions_CNN_prob_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 36s 21ms/step - loss: 0.2069 - accuracy: 0.9327 - auc: 0.8844 - recall: 0.4113 - precision: 0.7346 - val_loss: 0.1286 - val_accuracy: 0.9556 - val_auc: 0.9617 - val_recall: 0.5908 - val_precision: 0.9070\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 38s 23ms/step - loss: 0.1221 - accuracy: 0.9611 - auc: 0.9591 - recall: 0.6880 - precision: 0.8576 - val_loss: 0.2117 - val_accuracy: 0.9650 - val_auc: 0.9742 - val_recall: 0.7339 - val_precision: 0.8753\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0951 - accuracy: 0.9696 - auc: 0.9736 - recall: 0.7487 - precision: 0.9015 - val_loss: 0.1211 - val_accuracy: 0.9581 - val_auc: 0.9791 - val_recall: 0.5615 - val_precision: 0.9903\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0804 - accuracy: 0.9736 - auc: 0.9814 - recall: 0.7866 - precision: 0.9120 - val_loss: 0.1094 - val_accuracy: 0.9586 - val_auc: 0.9797 - val_recall: 0.5908 - val_precision: 0.9527\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0724 - accuracy: 0.9761 - auc: 0.9851 - recall: 0.8187 - precision: 0.9111 - val_loss: 0.1002 - val_accuracy: 0.9700 - val_auc: 0.9833 - val_recall: 0.7119 - val_precision: 0.9604\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 38s 23ms/step - loss: 0.0609 - accuracy: 0.9807 - auc: 0.9898 - recall: 0.8511 - precision: 0.9319 - val_loss: 0.1177 - val_accuracy: 0.9648 - val_auc: 0.9825 - val_recall: 0.6349 - val_precision: 0.9886\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0599 - accuracy: 0.9814 - auc: 0.9905 - recall: 0.8573 - precision: 0.9339 - val_loss: 0.1241 - val_accuracy: 0.9707 - val_auc: 0.9840 - val_recall: 0.8606 - val_precision: 0.8345\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 42s 26ms/step - loss: 0.0498 - accuracy: 0.9856 - auc: 0.9928 - recall: 0.8921 - precision: 0.9476 - val_loss: 0.1001 - val_accuracy: 0.9780 - val_auc: 0.9868 - val_recall: 0.8367 - val_precision: 0.9231\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0423 - accuracy: 0.9864 - auc: 0.9951 - recall: 0.8971 - precision: 0.9513 - val_loss: 0.0972 - val_accuracy: 0.9702 - val_auc: 0.9747 - val_recall: 0.7083 - val_precision: 0.9674\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 41s 25ms/step - loss: 0.0417 - accuracy: 0.9879 - auc: 0.9951 - recall: 0.9159 - precision: 0.9495 - val_loss: 0.0882 - val_accuracy: 0.9768 - val_auc: 0.9823 - val_recall: 0.7835 - val_precision: 0.9639\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 44s 27ms/step - loss: 0.0378 - accuracy: 0.9884 - auc: 0.9967 - recall: 0.9136 - precision: 0.9576 - val_loss: 0.0866 - val_accuracy: 0.9782 - val_auc: 0.9849 - val_recall: 0.8697 - val_precision: 0.8960\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 42s 26ms/step - loss: 0.0379 - accuracy: 0.9897 - auc: 0.9965 - recall: 0.9264 - precision: 0.9590 - val_loss: 0.1070 - val_accuracy: 0.9735 - val_auc: 0.9778 - val_recall: 0.7303 - val_precision: 0.9851\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 43s 27ms/step - loss: 0.0325 - accuracy: 0.9915 - auc: 0.9975 - recall: 0.9437 - precision: 0.9620 - val_loss: 0.0966 - val_accuracy: 0.9764 - val_auc: 0.9770 - val_recall: 0.8165 - val_precision: 0.9252\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 45s 28ms/step - loss: 0.0337 - accuracy: 0.9914 - auc: 0.9971 - recall: 0.9403 - precision: 0.9647 - val_loss: 0.1723 - val_accuracy: 0.9711 - val_auc: 0.9492 - val_recall: 0.7064 - val_precision: 0.9821\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 46s 28ms/step - loss: 0.0308 - accuracy: 0.9921 - auc: 0.9976 - recall: 0.9511 - precision: 0.9620 - val_loss: 0.1007 - val_accuracy: 0.9806 - val_auc: 0.9786 - val_recall: 0.8257 - val_precision: 0.9636\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0312 - accuracy: 0.9921 - auc: 0.9980 - recall: 0.9437 - precision: 0.9693 - val_loss: 0.0804 - val_accuracy: 0.9809 - val_auc: 0.9845 - val_recall: 0.8312 - val_precision: 0.9618\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 43s 27ms/step - loss: 0.0288 - accuracy: 0.9932 - auc: 0.9977 - recall: 0.9540 - precision: 0.9714 - val_loss: 0.0775 - val_accuracy: 0.9799 - val_auc: 0.9854 - val_recall: 0.8972 - val_precision: 0.8907\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0243 - accuracy: 0.9945 - auc: 0.9987 - recall: 0.9654 - precision: 0.9743 - val_loss: 0.0889 - val_accuracy: 0.9804 - val_auc: 0.9774 - val_recall: 0.8440 - val_precision: 0.9426\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 49s 30ms/step - loss: 0.0274 - accuracy: 0.9940 - auc: 0.9980 - recall: 0.9595 - precision: 0.9745 - val_loss: 0.1055 - val_accuracy: 0.9730 - val_auc: 0.9726 - val_recall: 0.7284 - val_precision: 0.9802\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 43s 27ms/step - loss: 0.0256 - accuracy: 0.9943 - auc: 0.9988 - recall: 0.9682 - precision: 0.9694 - val_loss: 0.1169 - val_accuracy: 0.9664 - val_auc: 0.9819 - val_recall: 0.9028 - val_precision: 0.7773\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0255 - accuracy: 0.9947 - auc: 0.9985 - recall: 0.9671 - precision: 0.9749 - val_loss: 0.0894 - val_accuracy: 0.9778 - val_auc: 0.9784 - val_recall: 0.8514 - val_precision: 0.9080\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 44s 27ms/step - loss: 0.0255 - accuracy: 0.9942 - auc: 0.9985 - recall: 0.9709 - precision: 0.9662 - val_loss: 0.0978 - val_accuracy: 0.9785 - val_auc: 0.9766 - val_recall: 0.8716 - val_precision: 0.8979\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 42s 26ms/step - loss: 0.0182 - accuracy: 0.9972 - auc: 0.9991 - recall: 0.9846 - precision: 0.9848 - val_loss: 0.1030 - val_accuracy: 0.9816 - val_auc: 0.9721 - val_recall: 0.8569 - val_precision: 0.9434\n",
      "Epoch 24/128\n",
      "1624/1624 [==============================] - 42s 26ms/step - loss: 0.0141 - accuracy: 0.9982 - auc: 0.9996 - recall: 0.9901 - precision: 0.9907 - val_loss: 0.1163 - val_accuracy: 0.9820 - val_auc: 0.9706 - val_recall: 0.8587 - val_precision: 0.9455\n",
      "Epoch 25/128\n",
      "1624/1624 [==============================] - 45s 28ms/step - loss: 0.0122 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9941 - precision: 0.9918 - val_loss: 0.1449 - val_accuracy: 0.9818 - val_auc: 0.9646 - val_recall: 0.8587 - val_precision: 0.9435\n",
      "Epoch 26/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0119 - accuracy: 0.9989 - auc: 0.9997 - recall: 0.9947 - precision: 0.9935 - val_loss: 0.1413 - val_accuracy: 0.9825 - val_auc: 0.9646 - val_recall: 0.8679 - val_precision: 0.9422\n",
      "Epoch 27/128\n",
      "1624/1624 [==============================] - 53s 33ms/step - loss: 0.0115 - accuracy: 0.9990 - auc: 1.0000 - recall: 0.9968 - precision: 0.9927 - val_loss: 0.1385 - val_accuracy: 0.9813 - val_auc: 0.9655 - val_recall: 0.8716 - val_precision: 0.9259\n",
      "Epoch 28/128\n",
      "1624/1624 [==============================] - 41s 25ms/step - loss: 0.0108 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9987 - precision: 0.9943 - val_loss: 0.1506 - val_accuracy: 0.9820 - val_auc: 0.9639 - val_recall: 0.8661 - val_precision: 0.9384\n",
      "Epoch 29/128\n",
      "1624/1624 [==============================] - 44s 27ms/step - loss: 0.0107 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9985 - precision: 0.9950 - val_loss: 0.1549 - val_accuracy: 0.9825 - val_auc: 0.9621 - val_recall: 0.8716 - val_precision: 0.9387\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.0725 - accuracy: 0.9796 - auc: 0.9873 - recall: 0.8953 - precision: 0.8753\n"
     ]
    }
   ],
   "source": [
    "# CNN model 18\n",
    "# 5 layer CNN\n",
    "# Normally Sampled\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_19 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Predicted\n",
      "0          0   0.000036\n",
      "1          1   0.004224\n",
      "2          2   0.012739\n",
      "3          3   0.000304\n",
      "4          4   0.000064\n",
      "...      ...        ...\n",
      "30912  30912   0.006777\n",
      "30913  30913   0.011279\n",
      "30914  30914   0.257418\n",
      "30915  30915   0.000593\n",
      "30916  30916   0.038625\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_19[0], \"predictions_CNN_prob_19_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 6\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20,random_state=RANDOM_STATE)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size=0.10,random_state=RANDOM_STATE)\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255\n",
    "x_test= x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1620/1620 [==============================] - 31s 18ms/step - loss: 0.1783 - accuracy: 0.9409 - auc: 0.9066 - recall: 0.5073 - precision: 0.7562 - val_loss: 0.1178 - val_accuracy: 0.9597 - val_auc: 0.9617 - val_recall: 0.7710 - val_precision: 0.7741\n",
      "Epoch 2/128\n",
      "1620/1620 [==============================] - 33s 20ms/step - loss: 0.1165 - accuracy: 0.9613 - auc: 0.9609 - recall: 0.7189 - precision: 0.8285 - val_loss: 0.1100 - val_accuracy: 0.9640 - val_auc: 0.9643 - val_recall: 0.8200 - val_precision: 0.7846\n",
      "Epoch 3/128\n",
      "1620/1620 [==============================] - 33s 20ms/step - loss: 0.0952 - accuracy: 0.9679 - auc: 0.9748 - recall: 0.7541 - precision: 0.8725 - val_loss: 0.1009 - val_accuracy: 0.9660 - val_auc: 0.9704 - val_recall: 0.7984 - val_precision: 0.8144\n",
      "Epoch 4/128\n",
      "1620/1620 [==============================] - 35s 21ms/step - loss: 0.0768 - accuracy: 0.9749 - auc: 0.9821 - recall: 0.8152 - precision: 0.8963 - val_loss: 0.1062 - val_accuracy: 0.9621 - val_auc: 0.9770 - val_recall: 0.8043 - val_precision: 0.7769\n",
      "Epoch 5/128\n",
      "1620/1620 [==============================] - 34s 21ms/step - loss: 0.0673 - accuracy: 0.9784 - auc: 0.9866 - recall: 0.8422 - precision: 0.9112 - val_loss: 0.1162 - val_accuracy: 0.9700 - val_auc: 0.9498 - val_recall: 0.7299 - val_precision: 0.9142\n",
      "Epoch 6/128\n",
      "1620/1620 [==============================] - 34s 21ms/step - loss: 0.0567 - accuracy: 0.9821 - auc: 0.9906 - recall: 0.8664 - precision: 0.9296 - val_loss: 0.1317 - val_accuracy: 0.9588 - val_auc: 0.9556 - val_recall: 0.7495 - val_precision: 0.7785\n",
      "Epoch 7/128\n",
      "1620/1620 [==============================] - 35s 21ms/step - loss: 0.0508 - accuracy: 0.9841 - auc: 0.9920 - recall: 0.8842 - precision: 0.9360 - val_loss: 0.0907 - val_accuracy: 0.9715 - val_auc: 0.9782 - val_recall: 0.8200 - val_precision: 0.8534\n",
      "Epoch 8/128\n",
      "1620/1620 [==============================] - 35s 22ms/step - loss: 0.0443 - accuracy: 0.9862 - auc: 0.9942 - recall: 0.9052 - precision: 0.9397 - val_loss: 0.0821 - val_accuracy: 0.9743 - val_auc: 0.9781 - val_recall: 0.8180 - val_precision: 0.8837\n",
      "Epoch 9/128\n",
      "1620/1620 [==============================] - 36s 22ms/step - loss: 0.0414 - accuracy: 0.9876 - auc: 0.9945 - recall: 0.9125 - precision: 0.9483 - val_loss: 0.0921 - val_accuracy: 0.9738 - val_auc: 0.9706 - val_recall: 0.7710 - val_precision: 0.9206\n",
      "Epoch 10/128\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.0358 - accuracy: 0.9896 - auc: 0.9965 - recall: 0.9282 - precision: 0.9550 - val_loss: 0.0911 - val_accuracy: 0.9734 - val_auc: 0.9737 - val_recall: 0.7945 - val_precision: 0.8943\n",
      "Epoch 11/128\n",
      "1620/1620 [==============================] - 36s 22ms/step - loss: 0.0366 - accuracy: 0.9894 - auc: 0.9964 - recall: 0.9232 - precision: 0.9571 - val_loss: 0.0945 - val_accuracy: 0.9760 - val_auc: 0.9745 - val_recall: 0.8043 - val_precision: 0.9154\n",
      "Epoch 12/128\n",
      "1620/1620 [==============================] - 38s 23ms/step - loss: 0.0336 - accuracy: 0.9905 - auc: 0.9970 - recall: 0.9320 - precision: 0.9613 - val_loss: 0.0946 - val_accuracy: 0.9771 - val_auc: 0.9679 - val_recall: 0.8219 - val_precision: 0.9111\n",
      "Epoch 13/128\n",
      "1620/1620 [==============================] - 38s 24ms/step - loss: 0.0304 - accuracy: 0.9924 - auc: 0.9973 - recall: 0.9455 - precision: 0.9690 - val_loss: 0.1016 - val_accuracy: 0.9708 - val_auc: 0.9708 - val_recall: 0.7965 - val_precision: 0.8641\n",
      "Epoch 14/128\n",
      "1620/1620 [==============================] - 38s 24ms/step - loss: 0.0190 - accuracy: 0.9961 - auc: 0.9995 - recall: 0.9687 - precision: 0.9873 - val_loss: 0.1012 - val_accuracy: 0.9790 - val_auc: 0.9692 - val_recall: 0.8474 - val_precision: 0.9097\n",
      "Epoch 15/128\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.0140 - accuracy: 0.9978 - auc: 0.9997 - recall: 0.9833 - precision: 0.9922 - val_loss: 0.1158 - val_accuracy: 0.9799 - val_auc: 0.9603 - val_recall: 0.8513 - val_precision: 0.9158\n",
      "Epoch 16/128\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.0113 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9904 - precision: 0.9950 - val_loss: 0.1366 - val_accuracy: 0.9802 - val_auc: 0.9491 - val_recall: 0.8532 - val_precision: 0.9179\n",
      "Epoch 17/128\n",
      "1620/1620 [==============================] - 37s 23ms/step - loss: 0.0109 - accuracy: 0.9988 - auc: 1.0000 - recall: 0.9927 - precision: 0.9942 - val_loss: 0.1501 - val_accuracy: 0.9788 - val_auc: 0.9407 - val_recall: 0.8200 - val_precision: 0.9332\n",
      "Epoch 18/128\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.0096 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9951 - precision: 0.9957 - val_loss: 0.1572 - val_accuracy: 0.9804 - val_auc: 0.9441 - val_recall: 0.8474 - val_precision: 0.9252\n",
      "Epoch 19/128\n",
      "1620/1620 [==============================] - 40s 24ms/step - loss: 0.0089 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9955 - precision: 0.9979 - val_loss: 0.1608 - val_accuracy: 0.9807 - val_auc: 0.9441 - val_recall: 0.8493 - val_precision: 0.9274\n",
      "Epoch 20/128\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.0087 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9961 - precision: 0.9979 - val_loss: 0.1660 - val_accuracy: 0.9802 - val_auc: 0.9433 - val_recall: 0.8454 - val_precision: 0.9251\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.0781 - accuracy: 0.9783 - auc: 0.9794 - recall: 0.8556 - precision: 0.9022\n"
     ]
    }
   ],
   "source": [
    "# CNN model 20\n",
    "# 5 layer CNN\n",
    "# Normally Sampled\n",
    "record3 ={}\n",
    "\n",
    "for i in range(60,61):\n",
    "    RANDOM_STATE = i\n",
    "    x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20,random_state=RANDOM_STATE)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size=0.10,random_state=RANDOM_STATE)\n",
    "    x_train = x_train/255\n",
    "    x_val = x_val/255\n",
    "    x_test= x_test/255\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.000001), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "        layers.Dropout(0.6, seed=RANDOM_STATE),\n",
    "        #layers.Dense(128, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "        #layers.Dense(32, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "        #layers.Dense(16, activation='relu', kernel_regularizer=l2(0.000001)),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model_CNN_20 = model_score(model, x_train, y_train)\n",
    "    record3[RANDOM_STATE] = model_CNN_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 [0.08285435289144516, 0.9775601029396057, 0.9773394465446472, 0.8039215803146362, 0.9335154891014099]\n",
      "46 [0.07353801280260086, 0.9790884852409363, 0.9865972399711609, 0.8555984497070312, 0.9067103266716003]\n",
      "47 [0.07375148683786392, 0.9784632325172424, 0.9823421239852905, 0.8491008877754211, 0.9027431607246399]\n",
      "48 [0.07212630659341812, 0.9765179753303528, 0.9848204255104065, 0.8209069967269897, 0.9104859232902527]\n",
      "49 [0.07011471688747406, 0.9797832369804382, 0.9829973578453064, 0.8502758145332336, 0.9144067764282227]\n",
      "50 [0.07773926854133606, 0.9770042896270752, 0.9819326996803284, 0.8342007398605347, 0.9121951460838318]\n",
      "51 [0.0708058550953865, 0.978671669960022, 0.9833319187164307, 0.8588235378265381, 0.8960720300674438]\n",
      "52 [0.07138154655694962, 0.9731137752532959, 0.9874613881111145, 0.8018433451652527, 0.8900255560874939]\n",
      "53 [0.08558155596256256, 0.9751285314559937, 0.9839478731155396, 0.8449731469154358, 0.8758949637413025]\n",
      "54 [0.07688213884830475, 0.9754064083099365, 0.9828990697860718, 0.8467375040054321, 0.8801261782646179]\n",
      "55 [0.07893358916044235, 0.9741559028625488, 0.9813746213912964, 0.7650189995765686, 0.9410664439201355]\n",
      "56 [0.07825099676847458, 0.9788801074028015, 0.9830412864685059, 0.8652967810630798, 0.8995253443717957]\n",
      "57 [0.07184413820505142, 0.9773516654968262, 0.9854053854942322, 0.8366064429283142, 0.9002535939216614]\n",
      "58 [0.07240155339241028, 0.9781158566474915, 0.9843016862869263, 0.858144998550415, 0.8922204375267029]\n",
      "59 [0.06990085542201996, 0.9788801074028015, 0.9868019223213196, 0.8593155741691589, 0.9047237634658813]\n"
     ]
    }
   ],
   "source": [
    "for i,j in record3.items():\n",
    "    print(i, j[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = record3[42][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x20eab74bc70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  3.439843e-07\n",
      "1          1  6.308306e-02\n",
      "2          2  6.886108e-03\n",
      "3          3  6.125866e-05\n",
      "4          4  3.270529e-05\n",
      "...      ...           ...\n",
      "30912  30912  3.924706e-05\n",
      "30913  30913  1.913464e-05\n",
      "30914  30914  4.567312e-02\n",
      "30915  30915  7.807380e-05\n",
      "30916  30916  7.442135e-07\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model, \"predictions_CNN_prob_42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x20dbea78be0>,\n",
       " <keras.callbacks.History at 0x20db8d88250>,\n",
       " [0.07020298391580582,\n",
       "  0.978324294090271,\n",
       "  0.9851251244544983,\n",
       "  0.8885519504547119,\n",
       "  0.8765893578529358]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_to_csv(model_CNN_20[0], \"predictions_CNN_prob_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1443/1443 [==============================] - 27s 18ms/step - loss: 0.2865 - accuracy: 0.9114 - auc: 0.6964 - recall: 0.0551 - precision: 0.6705 - val_loss: 0.2606 - val_accuracy: 0.9179 - val_auc: 0.7582 - val_recall: 0.1430 - val_precision: 0.7784\n",
      "Epoch 2/128\n",
      "1443/1443 [==============================] - 25s 17ms/step - loss: 0.2508 - accuracy: 0.9214 - auc: 0.7710 - recall: 0.2203 - precision: 0.7259 - val_loss: 0.2435 - val_accuracy: 0.9220 - val_auc: 0.7862 - val_recall: 0.2652 - val_precision: 0.6931\n",
      "Epoch 3/128\n",
      "1443/1443 [==============================] - 29s 20ms/step - loss: 0.2395 - accuracy: 0.9251 - auc: 0.7915 - recall: 0.2665 - precision: 0.7498 - val_loss: 0.2837 - val_accuracy: 0.8982 - val_auc: 0.7946 - val_recall: 0.4214 - val_precision: 0.4410\n",
      "Epoch 4/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2344 - accuracy: 0.9261 - auc: 0.8055 - recall: 0.2964 - precision: 0.7331 - val_loss: 0.2363 - val_accuracy: 0.9198 - val_auc: 0.8206 - val_recall: 0.4148 - val_precision: 0.5871\n",
      "Epoch 5/128\n",
      "1443/1443 [==============================] - 32s 22ms/step - loss: 0.2300 - accuracy: 0.9277 - auc: 0.8157 - recall: 0.3183 - precision: 0.7402 - val_loss: 0.2392 - val_accuracy: 0.9232 - val_auc: 0.8149 - val_recall: 0.3958 - val_precision: 0.6267\n",
      "Epoch 6/128\n",
      "1443/1443 [==============================] - 32s 22ms/step - loss: 0.2278 - accuracy: 0.9288 - auc: 0.8195 - recall: 0.3321 - precision: 0.7455 - val_loss: 0.2311 - val_accuracy: 0.9270 - val_auc: 0.8352 - val_recall: 0.3258 - val_precision: 0.7257\n",
      "Epoch 7/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2242 - accuracy: 0.9295 - auc: 0.8278 - recall: 0.3435 - precision: 0.7456 - val_loss: 0.2291 - val_accuracy: 0.9288 - val_auc: 0.8293 - val_recall: 0.4129 - val_precision: 0.6834\n",
      "Epoch 8/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2196 - accuracy: 0.9313 - auc: 0.8373 - recall: 0.3489 - precision: 0.7730 - val_loss: 0.2179 - val_accuracy: 0.9301 - val_auc: 0.8460 - val_recall: 0.3381 - val_precision: 0.7677\n",
      "Epoch 9/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2162 - accuracy: 0.9329 - auc: 0.8422 - recall: 0.3729 - precision: 0.7733 - val_loss: 0.2218 - val_accuracy: 0.9300 - val_auc: 0.8425 - val_recall: 0.3703 - val_precision: 0.7322\n",
      "Epoch 10/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2142 - accuracy: 0.9329 - auc: 0.8480 - recall: 0.3779 - precision: 0.7670 - val_loss: 0.2153 - val_accuracy: 0.9322 - val_auc: 0.8521 - val_recall: 0.3286 - val_precision: 0.8262\n",
      "Epoch 11/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2114 - accuracy: 0.9337 - auc: 0.8545 - recall: 0.3758 - precision: 0.7842 - val_loss: 0.2191 - val_accuracy: 0.9299 - val_auc: 0.8497 - val_recall: 0.3741 - val_precision: 0.7274\n",
      "Epoch 12/128\n",
      "1443/1443 [==============================] - 31s 22ms/step - loss: 0.2080 - accuracy: 0.9342 - auc: 0.8606 - recall: 0.3958 - precision: 0.7705 - val_loss: 0.2116 - val_accuracy: 0.9336 - val_auc: 0.8549 - val_recall: 0.3523 - val_precision: 0.8194\n",
      "Epoch 13/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2073 - accuracy: 0.9343 - auc: 0.8650 - recall: 0.4019 - precision: 0.7655 - val_loss: 0.2135 - val_accuracy: 0.9313 - val_auc: 0.8629 - val_recall: 0.4242 - val_precision: 0.7077\n",
      "Epoch 14/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2046 - accuracy: 0.9349 - auc: 0.8706 - recall: 0.3910 - precision: 0.7878 - val_loss: 0.2107 - val_accuracy: 0.9326 - val_auc: 0.8652 - val_recall: 0.3731 - val_precision: 0.7725\n",
      "Epoch 15/128\n",
      "1443/1443 [==============================] - 34s 23ms/step - loss: 0.2053 - accuracy: 0.9348 - auc: 0.8695 - recall: 0.3953 - precision: 0.7804 - val_loss: 0.2080 - val_accuracy: 0.9337 - val_auc: 0.8654 - val_recall: 0.3816 - val_precision: 0.7825\n",
      "Epoch 16/128\n",
      "1440/1443 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9348 - auc: 0.8742 - recall: 0.4045 - precision: 0.7711"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21024/3072215185.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     20\u001b[0m     datagen.flow(x_train_r, y_train, batch_size=32,\n\u001b[0;32m     21\u001b[0m     subset='training'),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## With Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.2)\n",
    "\n",
    "\n",
    "x_train_r = layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,))(x_train)\n",
    "x_train_r.shape\n",
    "\n",
    "datagen.fit(x_train_r)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train_r, y_train, batch_size=32,\n",
    "    subset='training'),\n",
    "    validation_data=datagen.flow(x_train_r, y_train,\n",
    "    batch_size=8, subset='validation'), \n",
    "    epochs= 128, \n",
    "    batch_size = 64, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('label', axis=1)\n",
    "y = ds.label.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 99.95%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.999676     0.998091  0.999532      0.998884      0.999532\n",
      "recall         0.999809     0.996759  0.999532      0.998284      0.999532\n",
      "f1-score       0.999743     0.997425  0.999532      0.998584      0.999532\n",
      "support    52465.000000  5246.000000  0.999532  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52455    10]\n",
      " [   17  5229]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.9999868619636735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(xgb, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 97.14%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.974667     0.930210  0.971444      0.952439      0.970625\n",
      "recall         0.994434     0.741616  0.971444      0.868025      0.971444\n",
      "f1-score       0.984452     0.825276  0.971444      0.904864      0.969977\n",
      "support    13116.000000  1312.000000  0.971444  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13043    73]\n",
      " [  339   973]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.9858884942706356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(xgb, x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv(\"test.csv\")\n",
    "Id = test_ds['Id'][:]\n",
    "test_ds = test_ds.drop(\"Id\", axis=1)\n",
    "test_ds = test_ds/255\n",
    "\n",
    "y_pred_proba = xgb.predict_proba(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  2.899778e-06\n",
      "1          1  2.501287e-11\n",
      "2          2  5.768883e-17\n",
      "3          3  3.866564e-25\n",
      "4          4  7.860897e-16\n",
      "...      ...           ...\n",
      "30912  30912  5.064118e-09\n",
      "30913  30913  3.525026e-05\n",
      "30914  30914  3.110209e-02\n",
      "30915  30915  1.194052e-16\n",
      "30916  30916  1.857667e-12\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({'Id':Id.values, 'Predicted':pred.flatten()}, columns=['Id', 'Predicted'])\n",
    "print(pred_df)\n",
    "pred_df.to_csv('predictions_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=400, Accuracy: 97.519%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.000, n=399, Accuracy: 97.449%, F1-score: 0.843, ROC_AUC: 0.989\n",
      "Thresh=0.000, n=398, Accuracy: 97.449%, F1-score: 0.843, ROC_AUC: 0.988\n",
      "Thresh=0.000, n=397, Accuracy: 97.415%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=396, Accuracy: 97.540%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=395, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=394, Accuracy: 97.463%, F1-score: 0.844, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=393, Accuracy: 97.533%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=392, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=391, Accuracy: 97.526%, F1-score: 0.847, ROC_AUC: 0.990\n",
      "Thresh=0.001, n=390, Accuracy: 97.456%, F1-score: 0.844, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=389, Accuracy: 97.422%, F1-score: 0.841, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=388, Accuracy: 97.436%, F1-score: 0.841, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=387, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=386, Accuracy: 97.540%, F1-score: 0.850, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=385, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=384, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=383, Accuracy: 97.318%, F1-score: 0.834, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=382, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=381, Accuracy: 97.352%, F1-score: 0.836, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=380, Accuracy: 97.366%, F1-score: 0.837, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=379, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=378, Accuracy: 97.345%, F1-score: 0.836, ROC_AUC: 0.986\n",
      "Thresh=0.001, n=377, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=376, Accuracy: 97.387%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=375, Accuracy: 97.332%, F1-score: 0.834, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=374, Accuracy: 97.401%, F1-score: 0.839, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=373, Accuracy: 97.422%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=372, Accuracy: 97.477%, F1-score: 0.845, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=371, Accuracy: 97.304%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=370, Accuracy: 97.512%, F1-score: 0.847, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=369, Accuracy: 97.463%, F1-score: 0.844, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=368, Accuracy: 97.470%, F1-score: 0.844, ROC_AUC: 0.986\n",
      "Thresh=0.001, n=367, Accuracy: 97.345%, F1-score: 0.836, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=366, Accuracy: 97.394%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=365, Accuracy: 97.394%, F1-score: 0.839, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=364, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=363, Accuracy: 97.366%, F1-score: 0.837, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=362, Accuracy: 97.429%, F1-score: 0.842, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=361, Accuracy: 97.422%, F1-score: 0.840, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=360, Accuracy: 97.311%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=359, Accuracy: 97.429%, F1-score: 0.841, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=358, Accuracy: 97.449%, F1-score: 0.842, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=357, Accuracy: 97.290%, F1-score: 0.833, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=356, Accuracy: 97.325%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=355, Accuracy: 97.415%, F1-score: 0.841, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=354, Accuracy: 97.366%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=353, Accuracy: 97.380%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=352, Accuracy: 97.442%, F1-score: 0.842, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=351, Accuracy: 97.526%, F1-score: 0.848, ROC_AUC: 0.986\n"
     ]
    }
   ],
   "source": [
    "thresholds = sort(xgb.feature_importances_)\n",
    "store = {}\n",
    "\n",
    "for thresh in thresholds[:50]:\n",
    "    selection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "    select_x_train = selection.transform(x_train)\n",
    "    selection_model = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    selection_model.fit(select_x_train, y_train)\n",
    "    select_x_test = selection.transform(x_test)\n",
    "    predictions = selection_model.predict(select_x_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test,predictions)\n",
    "    n = select_x_train.shape[1]\n",
    "    roc_auc = roc_auc_score(y_test, selection_model.predict_proba(select_x_test)[:, 1])\n",
    "    store[n] = {\"Threshold\": thresh, \"Accuracy\": accuracy, \"F1-Score\": f1, \"ROC_AUC\": roc_auc, \"Model\": selection_model, \"Selection\": selection}\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.3f%%, F1-score: %.3f, ROC_AUC: %.3f\" % (thresh, n , accuracy*100.0, f1, roc_auc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_re = pd.DataFrame(store).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "      <th>Selection</th>\n",
       "      <th>Accuracy\\t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.975187</td>\n",
       "      <td>0.847530</td>\n",
       "      <td>0.988013</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.975187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.974494</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.988947</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.974494</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.988064</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.974147</td>\n",
       "      <td>0.840394</td>\n",
       "      <td>0.987188</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.975395</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  Accuracy  F1-Score   ROC_AUC  \\\n",
       "400   0.000397  0.975187  0.847530  0.988013   \n",
       "399   0.000409  0.974494  0.842601  0.988947   \n",
       "398   0.000420  0.974494  0.843137  0.988064   \n",
       "397   0.000437  0.974147  0.840394  0.987188   \n",
       "396   0.000511  0.975395  0.848485  0.988470   \n",
       "\n",
       "                                                 Model  \\\n",
       "400  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "399  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "398  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "397  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "396  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "\n",
       "                                             Selection  Accuracy\\t  \n",
       "400  SelectFromModel(estimator=XGBClassifier(base_s...    0.975187  \n",
       "399  SelectFromModel(estimator=XGBClassifier(base_s...    0.974494  \n",
       "398  SelectFromModel(estimator=XGBClassifier(base_s...    0.974494  \n",
       "397  SelectFromModel(estimator=XGBClassifier(base_s...    0.974147  \n",
       "396  SelectFromModel(estimator=XGBClassifier(base_s...    0.975395  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_re['ROC_AUC'] =pd.to_numeric(thresh_re['ROC_AUC'])\n",
    "thresh_re['Threshold'] =pd.to_numeric(thresh_re['Threshold'])\n",
    "thresh_re['Accuracy'] =pd.to_numeric(thresh_re['Accuracy'])\n",
    "thresh_re['F1-Score'] =pd.to_numeric(thresh_re['F1-Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Threshold                                              0.000511\n",
       "Accuracy                                               0.975395\n",
       "F1-Score                                               0.848485\n",
       "ROC_AUC                                                 0.98847\n",
       "Model         XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "Selection     SelectFromModel(estimator=XGBClassifier(base_s...\n",
       "Accuracy\\t                                             0.975395\n",
       "Name: 396, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thresh = thresh_re.loc[thresh_re['Accuracy'].idxmax()]\n",
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_select = store[391][\"Selection\"]\n",
    "best_model = store[391][\"Model\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegModel = LogisticRegression(max_iter=10000)\n",
    "logRegModel = LogisticRegression(max_iter=10000)\n",
    "logRegModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926878     0.749506  0.922216      0.838192      0.910755\n",
      "recall         0.992757     0.216737  0.922216      0.604747      0.922216\n",
      "f1-score       0.958687     0.336241  0.922216      0.647464      0.902106\n",
      "support    52465.000000  5246.000000  0.922216  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52085   380]\n",
      " [ 4109  1137]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8274844486306594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(logRegModel, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926524     0.756098  0.922165      0.841311      0.911026\n",
      "recall         0.993138     0.212652  0.922165      0.602895      0.922165\n",
      "f1-score       0.958675     0.331945  0.922165      0.645310      0.901684\n",
      "support    13116.000000  1312.000000  0.922165  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13026    90]\n",
      " [ 1033   279]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8031492500781023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(logRegModel, x_test ,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(loss='hinge', max_iter=1000000)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVM = LinearSVC(loss='hinge', dual=True,max_iter=1000000)\n",
    "linearSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0       1  accuracy     macro avg  weighted avg\n",
      "precision      0.909099     0.0  0.909099      0.454549      0.826461\n",
      "recall         1.000000     0.0  0.909099      0.500000      0.909099\n",
      "f1-score       0.952385     0.0  0.909099      0.476193      0.865812\n",
      "support    52465.000000  5246.0  0.909099  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52465     0]\n",
      " [ 5246     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(linearSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0       1  accuracy     macro avg  weighted avg\n",
      "precision      0.909066     0.0  0.909066      0.454533      0.826400\n",
      "recall         1.000000     0.0  0.909066      0.500000      0.909066\n",
      "f1-score       0.952367     0.0  0.909066      0.476184      0.865764\n",
      "support    13116.000000  1312.0  0.909066  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13116     0]\n",
      " [ 1312     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(linearSVM, x_test, y_test, auc=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel SVM¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomialSVM = SVC(kernel=\"poly\")\n",
    "polynomialSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 98.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.989074     0.98961  0.989118      0.989342      0.989123\n",
      "recall         0.999066     0.88963  0.989118      0.944348      0.989118\n",
      "f1-score       0.994045     0.93696  0.989118      0.965503      0.988856\n",
      "support    52465.000000  5246.00000  0.989118  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52416    49]\n",
      " [  579  4667]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(polynomialSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 97.32%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.976066     0.937618  0.973246      0.956842      0.972570\n",
      "recall         0.994968     0.756098  0.973246      0.875533      0.973246\n",
      "f1-score       0.985426     0.837131  0.973246      0.911279      0.971941\n",
      "support    13116.000000  1312.000000  0.973246  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13050    66]\n",
      " [  320   992]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(polynomialSVM, x_test, y_test, auc=False)                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Kernel SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rbfSVM = SVC(kernel=\"rbf\")\n",
    "rbfSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 98.06%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.980985     0.976460  0.980645      0.978722      0.980573\n",
      "recall         0.998056     0.806519  0.980645      0.902288      0.980645\n",
      "f1-score       0.989447     0.883391  0.980645      0.936419      0.979806\n",
      "support    52465.000000  5246.000000  0.980645  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52363   102]\n",
      " [ 1015  4231]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(rbfSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 96.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.971918     0.932203  0.969157      0.952061      0.968307\n",
      "recall         0.994815     0.712652  0.969157      0.853734      0.969157\n",
      "f1-score       0.983233     0.807775  0.969157      0.895504      0.967278\n",
      "support    13116.000000  1312.000000  0.969157  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13048    68]\n",
      " [  377   935]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(rbfSVM, x_test, y_test, auc=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100,random_state=0)\n",
    "ada.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.24%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926147     0.771631  0.922372      0.848889      0.912101\n",
      "recall         0.993863     0.207396  0.922372      0.600629      0.922372\n",
      "f1-score       0.958811     0.326923  0.922372      0.642867      0.901371\n",
      "support    52465.000000  5246.000000  0.922372  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52143   322]\n",
      " [ 4158  1088]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8768183054992383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(ada, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.09%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.925702     0.735537  0.920918      0.830620      0.908410\n",
      "recall         0.992681     0.203506  0.920918      0.598093      0.920918\n",
      "f1-score       0.958022     0.318806  0.920918      0.638414      0.899895\n",
      "support    13116.000000  1312.000000  0.920918  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13020    96]\n",
      " [ 1045   267]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8529957708514643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(ada, x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = tf.keras.Sequential([\n",
    "    #layers.InputLayer(input_shape=(None,), dtype=\"float\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "812/812 [==============================] - 7s 8ms/step - loss: 0.1121 - accuracy: 0.9625 - auc: 0.9639 - val_loss: 0.1125 - val_accuracy: 0.9550 - val_auc: 0.9710\n",
      "Epoch 2/128\n",
      "812/812 [==============================] - 9s 12ms/step - loss: 0.1083 - accuracy: 0.9643 - auc: 0.9656 - val_loss: 0.1085 - val_accuracy: 0.9589 - val_auc: 0.9686\n",
      "Epoch 3/128\n",
      "812/812 [==============================] - 10s 12ms/step - loss: 0.1112 - accuracy: 0.9642 - auc: 0.9635 - val_loss: 0.1123 - val_accuracy: 0.9582 - val_auc: 0.9728\n",
      "Epoch 4/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1070 - accuracy: 0.9641 - auc: 0.9682 - val_loss: 0.1250 - val_accuracy: 0.9581 - val_auc: 0.9691\n",
      "Epoch 5/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1052 - accuracy: 0.9649 - auc: 0.9685 - val_loss: 0.1040 - val_accuracy: 0.9641 - val_auc: 0.9698\n",
      "Epoch 6/128\n",
      "812/812 [==============================] - 11s 14ms/step - loss: 0.1055 - accuracy: 0.9648 - auc: 0.9680 - val_loss: 0.1064 - val_accuracy: 0.9591 - val_auc: 0.9750\n",
      "Epoch 7/128\n",
      "812/812 [==============================] - 13s 16ms/step - loss: 0.1003 - accuracy: 0.9658 - auc: 0.9707 - val_loss: 0.1035 - val_accuracy: 0.9666 - val_auc: 0.9725\n",
      "Epoch 8/128\n",
      "812/812 [==============================] - 12s 15ms/step - loss: 0.1056 - accuracy: 0.9645 - auc: 0.9696 - val_loss: 0.0985 - val_accuracy: 0.9648 - val_auc: 0.9747\n",
      "Epoch 9/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1021 - accuracy: 0.9670 - auc: 0.9698 - val_loss: 0.0965 - val_accuracy: 0.9650 - val_auc: 0.9747\n",
      "Epoch 10/128\n",
      "812/812 [==============================] - 12s 14ms/step - loss: 0.0994 - accuracy: 0.9666 - auc: 0.9724 - val_loss: 0.0979 - val_accuracy: 0.9634 - val_auc: 0.9759\n",
      "Epoch 11/128\n",
      "812/812 [==============================] - 15s 18ms/step - loss: 0.0955 - accuracy: 0.9677 - auc: 0.9741 - val_loss: 0.0962 - val_accuracy: 0.9652 - val_auc: 0.9786\n",
      "Epoch 12/128\n",
      "812/812 [==============================] - 12s 15ms/step - loss: 0.0989 - accuracy: 0.9675 - auc: 0.9704 - val_loss: 0.0990 - val_accuracy: 0.9652 - val_auc: 0.9772\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 128\n",
    "\n",
    "history = nn_model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9582 - auc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "score = nn_model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv(\"test.csv\")\n",
    "Id = test_ds['Id'][:]\n",
    "test_ds = test_ds.drop(\"Id\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB with 391 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform = best_select.transform(test_ds)\n",
    "predictions = best_model.predict(test_transform)\n",
    "predict_to_csv(best_model, test_transform,\"predictions_xgb_391\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB with all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_to_csv(xgb,test_ds,\"predictions_xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_to_csv(nn_model,test_ds,\"prediction_nn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"predictions_xgb_391.csv\")\n",
    "b = pd.read_csv(\"prediction_nn1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a.Predicted - b.Predicted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c61f45fa4287766d1fe49b974af5d77a1d3358a56f5db6d660bceae78d85026e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gpuEnv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
