{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT4012 Kaggle Competition\n",
    "\n",
    "Author: Loh Hong Tak Edmund\n",
    "\n",
    "Python Version: 3.8.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plan:\n",
    "\n",
    "- EDA\n",
    "- Train-Test Split\n",
    "- Oversampling \n",
    "    - SMOTE-EN\n",
    "    - ADASYN\n",
    "    - BorderlineSMOTE\n",
    "    - SVMSMOTE\n",
    "- Neural Networks\n",
    "    - Vanila NN\n",
    "    - CNN (3 layer)\n",
    "    - CNN (5 layer)\n",
    "- Ensemble Methods\n",
    "    - XGBoost\n",
    "    - RandomForest\n",
    "    - Logistic Regression\n",
    "    - MNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.4.2-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\edmun\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\edmun\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Packages\n",
    "\n",
    "# EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, log_loss, roc_auc_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Settings\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRFEfeatures(model, x, y, n_features_to_select):\n",
    "    rfe = RFE(model, n_features_to_select)\n",
    "    rfe = rfe.fit(x,y)\n",
    "    selected_features = list(x.columns[rfe.support_])\n",
    "    print('Selected features: %s' % selected_features)\n",
    "    return selected_features\n",
    "\n",
    "def get_auc(model, x, y):\n",
    "    y_pred_proba = model.predict_proba(x)[:,1]\n",
    "    [fpr, tpr, thr] = roc_curve(y, y_pred_proba)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "def get_logloss(model, x, y):\n",
    "    y_pred_proba = model.predict_proba(x)[:,1]\n",
    "    return log_loss(y, y_pred_proba)\n",
    "\n",
    "def print_train_score(model, x_train, y_train, auc=True):\n",
    "    pred = model.predict(x_train)\n",
    "    model_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "    print(\"TRAIN RESULT:\\n================================================\")\n",
    "    print(f\"ACCURACY SCORE: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{model_report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CONFUSION MATRIX: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "    if auc:\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"AUC Score: \\n {get_auc(model, x_train, y_train)}\\n\")\n",
    "    \n",
    "def print_test_score(model, x_test, y_test, auc=True):\n",
    "    pred = model.predict(x_test)\n",
    "    model_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "    print(\"TEST RESULT:\\n================================================\")\n",
    "    print(f\"ACCURACY SCORE: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{model_report}\")\n",
    "    print(\"_______________________________________________\")\n",
    "    print(f\"CONFUSION MATRIX: \\n {confusion_matrix(y_test, pred)}\\n\")\n",
    "    if auc:\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"AUC Score: \\n {get_auc(model, x_test, y_test)}\\n\")\n",
    "\n",
    "def predict_to_csv(model,ds,name):\n",
    "    pred = model.predict(ds)\n",
    "    pred_df = pd.DataFrame({'Id':Id, 'Predicted':pred}, columns=['Id', 'Predicted'])\n",
    "    pred_df.to_csv('%s.csv'%(name), index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0c0</th>\n",
       "      <th>r0c1</th>\n",
       "      <th>r0c2</th>\n",
       "      <th>r0c3</th>\n",
       "      <th>r0c4</th>\n",
       "      <th>r0c5</th>\n",
       "      <th>r0c6</th>\n",
       "      <th>r0c7</th>\n",
       "      <th>r0c8</th>\n",
       "      <th>r0c9</th>\n",
       "      <th>...</th>\n",
       "      <th>r19c11</th>\n",
       "      <th>r19c12</th>\n",
       "      <th>r19c13</th>\n",
       "      <th>r19c14</th>\n",
       "      <th>r19c15</th>\n",
       "      <th>r19c16</th>\n",
       "      <th>r19c17</th>\n",
       "      <th>r19c18</th>\n",
       "      <th>r19c19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>52</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>141</td>\n",
       "      <td>172</td>\n",
       "      <td>197</td>\n",
       "      <td>223</td>\n",
       "      <td>233</td>\n",
       "      <td>246</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>169</td>\n",
       "      <td>147</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0c0  r0c1  r0c2  r0c3  r0c4  r0c5  r0c6  r0c7  r0c8  r0c9  ...  r19c11  \\\n",
       "0     1     1     1     1    28    43    52   255   255   255  ...     191   \n",
       "1     1     1     1     1     1     1     1     1     1     1  ...       1   \n",
       "2     1     1   128   255   255   255   255   255   255   255  ...     255   \n",
       "3    53    54    61    91   141   172   197   223   233   246  ...     184   \n",
       "4    46    46    46    46    36    36    41    41    41    41  ...      38   \n",
       "\n",
       "   r19c12  r19c13  r19c14  r19c15  r19c16  r19c17  r19c18  r19c19  label  \n",
       "0     255      52      34       1       1       1       1       1      0  \n",
       "1       1       1       1       1       1       1       1       1      0  \n",
       "2     255     255     255     255     255     128       1       1      0  \n",
       "3     185     187     169     147     106      82      34      23      1  \n",
       "4      65      65      95      95     149     149     205     205      0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "72134    0\n",
       "72135    0\n",
       "72136    0\n",
       "72137    0\n",
       "72138    0\n",
       "Name: label, Length: 72139, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 65581, 1: 6558})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter\n",
    "counter(ds.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0c0</th>\n",
       "      <th>r0c1</th>\n",
       "      <th>r0c2</th>\n",
       "      <th>r0c3</th>\n",
       "      <th>r0c4</th>\n",
       "      <th>r0c5</th>\n",
       "      <th>r0c6</th>\n",
       "      <th>r0c7</th>\n",
       "      <th>r0c8</th>\n",
       "      <th>r0c9</th>\n",
       "      <th>...</th>\n",
       "      <th>r19c11</th>\n",
       "      <th>r19c12</th>\n",
       "      <th>r19c13</th>\n",
       "      <th>r19c14</th>\n",
       "      <th>r19c15</th>\n",
       "      <th>r19c16</th>\n",
       "      <th>r19c17</th>\n",
       "      <th>r19c18</th>\n",
       "      <th>r19c19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "      <td>72139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.125383</td>\n",
       "      <td>51.473308</td>\n",
       "      <td>70.855279</td>\n",
       "      <td>82.032354</td>\n",
       "      <td>86.869142</td>\n",
       "      <td>96.391730</td>\n",
       "      <td>101.608728</td>\n",
       "      <td>108.712333</td>\n",
       "      <td>115.257752</td>\n",
       "      <td>119.014680</td>\n",
       "      <td>...</td>\n",
       "      <td>105.187416</td>\n",
       "      <td>101.996327</td>\n",
       "      <td>98.175689</td>\n",
       "      <td>94.994663</td>\n",
       "      <td>83.791611</td>\n",
       "      <td>79.024744</td>\n",
       "      <td>67.467084</td>\n",
       "      <td>49.497775</td>\n",
       "      <td>37.186349</td>\n",
       "      <td>0.090908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.769428</td>\n",
       "      <td>83.545299</td>\n",
       "      <td>93.468985</td>\n",
       "      <td>99.787787</td>\n",
       "      <td>100.295541</td>\n",
       "      <td>103.128587</td>\n",
       "      <td>104.129642</td>\n",
       "      <td>103.806258</td>\n",
       "      <td>106.480366</td>\n",
       "      <td>107.572306</td>\n",
       "      <td>...</td>\n",
       "      <td>106.387324</td>\n",
       "      <td>102.402083</td>\n",
       "      <td>103.242319</td>\n",
       "      <td>102.317456</td>\n",
       "      <td>98.440790</td>\n",
       "      <td>97.781003</td>\n",
       "      <td>90.884177</td>\n",
       "      <td>82.706445</td>\n",
       "      <td>72.454911</td>\n",
       "      <td>0.287480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               r0c0          r0c1          r0c2          r0c3          r0c4  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      36.125383     51.473308     70.855279     82.032354     86.869142   \n",
       "std       70.769428     83.545299     93.468985     99.787787    100.295541   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000      2.000000     18.000000     33.000000   \n",
       "75%       30.000000     80.000000    128.000000    171.000000    181.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "               r0c5          r0c6          r0c7          r0c8          r0c9  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      96.391730    101.608728    108.712333    115.257752    119.014680   \n",
       "std      103.128587    104.129642    103.806258    106.480366    107.572306   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%       52.000000     67.000000     91.000000     96.000000    104.000000   \n",
       "75%      208.000000    219.000000    226.000000    248.000000    255.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "       ...        r19c11        r19c12        r19c13        r19c14  \\\n",
       "count  ...  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean   ...    105.187416    101.996327     98.175689     94.994663   \n",
       "std    ...    106.387324    102.402083    103.242319    102.317456   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "50%    ...     69.000000     73.000000     60.000000     52.000000   \n",
       "75%    ...    236.000000    213.000000    207.000000    199.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "             r19c15        r19c16        r19c17        r19c18        r19c19  \\\n",
       "count  72139.000000  72139.000000  72139.000000  72139.000000  72139.000000   \n",
       "mean      83.791611     79.024744     67.467084     49.497775     37.186349   \n",
       "std       98.440790     97.781003     90.884177     82.706445     72.454911   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%       26.000000      7.000000      1.000000      1.000000      1.000000   \n",
       "75%      172.000000    163.000000    128.000000     73.000000     24.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "              label  \n",
       "count  72139.000000  \n",
       "mean       0.090908  \n",
       "std        0.287480  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 401 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('label', axis=1)\n",
    "y = ds.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size=0.10,random_state=42)\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255\n",
    "x_test= x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13158, 1: 1270})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "x_train_smenn, y_train_smenn = SMOTEENN().fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "x_train_tomek, y_train_tomek = SMOTETomek().fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "x_train_adasyn, y_train_adasyn = ADASYN().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "x_train_borderline, y_train_borderline = BorderlineSMOTE().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "x_train_svmsmote, y_train_svmsmote = SVMSMOTE().fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "x_train_oversam, y_train_oversam = RandomOverSampler(random_state=42).fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 47196, 1: 47196})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mat(X):\n",
    "    X_mat = []\n",
    "    for i in range(X.shape[0]):\n",
    "        X_mat.append(np.reshape(X.iloc[i].tolist(), (20,20)).T)\n",
    "    X_mat_arr = np.array(X_mat)\n",
    "    X_mat_arr_ex = X_mat_arr[:,:,:,None]\n",
    "    return X_mat_arr_ex\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    r = reshape_mat(image_batch)\n",
    "    for n in range(100):\n",
    "        ax = plt.subplot(10,10,n+1)\n",
    "        plt.imshow(r[n])\n",
    "        plt.title(str(label_batch[n]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_batch(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "def model_score(model, x, y):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'AUC', 'Recall', 'Precision']\n",
    "    )\n",
    "    #checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
    "\n",
    "    #early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,restore_best_weights=True)\n",
    "\n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "                EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=12, restore_best_weights=True)]\n",
    "    \n",
    "    print(\"\\n MODEL BUILDING ============================================================================ \\n\")\n",
    "\n",
    "    history = model.fit(\n",
    "        x, y, \n",
    "        epochs=128, \n",
    "        batch_size = 32, \n",
    "        validation_data=(x_val,y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    print(\"\\n MODEL EVALUATION ON TEST SET ============================================================================ \\n\")\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "    return [model, history, score]\n",
    "\n",
    "\n",
    "def pred_test_to_csv(model, name):\n",
    "    test_ds = pd.read_csv(\"test.csv\")\n",
    "    Id = test_ds['Id'][:]\n",
    "    test_ds = test_ds.drop(\"Id\", axis=1)\n",
    "    test_ds = test_ds/255\n",
    "    pred = model.predict(test_ds)\n",
    "    pred_df = pd.DataFrame({'Id':Id.values, 'Predicted':pred.flatten()}, columns=['Id', 'Predicted'])\n",
    "    print(pred_df)\n",
    "    pred_df.to_csv(f'{name}.csv', index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters, (3, 3), activation = 'relu', padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        tf.keras.layers.Conv2D(filters, (3, 3), activation = 'relu', padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
    "    ])\n",
    "    return block\n",
    "\n",
    "def conv_layer(filters):\n",
    "    return tf.keras.Sequential([layers.Conv2D(filters, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same')])\n",
    "\n",
    "def pool_layer(size):\n",
    "    return tf.keras.Sequential([layers.MaxPooling2D(pool_size=(size, size), strides=(2, 2), padding='same')])\n",
    "\n",
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation='relu'),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (4-layers) with SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2888/2888 [==============================] - 93s 32ms/step - loss: 0.2734 - accuracy: 0.8899 - auc: 0.9593 - recall: 0.8876 - precision: 0.8959 - val_loss: 0.2019 - val_accuracy: 0.9340 - val_auc: 0.9749 - val_recall: 0.9179 - val_precision: 0.5935\n",
      "Epoch 2/32\n",
      "2888/2888 [==============================] - 124s 43ms/step - loss: 0.1327 - accuracy: 0.9571 - auc: 0.9912 - recall: 0.9601 - precision: 0.9561 - val_loss: 0.1529 - val_accuracy: 0.9534 - val_auc: 0.9798 - val_recall: 0.9104 - val_precision: 0.6883\n",
      "Epoch 3/32\n",
      "2888/2888 [==============================] - 145s 50ms/step - loss: 0.1060 - accuracy: 0.9680 - auc: 0.9948 - recall: 0.9719 - precision: 0.9657 - val_loss: 0.1655 - val_accuracy: 0.9525 - val_auc: 0.9656 - val_recall: 0.8358 - val_precision: 0.7066\n",
      "Epoch 4/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.0891 - accuracy: 0.9750 - auc: 0.9967 - recall: 0.9780 - precision: 0.9732 - val_loss: 0.1625 - val_accuracy: 0.9569 - val_auc: 0.9806 - val_recall: 0.9179 - val_precision: 0.7059\n",
      "Epoch 5/32\n",
      "2888/2888 [==============================] - 146s 51ms/step - loss: 0.0819 - accuracy: 0.9777 - auc: 0.9971 - recall: 0.9802 - precision: 0.9763 - val_loss: 0.1486 - val_accuracy: 0.9567 - val_auc: 0.9809 - val_recall: 0.9216 - val_precision: 0.7037\n",
      "Epoch 6/32\n",
      "2888/2888 [==============================] - 137s 47ms/step - loss: 0.0737 - accuracy: 0.9808 - auc: 0.9978 - recall: 0.9840 - precision: 0.9785 - val_loss: 0.1352 - val_accuracy: 0.9683 - val_auc: 0.9776 - val_recall: 0.8657 - val_precision: 0.8070\n",
      "Epoch 7/32\n",
      "2888/2888 [==============================] - 169s 59ms/step - loss: 0.0684 - accuracy: 0.9830 - auc: 0.9982 - recall: 0.9857 - precision: 0.9812 - val_loss: 0.1548 - val_accuracy: 0.9584 - val_auc: 0.9798 - val_recall: 0.9216 - val_precision: 0.7139\n",
      "Epoch 8/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0662 - accuracy: 0.9842 - auc: 0.9982 - recall: 0.9868 - precision: 0.9823 - val_loss: 0.1312 - val_accuracy: 0.9681 - val_auc: 0.9798 - val_recall: 0.8993 - val_precision: 0.7876\n",
      "Epoch 9/32\n",
      "2888/2888 [==============================] - 166s 57ms/step - loss: 0.0604 - accuracy: 0.9858 - auc: 0.9985 - recall: 0.9883 - precision: 0.9840 - val_loss: 0.2002 - val_accuracy: 0.9567 - val_auc: 0.9759 - val_recall: 0.9179 - val_precision: 0.7049\n",
      "Epoch 10/32\n",
      "2888/2888 [==============================] - 144s 50ms/step - loss: 0.0576 - accuracy: 0.9871 - auc: 0.9986 - recall: 0.9887 - precision: 0.9860 - val_loss: 0.1479 - val_accuracy: 0.9624 - val_auc: 0.9837 - val_recall: 0.9160 - val_precision: 0.7406\n",
      "Epoch 11/32\n",
      "2888/2888 [==============================] - 140s 48ms/step - loss: 0.0553 - accuracy: 0.9874 - auc: 0.9988 - recall: 0.9898 - precision: 0.9857 - val_loss: 0.1407 - val_accuracy: 0.9659 - val_auc: 0.9740 - val_recall: 0.8899 - val_precision: 0.7756\n",
      "Epoch 12/32\n",
      "2888/2888 [==============================] - 107s 37ms/step - loss: 0.0538 - accuracy: 0.9876 - auc: 0.9988 - recall: 0.9895 - precision: 0.9862 - val_loss: 0.1536 - val_accuracy: 0.9648 - val_auc: 0.9834 - val_recall: 0.9347 - val_precision: 0.7489\n",
      "Epoch 13/32\n",
      "2888/2888 [==============================] - 79s 28ms/step - loss: 0.0502 - accuracy: 0.9885 - auc: 0.9991 - recall: 0.9902 - precision: 0.9874 - val_loss: 0.1704 - val_accuracy: 0.9666 - val_auc: 0.9693 - val_recall: 0.8750 - val_precision: 0.7882\n",
      "Epoch 14/32\n",
      "2888/2888 [==============================] - 77s 27ms/step - loss: 0.0343 - accuracy: 0.9945 - auc: 0.9997 - recall: 0.9961 - precision: 0.9931 - val_loss: 0.1723 - val_accuracy: 0.9723 - val_auc: 0.9736 - val_recall: 0.9049 - val_precision: 0.8165\n",
      "Epoch 15/32\n",
      "2888/2888 [==============================] - 79s 27ms/step - loss: 0.0302 - accuracy: 0.9957 - auc: 0.9998 - recall: 0.9974 - precision: 0.9941 - val_loss: 0.1809 - val_accuracy: 0.9712 - val_auc: 0.9743 - val_recall: 0.9216 - val_precision: 0.7994\n",
      "Epoch 16/32\n",
      "2888/2888 [==============================] - 76s 26ms/step - loss: 0.0284 - accuracy: 0.9960 - auc: 0.9998 - recall: 0.9977 - precision: 0.9944 - val_loss: 0.1858 - val_accuracy: 0.9719 - val_auc: 0.9734 - val_recall: 0.9086 - val_precision: 0.8117\n",
      "1444/1444 [==============================] - 23s 16ms/step - loss: 0.0184 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# predictions_CNN_prob_1 - SUBMIT THISISSISISISISISISIS\n",
    "#  0.98813\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_1 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/32\n",
      "2888/2888 [==============================] - 170s 58ms/step - loss: 0.4688 - accuracy: 0.7657 - auc: 0.8603 - recall: 0.7909 - precision: 0.7601 - val_loss: 0.2494 - val_accuracy: 0.9092 - val_auc: 0.8979 - val_recall: 0.6903 - val_precision: 0.5082\n",
      "Epoch 2/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.2901 - accuracy: 0.8858 - auc: 0.9513 - recall: 0.8869 - precision: 0.8891 - val_loss: 0.2143 - val_accuracy: 0.9165 - val_auc: 0.9375 - val_recall: 0.7985 - val_precision: 0.5337\n",
      "Epoch 3/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.2420 - accuracy: 0.9090 - auc: 0.9668 - recall: 0.9115 - precision: 0.9105 - val_loss: 0.2316 - val_accuracy: 0.9092 - val_auc: 0.9390 - val_recall: 0.8022 - val_precision: 0.5071\n",
      "Epoch 4/32\n",
      "2888/2888 [==============================] - 168s 58ms/step - loss: 0.2168 - accuracy: 0.9213 - auc: 0.9741 - recall: 0.9236 - precision: 0.9223 - val_loss: 0.2500 - val_accuracy: 0.9002 - val_auc: 0.9427 - val_recall: 0.8377 - val_precision: 0.4787\n",
      "Epoch 5/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.2014 - accuracy: 0.9282 - auc: 0.9781 - recall: 0.9307 - precision: 0.9288 - val_loss: 0.1968 - val_accuracy: 0.9278 - val_auc: 0.9402 - val_recall: 0.7743 - val_precision: 0.5837\n",
      "Epoch 6/32\n",
      "2888/2888 [==============================] - 161s 56ms/step - loss: 0.1923 - accuracy: 0.9326 - auc: 0.9804 - recall: 0.9358 - precision: 0.9325 - val_loss: 0.1975 - val_accuracy: 0.9267 - val_auc: 0.9449 - val_recall: 0.7892 - val_precision: 0.5771\n",
      "Epoch 7/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.1832 - accuracy: 0.9367 - auc: 0.9826 - recall: 0.9400 - precision: 0.9363 - val_loss: 0.1693 - val_accuracy: 0.9425 - val_auc: 0.9566 - val_recall: 0.8060 - val_precision: 0.6545\n",
      "Epoch 8/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.1780 - accuracy: 0.9394 - auc: 0.9838 - recall: 0.9421 - precision: 0.9393 - val_loss: 0.1860 - val_accuracy: 0.9345 - val_auc: 0.9559 - val_recall: 0.8209 - val_precision: 0.6094\n",
      "Epoch 9/32\n",
      "2888/2888 [==============================] - 157s 55ms/step - loss: 0.1710 - accuracy: 0.9423 - auc: 0.9854 - recall: 0.9455 - precision: 0.9417 - val_loss: 0.1720 - val_accuracy: 0.9409 - val_auc: 0.9556 - val_recall: 0.7854 - val_precision: 0.6507\n",
      "Epoch 10/32\n",
      "2888/2888 [==============================] - 154s 53ms/step - loss: 0.1675 - accuracy: 0.9443 - auc: 0.9862 - recall: 0.9472 - precision: 0.9439 - val_loss: 0.2052 - val_accuracy: 0.9271 - val_auc: 0.9565 - val_recall: 0.8377 - val_precision: 0.5734\n",
      "Epoch 11/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.1646 - accuracy: 0.9458 - auc: 0.9868 - recall: 0.9488 - precision: 0.9452 - val_loss: 0.1724 - val_accuracy: 0.9432 - val_auc: 0.9529 - val_recall: 0.7780 - val_precision: 0.6661\n",
      "Epoch 12/32\n",
      "2888/2888 [==============================] - 159s 55ms/step - loss: 0.1594 - accuracy: 0.9488 - auc: 0.9878 - recall: 0.9530 - precision: 0.9471 - val_loss: 0.1551 - val_accuracy: 0.9506 - val_auc: 0.9569 - val_recall: 0.7649 - val_precision: 0.7206\n",
      "Epoch 13/32\n",
      "2888/2888 [==============================] - 160s 56ms/step - loss: 0.1566 - accuracy: 0.9498 - auc: 0.9884 - recall: 0.9538 - precision: 0.9482 - val_loss: 0.1627 - val_accuracy: 0.9440 - val_auc: 0.9591 - val_recall: 0.7929 - val_precision: 0.6672\n",
      "Epoch 14/32\n",
      "2888/2888 [==============================] - 169s 59ms/step - loss: 0.1556 - accuracy: 0.9505 - auc: 0.9887 - recall: 0.9532 - precision: 0.9502 - val_loss: 0.1559 - val_accuracy: 0.9513 - val_auc: 0.9590 - val_recall: 0.7631 - val_precision: 0.7265\n",
      "Epoch 15/32\n",
      "2888/2888 [==============================] - 163s 57ms/step - loss: 0.1516 - accuracy: 0.9524 - auc: 0.9893 - recall: 0.9560 - precision: 0.9511 - val_loss: 0.1727 - val_accuracy: 0.9435 - val_auc: 0.9609 - val_recall: 0.8302 - val_precision: 0.6544\n",
      "Epoch 16/32\n",
      "2888/2888 [==============================] - 157s 54ms/step - loss: 0.1477 - accuracy: 0.9537 - auc: 0.9901 - recall: 0.9575 - precision: 0.9521 - val_loss: 0.1733 - val_accuracy: 0.9453 - val_auc: 0.9666 - val_recall: 0.8470 - val_precision: 0.6599\n",
      "Epoch 17/32\n",
      "2888/2888 [==============================] - 166s 57ms/step - loss: 0.1477 - accuracy: 0.9540 - auc: 0.9901 - recall: 0.9572 - precision: 0.9530 - val_loss: 0.1495 - val_accuracy: 0.9558 - val_auc: 0.9630 - val_recall: 0.7910 - val_precision: 0.7478\n",
      "Epoch 18/32\n",
      "2888/2888 [==============================] - 162s 56ms/step - loss: 0.1457 - accuracy: 0.9563 - auc: 0.9904 - recall: 0.9592 - precision: 0.9553 - val_loss: 0.1643 - val_accuracy: 0.9468 - val_auc: 0.9672 - val_recall: 0.8433 - val_precision: 0.6696\n",
      "Epoch 19/32\n",
      "2888/2888 [==============================] - 157s 54ms/step - loss: 0.1450 - accuracy: 0.9561 - auc: 0.9906 - recall: 0.9589 - precision: 0.9553 - val_loss: 0.1623 - val_accuracy: 0.9492 - val_auc: 0.9606 - val_recall: 0.8190 - val_precision: 0.6913\n",
      "Epoch 20/32\n",
      "2888/2888 [==============================] - 183s 63ms/step - loss: 0.1415 - accuracy: 0.9571 - auc: 0.9913 - recall: 0.9597 - precision: 0.9564 - val_loss: 0.1648 - val_accuracy: 0.9428 - val_auc: 0.9642 - val_recall: 0.8358 - val_precision: 0.6493\n",
      "Epoch 21/32\n",
      "2888/2888 [==============================] - 166s 58ms/step - loss: 0.1409 - accuracy: 0.9573 - auc: 0.9914 - recall: 0.9603 - precision: 0.9563 - val_loss: 0.1661 - val_accuracy: 0.9487 - val_auc: 0.9607 - val_recall: 0.8153 - val_precision: 0.6893\n",
      "Epoch 22/32\n",
      "2888/2888 [==============================] - 163s 57ms/step - loss: 0.1376 - accuracy: 0.9591 - auc: 0.9918 - recall: 0.9623 - precision: 0.9577 - val_loss: 0.1688 - val_accuracy: 0.9437 - val_auc: 0.9645 - val_recall: 0.8284 - val_precision: 0.6558\n",
      "Epoch 23/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.1082 - accuracy: 0.9708 - auc: 0.9954 - recall: 0.9735 - precision: 0.9693 - val_loss: 0.1589 - val_accuracy: 0.9475 - val_auc: 0.9684 - val_recall: 0.8563 - val_precision: 0.6701\n",
      "Epoch 24/32\n",
      "2888/2888 [==============================] - 160s 55ms/step - loss: 0.0994 - accuracy: 0.9736 - auc: 0.9961 - recall: 0.9765 - precision: 0.9721 - val_loss: 0.1477 - val_accuracy: 0.9556 - val_auc: 0.9662 - val_recall: 0.8358 - val_precision: 0.7273\n",
      "Epoch 25/32\n",
      "2888/2888 [==============================] - 158s 55ms/step - loss: 0.0967 - accuracy: 0.9743 - auc: 0.9964 - recall: 0.9770 - precision: 0.9729 - val_loss: 0.1471 - val_accuracy: 0.9556 - val_auc: 0.9640 - val_recall: 0.8321 - val_precision: 0.7288\n",
      "Epoch 26/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0950 - accuracy: 0.9750 - auc: 0.9965 - recall: 0.9777 - precision: 0.9734 - val_loss: 0.1454 - val_accuracy: 0.9555 - val_auc: 0.9671 - val_recall: 0.8078 - val_precision: 0.7376\n",
      "Epoch 27/32\n",
      "2888/2888 [==============================] - 153s 53ms/step - loss: 0.0941 - accuracy: 0.9753 - auc: 0.9965 - recall: 0.9777 - precision: 0.9740 - val_loss: 0.1468 - val_accuracy: 0.9541 - val_auc: 0.9668 - val_recall: 0.8396 - val_precision: 0.7154\n",
      "Epoch 28/32\n",
      "2888/2888 [==============================] - 152s 53ms/step - loss: 0.0918 - accuracy: 0.9761 - auc: 0.9967 - recall: 0.9785 - precision: 0.9749 - val_loss: 0.1443 - val_accuracy: 0.9569 - val_auc: 0.9670 - val_recall: 0.8265 - val_precision: 0.7396\n",
      "Epoch 29/32\n",
      "2888/2888 [==============================] - 153s 53ms/step - loss: 0.0922 - accuracy: 0.9755 - auc: 0.9968 - recall: 0.9778 - precision: 0.9744 - val_loss: 0.1399 - val_accuracy: 0.9589 - val_auc: 0.9648 - val_recall: 0.8172 - val_precision: 0.7591\n",
      "Epoch 30/32\n",
      "2888/2888 [==============================] - 156s 54ms/step - loss: 0.0887 - accuracy: 0.9775 - auc: 0.9969 - recall: 0.9804 - precision: 0.9756 - val_loss: 0.1415 - val_accuracy: 0.9581 - val_auc: 0.9667 - val_recall: 0.8284 - val_precision: 0.7475\n",
      "Epoch 31/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.0887 - accuracy: 0.9776 - auc: 0.9969 - recall: 0.9802 - precision: 0.9761 - val_loss: 0.1423 - val_accuracy: 0.9576 - val_auc: 0.9652 - val_recall: 0.7892 - val_precision: 0.7622\n",
      "Epoch 32/32\n",
      "2888/2888 [==============================] - 155s 54ms/step - loss: 0.0871 - accuracy: 0.9780 - auc: 0.9970 - recall: 0.9803 - precision: 0.9767 - val_loss: 0.1355 - val_accuracy: 0.9593 - val_auc: 0.9685 - val_recall: 0.8172 - val_precision: 0.7617\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 8s 32ms/step - loss: 0.1398 - accuracy: 0.9601 - auc: 0.9627 - recall: 0.8038 - precision: 0.7663\n"
     ]
    }
   ],
   "source": [
    "# predictions_CNN_prob_2 \n",
    "# SMOTE EN sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_2 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/32\n",
      "1624/1624 [==============================] - 93s 56ms/step - loss: 0.2617 - accuracy: 0.9210 - auc: 0.7793 - recall: 0.1982 - precision: 0.7438 - val_loss: 0.2422 - val_accuracy: 0.9397 - val_auc: 0.9067 - val_recall: 0.4944 - val_precision: 0.7749\n",
      "Epoch 2/32\n",
      "1624/1624 [==============================] - 100s 62ms/step - loss: 0.1812 - accuracy: 0.9435 - auc: 0.9053 - recall: 0.4986 - precision: 0.8044 - val_loss: 0.1912 - val_accuracy: 0.9494 - val_auc: 0.9451 - val_recall: 0.5634 - val_precision: 0.8389\n",
      "Epoch 3/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1584 - accuracy: 0.9493 - auc: 0.9349 - recall: 0.5720 - precision: 0.8141 - val_loss: 0.1366 - val_accuracy: 0.9572 - val_auc: 0.9592 - val_recall: 0.6828 - val_precision: 0.8262\n",
      "Epoch 4/32\n",
      "1624/1624 [==============================] - 90s 56ms/step - loss: 0.1436 - accuracy: 0.9546 - auc: 0.9497 - recall: 0.6178 - precision: 0.8400 - val_loss: 0.1339 - val_accuracy: 0.9586 - val_auc: 0.9696 - val_recall: 0.5989 - val_precision: 0.9304\n",
      "Epoch 5/32\n",
      "1624/1624 [==============================] - 90s 55ms/step - loss: 0.1323 - accuracy: 0.9584 - auc: 0.9574 - recall: 0.6621 - precision: 0.8461 - val_loss: 0.1343 - val_accuracy: 0.9624 - val_auc: 0.9768 - val_recall: 0.7463 - val_precision: 0.8316\n",
      "Epoch 6/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1264 - accuracy: 0.9602 - auc: 0.9623 - recall: 0.6809 - precision: 0.8513 - val_loss: 0.1416 - val_accuracy: 0.9605 - val_auc: 0.9736 - val_recall: 0.7015 - val_precision: 0.8468\n",
      "Epoch 7/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1175 - accuracy: 0.9641 - auc: 0.9691 - recall: 0.7130 - precision: 0.8681 - val_loss: 0.1138 - val_accuracy: 0.9643 - val_auc: 0.9737 - val_recall: 0.6978 - val_precision: 0.8947\n",
      "Epoch 8/32\n",
      "1624/1624 [==============================] - 91s 56ms/step - loss: 0.1159 - accuracy: 0.9647 - auc: 0.9691 - recall: 0.7199 - precision: 0.8692 - val_loss: 0.1123 - val_accuracy: 0.9648 - val_auc: 0.9765 - val_recall: 0.6866 - val_precision: 0.9132\n",
      "Epoch 9/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1136 - accuracy: 0.9649 - auc: 0.9721 - recall: 0.7305 - precision: 0.8619 - val_loss: 0.1284 - val_accuracy: 0.9650 - val_auc: 0.9785 - val_recall: 0.6959 - val_precision: 0.9053\n",
      "Epoch 10/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1052 - accuracy: 0.9671 - auc: 0.9772 - recall: 0.7543 - precision: 0.8661 - val_loss: 0.1029 - val_accuracy: 0.9695 - val_auc: 0.9827 - val_recall: 0.7948 - val_precision: 0.8659\n",
      "Epoch 11/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.1032 - accuracy: 0.9674 - auc: 0.9785 - recall: 0.7551 - precision: 0.8692 - val_loss: 0.1236 - val_accuracy: 0.9688 - val_auc: 0.9813 - val_recall: 0.8116 - val_precision: 0.8463\n",
      "Epoch 12/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.1001 - accuracy: 0.9696 - auc: 0.9793 - recall: 0.7670 - precision: 0.8829 - val_loss: 0.1027 - val_accuracy: 0.9683 - val_auc: 0.9834 - val_recall: 0.7201 - val_precision: 0.9212\n",
      "Epoch 13/32\n",
      "1624/1624 [==============================] - 95s 59ms/step - loss: 0.0978 - accuracy: 0.9707 - auc: 0.9795 - recall: 0.7761 - precision: 0.8869 - val_loss: 0.1050 - val_accuracy: 0.9681 - val_auc: 0.9841 - val_recall: 0.7239 - val_precision: 0.9151\n",
      "Epoch 14/32\n",
      "1624/1624 [==============================] - 123s 76ms/step - loss: 0.0953 - accuracy: 0.9716 - auc: 0.9820 - recall: 0.7925 - precision: 0.8831 - val_loss: 0.1189 - val_accuracy: 0.9678 - val_auc: 0.9803 - val_recall: 0.7649 - val_precision: 0.8723\n",
      "Epoch 15/32\n",
      "1624/1624 [==============================] - 106s 65ms/step - loss: 0.0943 - accuracy: 0.9714 - auc: 0.9824 - recall: 0.7920 - precision: 0.8809 - val_loss: 0.1085 - val_accuracy: 0.9697 - val_auc: 0.9821 - val_recall: 0.7556 - val_precision: 0.9020\n",
      "Epoch 16/32\n",
      "1624/1624 [==============================] - 96s 59ms/step - loss: 0.0935 - accuracy: 0.9723 - auc: 0.9832 - recall: 0.7990 - precision: 0.8843 - val_loss: 0.1009 - val_accuracy: 0.9711 - val_auc: 0.9866 - val_recall: 0.7929 - val_precision: 0.8836\n",
      "Epoch 17/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.0903 - accuracy: 0.9732 - auc: 0.9837 - recall: 0.8084 - precision: 0.8861 - val_loss: 0.1060 - val_accuracy: 0.9718 - val_auc: 0.9859 - val_recall: 0.8134 - val_precision: 0.8737\n",
      "Epoch 18/32\n",
      "1624/1624 [==============================] - 95s 58ms/step - loss: 0.0877 - accuracy: 0.9743 - auc: 0.9843 - recall: 0.8086 - precision: 0.8987 - val_loss: 0.1287 - val_accuracy: 0.9711 - val_auc: 0.9833 - val_recall: 0.8545 - val_precision: 0.8373\n",
      "Epoch 19/32\n",
      "1624/1624 [==============================] - 93s 57ms/step - loss: 0.0874 - accuracy: 0.9749 - auc: 0.9851 - recall: 0.8196 - precision: 0.8953 - val_loss: 0.1013 - val_accuracy: 0.9761 - val_auc: 0.9883 - val_recall: 0.8489 - val_precision: 0.8887\n",
      "Epoch 20/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.0861 - accuracy: 0.9749 - auc: 0.9852 - recall: 0.8190 - precision: 0.8961 - val_loss: 0.0899 - val_accuracy: 0.9719 - val_auc: 0.9874 - val_recall: 0.7668 - val_precision: 0.9174\n",
      "Epoch 21/32\n",
      "1624/1624 [==============================] - 92s 57ms/step - loss: 0.0832 - accuracy: 0.9756 - auc: 0.9871 - recall: 0.8257 - precision: 0.8979 - val_loss: 0.0950 - val_accuracy: 0.9738 - val_auc: 0.9847 - val_recall: 0.7948 - val_precision: 0.9122\n",
      "Epoch 22/32\n",
      "1624/1624 [==============================] - 93s 57ms/step - loss: 0.0855 - accuracy: 0.9751 - auc: 0.9861 - recall: 0.8281 - precision: 0.8902 - val_loss: 0.1086 - val_accuracy: 0.9645 - val_auc: 0.9798 - val_recall: 0.6642 - val_precision: 0.9344\n",
      "Epoch 23/32\n",
      "1624/1624 [==============================] - 94s 58ms/step - loss: 0.0818 - accuracy: 0.9761 - auc: 0.9873 - recall: 0.8321 - precision: 0.8978 - val_loss: 0.0967 - val_accuracy: 0.9704 - val_auc: 0.9854 - val_recall: 0.7593 - val_precision: 0.9065\n",
      "Epoch 24/32\n",
      "1624/1624 [==============================] - 93s 58ms/step - loss: 0.0824 - accuracy: 0.9759 - auc: 0.9866 - recall: 0.8353 - precision: 0.8928 - val_loss: 0.0958 - val_accuracy: 0.9742 - val_auc: 0.9849 - val_recall: 0.8097 - val_precision: 0.9023\n",
      "Epoch 25/32\n",
      "1624/1624 [==============================] - 95s 58ms/step - loss: 0.0810 - accuracy: 0.9764 - auc: 0.9877 - recall: 0.8387 - precision: 0.8946 - val_loss: 0.0936 - val_accuracy: 0.9745 - val_auc: 0.9891 - val_recall: 0.8116 - val_precision: 0.9044\n",
      "Epoch 26/32\n",
      "1624/1624 [==============================] - 89s 55ms/step - loss: 0.0645 - accuracy: 0.9824 - auc: 0.9937 - recall: 0.8773 - precision: 0.9251 - val_loss: 0.0842 - val_accuracy: 0.9768 - val_auc: 0.9890 - val_recall: 0.8396 - val_precision: 0.9036\n",
      "Epoch 27/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0574 - accuracy: 0.9849 - auc: 0.9949 - recall: 0.9012 - precision: 0.9300 - val_loss: 0.0811 - val_accuracy: 0.9773 - val_auc: 0.9875 - val_recall: 0.8433 - val_precision: 0.9058\n",
      "Epoch 28/32\n",
      "1624/1624 [==============================] - 86s 53ms/step - loss: 0.0561 - accuracy: 0.9849 - auc: 0.9951 - recall: 0.9052 - precision: 0.9266 - val_loss: 0.0799 - val_accuracy: 0.9773 - val_auc: 0.9868 - val_recall: 0.8265 - val_precision: 0.9210\n",
      "Epoch 29/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0543 - accuracy: 0.9853 - auc: 0.9949 - recall: 0.9105 - precision: 0.9258 - val_loss: 0.0807 - val_accuracy: 0.9777 - val_auc: 0.9872 - val_recall: 0.8340 - val_precision: 0.9179\n",
      "Epoch 30/32\n",
      "1624/1624 [==============================] - 88s 54ms/step - loss: 0.0532 - accuracy: 0.9864 - auc: 0.9956 - recall: 0.9150 - precision: 0.9342 - val_loss: 0.0801 - val_accuracy: 0.9778 - val_auc: 0.9879 - val_recall: 0.8377 - val_precision: 0.9163\n",
      "Epoch 31/32\n",
      "1624/1624 [==============================] - 87s 54ms/step - loss: 0.0521 - accuracy: 0.9861 - auc: 0.9957 - recall: 0.9144 - precision: 0.9309 - val_loss: 0.0791 - val_accuracy: 0.9783 - val_auc: 0.9861 - val_recall: 0.8489 - val_precision: 0.9118\n",
      "Epoch 32/32\n",
      "1624/1624 [==============================] - 87s 54ms/step - loss: 0.0504 - accuracy: 0.9868 - auc: 0.9956 - recall: 0.9182 - precision: 0.9354 - val_loss: 0.0830 - val_accuracy: 0.9773 - val_auc: 0.9883 - val_recall: 0.8619 - val_precision: 0.8902\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 7s 30ms/step - loss: 0.0866 - accuracy: 0.9777 - auc: 0.9858 - recall: 0.8659 - precision: 0.8849\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set.\n",
    "# predictions_CNN_prob_3 - SUBMIT THISISSISISISISISISIS\n",
    "# 0.99060 on kaggle\n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.0001), padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_3 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/64\n",
      "1624/1624 [==============================] - 167s 101ms/step - loss: 0.4036 - accuracy: 0.9200 - auc: 0.7902 - recall: 0.2610 - precision: 0.6482 - val_loss: 0.4930 - val_accuracy: 0.8820 - val_auc: 0.8621 - val_recall: 0.6493 - val_precision: 0.4138\n",
      "Epoch 2/64\n",
      "1624/1624 [==============================] - 156s 96ms/step - loss: 0.2805 - accuracy: 0.9348 - auc: 0.8776 - recall: 0.4469 - precision: 0.7302 - val_loss: 0.6525 - val_accuracy: 0.5035 - val_auc: 0.8335 - val_recall: 0.9627 - val_precision: 0.1535\n",
      "Epoch 3/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.2445 - accuracy: 0.9364 - auc: 0.8879 - recall: 0.4861 - precision: 0.7224 - val_loss: 0.2242 - val_accuracy: 0.9390 - val_auc: 0.9155 - val_recall: 0.6343 - val_precision: 0.6855\n",
      "Epoch 4/64\n",
      "1624/1624 [==============================] - 153s 94ms/step - loss: 0.2495 - accuracy: 0.9325 - auc: 0.8813 - recall: 0.4950 - precision: 0.6747 - val_loss: 0.4194 - val_accuracy: 0.9203 - val_auc: 0.8129 - val_recall: 0.1493 - val_precision: 0.9524\n",
      "Epoch 5/64\n",
      "1624/1624 [==============================] - 152s 94ms/step - loss: 0.2307 - accuracy: 0.9389 - auc: 0.8931 - recall: 0.4974 - precision: 0.7452 - val_loss: 0.9866 - val_accuracy: 0.7152 - val_auc: 0.8617 - val_recall: 0.8433 - val_precision: 0.2247\n",
      "Epoch 6/64\n",
      "1624/1624 [==============================] - 152s 93ms/step - loss: 0.2206 - accuracy: 0.9410 - auc: 0.9048 - recall: 0.5207 - precision: 0.7538 - val_loss: 0.2717 - val_accuracy: 0.9276 - val_auc: 0.9115 - val_recall: 0.2761 - val_precision: 0.8315\n",
      "Epoch 7/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.1993 - accuracy: 0.9455 - auc: 0.9238 - recall: 0.5624 - precision: 0.7760 - val_loss: 0.1855 - val_accuracy: 0.9494 - val_auc: 0.9334 - val_recall: 0.5653 - val_precision: 0.8370\n",
      "Epoch 8/64\n",
      "1624/1624 [==============================] - 152s 94ms/step - loss: 0.1825 - accuracy: 0.9485 - auc: 0.9347 - recall: 0.6044 - precision: 0.7792 - val_loss: 0.1801 - val_accuracy: 0.9473 - val_auc: 0.9310 - val_recall: 0.6026 - val_precision: 0.7802\n",
      "Epoch 9/64\n",
      "1624/1624 [==============================] - 150s 93ms/step - loss: 0.1633 - accuracy: 0.9518 - auc: 0.9448 - recall: 0.6415 - precision: 0.7888 - val_loss: 0.2104 - val_accuracy: 0.9269 - val_auc: 0.9443 - val_recall: 0.8153 - val_precision: 0.5750\n",
      "Epoch 10/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.1562 - accuracy: 0.9540 - auc: 0.9482 - recall: 0.6515 - precision: 0.8047 - val_loss: 0.2696 - val_accuracy: 0.9023 - val_auc: 0.9458 - val_recall: 0.8489 - val_precision: 0.4851\n",
      "Epoch 11/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1446 - accuracy: 0.9560 - auc: 0.9572 - recall: 0.6750 - precision: 0.8087 - val_loss: 0.1512 - val_accuracy: 0.9560 - val_auc: 0.9628 - val_recall: 0.7780 - val_precision: 0.7554\n",
      "Epoch 12/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.1408 - accuracy: 0.9575 - auc: 0.9594 - recall: 0.6896 - precision: 0.8145 - val_loss: 0.1590 - val_accuracy: 0.9463 - val_auc: 0.9559 - val_recall: 0.7836 - val_precision: 0.6840\n",
      "Epoch 13/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1378 - accuracy: 0.9585 - auc: 0.9606 - recall: 0.6990 - precision: 0.8175 - val_loss: 0.1575 - val_accuracy: 0.9525 - val_auc: 0.9556 - val_recall: 0.7369 - val_precision: 0.7481\n",
      "Epoch 14/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1314 - accuracy: 0.9596 - auc: 0.9652 - recall: 0.7117 - precision: 0.8202 - val_loss: 0.1435 - val_accuracy: 0.9548 - val_auc: 0.9596 - val_recall: 0.7668 - val_precision: 0.7514\n",
      "Epoch 15/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1275 - accuracy: 0.9614 - auc: 0.9663 - recall: 0.7132 - precision: 0.8372 - val_loss: 0.2033 - val_accuracy: 0.9264 - val_auc: 0.9600 - val_recall: 0.8377 - val_precision: 0.5705\n",
      "Epoch 16/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1264 - accuracy: 0.9614 - auc: 0.9683 - recall: 0.7098 - precision: 0.8399 - val_loss: 0.1341 - val_accuracy: 0.9551 - val_auc: 0.9700 - val_recall: 0.5840 - val_precision: 0.8968\n",
      "Epoch 17/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.1197 - accuracy: 0.9629 - auc: 0.9718 - recall: 0.7223 - precision: 0.8467 - val_loss: 0.1259 - val_accuracy: 0.9608 - val_auc: 0.9708 - val_recall: 0.7108 - val_precision: 0.8429\n",
      "Epoch 18/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1175 - accuracy: 0.9642 - auc: 0.9732 - recall: 0.7403 - precision: 0.8457 - val_loss: 0.1501 - val_accuracy: 0.9499 - val_auc: 0.9713 - val_recall: 0.8396 - val_precision: 0.6891\n",
      "Epoch 19/64\n",
      "1624/1624 [==============================] - 150s 92ms/step - loss: 0.1133 - accuracy: 0.9652 - auc: 0.9758 - recall: 0.7532 - precision: 0.8468 - val_loss: 0.1341 - val_accuracy: 0.9563 - val_auc: 0.9649 - val_recall: 0.7313 - val_precision: 0.7840\n",
      "Epoch 20/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1085 - accuracy: 0.9663 - auc: 0.9774 - recall: 0.7630 - precision: 0.8502 - val_loss: 0.2365 - val_accuracy: 0.9099 - val_auc: 0.9656 - val_recall: 0.9030 - val_precision: 0.5084\n",
      "Epoch 21/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1063 - accuracy: 0.9682 - auc: 0.9780 - recall: 0.7717 - precision: 0.8640 - val_loss: 0.1662 - val_accuracy: 0.9567 - val_auc: 0.9498 - val_recall: 0.5914 - val_precision: 0.9109\n",
      "Epoch 22/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.1033 - accuracy: 0.9685 - auc: 0.9799 - recall: 0.7755 - precision: 0.8642 - val_loss: 0.1333 - val_accuracy: 0.9621 - val_auc: 0.9639 - val_recall: 0.6735 - val_precision: 0.8914\n",
      "Epoch 23/64\n",
      "1624/1624 [==============================] - 149s 91ms/step - loss: 0.0837 - accuracy: 0.9745 - auc: 0.9877 - recall: 0.8283 - precision: 0.8835 - val_loss: 0.0985 - val_accuracy: 0.9679 - val_auc: 0.9823 - val_recall: 0.8321 - val_precision: 0.8244\n",
      "Epoch 24/64\n",
      "1624/1624 [==============================] - 151s 93ms/step - loss: 0.0784 - accuracy: 0.9761 - auc: 0.9890 - recall: 0.8480 - precision: 0.8844 - val_loss: 0.0963 - val_accuracy: 0.9695 - val_auc: 0.9814 - val_recall: 0.8060 - val_precision: 0.8571\n",
      "Epoch 25/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0758 - accuracy: 0.9777 - auc: 0.9898 - recall: 0.8554 - precision: 0.8945 - val_loss: 0.0974 - val_accuracy: 0.9685 - val_auc: 0.9812 - val_recall: 0.8041 - val_precision: 0.8484\n",
      "Epoch 26/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0733 - accuracy: 0.9784 - auc: 0.9902 - recall: 0.8603 - precision: 0.8972 - val_loss: 0.0960 - val_accuracy: 0.9676 - val_auc: 0.9839 - val_recall: 0.8302 - val_precision: 0.8226\n",
      "Epoch 27/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0717 - accuracy: 0.9781 - auc: 0.9908 - recall: 0.8586 - precision: 0.8964 - val_loss: 0.0952 - val_accuracy: 0.9705 - val_auc: 0.9822 - val_recall: 0.8172 - val_precision: 0.8588\n",
      "Epoch 28/64\n",
      "1624/1624 [==============================] - 147s 90ms/step - loss: 0.0690 - accuracy: 0.9794 - auc: 0.9910 - recall: 0.8609 - precision: 0.9073 - val_loss: 0.0933 - val_accuracy: 0.9714 - val_auc: 0.9819 - val_recall: 0.8116 - val_precision: 0.8717\n",
      "Epoch 29/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.0663 - accuracy: 0.9809 - auc: 0.9923 - recall: 0.8690 - precision: 0.9162 - val_loss: 0.0985 - val_accuracy: 0.9681 - val_auc: 0.9839 - val_recall: 0.8619 - val_precision: 0.8077\n",
      "Epoch 30/64\n",
      "1624/1624 [==============================] - 148s 91ms/step - loss: 0.0655 - accuracy: 0.9811 - auc: 0.9918 - recall: 0.8692 - precision: 0.9178 - val_loss: 0.0976 - val_accuracy: 0.9707 - val_auc: 0.9799 - val_recall: 0.8041 - val_precision: 0.8707\n",
      "Epoch 31/64\n",
      "1624/1624 [==============================] - 147s 90ms/step - loss: 0.0631 - accuracy: 0.9821 - auc: 0.9920 - recall: 0.8760 - precision: 0.9229 - val_loss: 0.1009 - val_accuracy: 0.9707 - val_auc: 0.9792 - val_recall: 0.7985 - val_precision: 0.8753\n",
      "Epoch 32/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0623 - accuracy: 0.9820 - auc: 0.9926 - recall: 0.8743 - precision: 0.9230 - val_loss: 0.0973 - val_accuracy: 0.9686 - val_auc: 0.9817 - val_recall: 0.8414 - val_precision: 0.8245\n",
      "Epoch 33/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0600 - accuracy: 0.9832 - auc: 0.9929 - recall: 0.8826 - precision: 0.9288 - val_loss: 0.0968 - val_accuracy: 0.9707 - val_auc: 0.9822 - val_recall: 0.8358 - val_precision: 0.8469\n",
      "Epoch 34/64\n",
      "1624/1624 [==============================] - 147s 91ms/step - loss: 0.0559 - accuracy: 0.9850 - auc: 0.9941 - recall: 0.8942 - precision: 0.9373 - val_loss: 0.0943 - val_accuracy: 0.9723 - val_auc: 0.9821 - val_recall: 0.8340 - val_precision: 0.8629\n",
      "Epoch 35/64\n",
      "1624/1624 [==============================] - 149s 92ms/step - loss: 0.0552 - accuracy: 0.9851 - auc: 0.9941 - recall: 0.8934 - precision: 0.9398 - val_loss: 0.0956 - val_accuracy: 0.9719 - val_auc: 0.9818 - val_recall: 0.8321 - val_precision: 0.8610\n",
      "Epoch 36/64\n",
      "1624/1624 [==============================] - 152s 93ms/step - loss: 0.0547 - accuracy: 0.9854 - auc: 0.9942 - recall: 0.8961 - precision: 0.9408 - val_loss: 0.0968 - val_accuracy: 0.9714 - val_auc: 0.9817 - val_recall: 0.8228 - val_precision: 0.8630\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 13s 56ms/step - loss: 0.1058 - accuracy: 0.9728 - auc: 0.9747 - recall: 0.8383 - precision: 0.8574\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    #keras.layers.InputLayer(input_shape=(20, 20, 1)),\n",
    "    conv_block(32),\n",
    "    conv_block(64),\n",
    "    conv_block(128),\n",
    "    conv_block(256),\n",
    "    conv_block(256),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_4 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 29s 17ms/step - loss: 0.1688 - accuracy: 0.9479 - auc: 0.9219 - recall: 0.5610 - precision: 0.8138 - val_loss: 0.1664 - val_accuracy: 0.9574 - val_auc: 0.9582 - val_recall: 0.7167 - val_precision: 0.7954\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.1108 - accuracy: 0.9655 - auc: 0.9712 - recall: 0.7255 - precision: 0.8775 - val_loss: 0.1071 - val_accuracy: 0.9683 - val_auc: 0.9720 - val_recall: 0.7605 - val_precision: 0.8753\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0924 - accuracy: 0.9729 - auc: 0.9810 - recall: 0.7869 - precision: 0.9054 - val_loss: 0.1032 - val_accuracy: 0.9747 - val_auc: 0.9829 - val_recall: 0.7643 - val_precision: 0.9481\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0808 - accuracy: 0.9778 - auc: 0.9859 - recall: 0.8240 - precision: 0.9264 - val_loss: 0.0988 - val_accuracy: 0.9721 - val_auc: 0.9850 - val_recall: 0.7947 - val_precision: 0.8875\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0767 - accuracy: 0.9804 - auc: 0.9886 - recall: 0.8496 - precision: 0.9306 - val_loss: 0.1099 - val_accuracy: 0.9688 - val_auc: 0.9839 - val_recall: 0.8346 - val_precision: 0.8252\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0687 - accuracy: 0.9836 - auc: 0.9923 - recall: 0.8752 - precision: 0.9422 - val_loss: 0.1115 - val_accuracy: 0.9711 - val_auc: 0.9819 - val_recall: 0.8384 - val_precision: 0.8432\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0647 - accuracy: 0.9857 - auc: 0.9943 - recall: 0.8922 - precision: 0.9489 - val_loss: 0.0955 - val_accuracy: 0.9773 - val_auc: 0.9833 - val_recall: 0.8308 - val_precision: 0.9123\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0618 - accuracy: 0.9866 - auc: 0.9951 - recall: 0.9037 - precision: 0.9479 - val_loss: 0.1028 - val_accuracy: 0.9747 - val_auc: 0.9791 - val_recall: 0.8365 - val_precision: 0.8800\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 32s 19ms/step - loss: 0.0575 - accuracy: 0.9890 - auc: 0.9959 - recall: 0.9251 - precision: 0.9535 - val_loss: 0.1045 - val_accuracy: 0.9761 - val_auc: 0.9845 - val_recall: 0.8498 - val_precision: 0.8834\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0577 - accuracy: 0.9894 - auc: 0.9957 - recall: 0.9279 - precision: 0.9559 - val_loss: 0.1104 - val_accuracy: 0.9723 - val_auc: 0.9849 - val_recall: 0.8631 - val_precision: 0.8376\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0551 - accuracy: 0.9902 - auc: 0.9968 - recall: 0.9365 - precision: 0.9559 - val_loss: 0.2460 - val_accuracy: 0.9430 - val_auc: 0.9741 - val_recall: 0.9144 - val_precision: 0.6288\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0526 - accuracy: 0.9912 - auc: 0.9974 - recall: 0.9396 - precision: 0.9632 - val_loss: 0.1166 - val_accuracy: 0.9742 - val_auc: 0.9719 - val_recall: 0.7490 - val_precision: 0.9586\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0396 - accuracy: 0.9960 - auc: 0.9989 - recall: 0.9719 - precision: 0.9843 - val_loss: 0.0973 - val_accuracy: 0.9806 - val_auc: 0.9838 - val_recall: 0.8612 - val_precision: 0.9207\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0333 - accuracy: 0.9978 - auc: 0.9993 - recall: 0.9870 - precision: 0.9895 - val_loss: 0.1112 - val_accuracy: 0.9808 - val_auc: 0.9795 - val_recall: 0.8631 - val_precision: 0.9209\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0301 - accuracy: 0.9986 - auc: 0.9997 - recall: 0.9920 - precision: 0.9922 - val_loss: 0.1129 - val_accuracy: 0.9815 - val_auc: 0.9744 - val_recall: 0.8688 - val_precision: 0.9232\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0278 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9941 - precision: 0.9937 - val_loss: 0.1215 - val_accuracy: 0.9816 - val_auc: 0.9730 - val_recall: 0.8669 - val_precision: 0.9268\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0268 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9937 - precision: 0.9935 - val_loss: 0.1383 - val_accuracy: 0.9813 - val_auc: 0.9682 - val_recall: 0.8688 - val_precision: 0.9214\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0253 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9983 - precision: 0.9935 - val_loss: 0.1400 - val_accuracy: 0.9816 - val_auc: 0.9649 - val_recall: 0.8631 - val_precision: 0.9303\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0248 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9977 - precision: 0.9956 - val_loss: 0.1439 - val_accuracy: 0.9811 - val_auc: 0.9646 - val_recall: 0.8707 - val_precision: 0.9178\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0246 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9981 - precision: 0.9950 - val_loss: 0.1498 - val_accuracy: 0.9815 - val_auc: 0.9639 - val_recall: 0.8726 - val_precision: 0.9198\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0243 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9979 - precision: 0.9958 - val_loss: 0.1602 - val_accuracy: 0.9813 - val_auc: 0.9611 - val_recall: 0.8669 - val_precision: 0.9231\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0240 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9990 - precision: 0.9958 - val_loss: 0.1659 - val_accuracy: 0.9813 - val_auc: 0.9618 - val_recall: 0.8707 - val_precision: 0.9197\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0239 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9985 - precision: 0.9962 - val_loss: 0.1678 - val_accuracy: 0.9813 - val_auc: 0.9619 - val_recall: 0.8688 - val_precision: 0.9214\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.0958 - accuracy: 0.9766 - auc: 0.9859 - recall: 0.8157 - precision: 0.9076\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set.\n",
    "# predictions_CNN_prob_6 \n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(96, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_6 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 29s 17ms/step - loss: 0.1820 - accuracy: 0.9436 - auc: 0.9062 - recall: 0.5161 - precision: 0.7870 - val_loss: 0.1933 - val_accuracy: 0.9589 - val_auc: 0.9688 - val_recall: 0.6736 - val_precision: 0.8480\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.1162 - accuracy: 0.9647 - auc: 0.9660 - recall: 0.7164 - precision: 0.8704 - val_loss: 0.1910 - val_accuracy: 0.9674 - val_auc: 0.9828 - val_recall: 0.8566 - val_precision: 0.8021\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0971 - accuracy: 0.9713 - auc: 0.9779 - recall: 0.7686 - precision: 0.8989 - val_loss: 0.1558 - val_accuracy: 0.9556 - val_auc: 0.9654 - val_recall: 0.6962 - val_precision: 0.7953\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0847 - accuracy: 0.9759 - auc: 0.9849 - recall: 0.8146 - precision: 0.9094 - val_loss: 0.0968 - val_accuracy: 0.9731 - val_auc: 0.9836 - val_recall: 0.7623 - val_precision: 0.9330\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0794 - accuracy: 0.9796 - auc: 0.9867 - recall: 0.8399 - precision: 0.9282 - val_loss: 0.1193 - val_accuracy: 0.9730 - val_auc: 0.9868 - val_recall: 0.8377 - val_precision: 0.8638\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0709 - accuracy: 0.9826 - auc: 0.9921 - recall: 0.8667 - precision: 0.9359 - val_loss: 0.1211 - val_accuracy: 0.9756 - val_auc: 0.9900 - val_recall: 0.8868 - val_precision: 0.8530\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0655 - accuracy: 0.9850 - auc: 0.9932 - recall: 0.8895 - precision: 0.9414 - val_loss: 0.1748 - val_accuracy: 0.9648 - val_auc: 0.9858 - val_recall: 0.8943 - val_precision: 0.7633\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.0639 - accuracy: 0.9858 - auc: 0.9944 - recall: 0.8970 - precision: 0.9427 - val_loss: 0.1090 - val_accuracy: 0.9742 - val_auc: 0.9871 - val_recall: 0.8623 - val_precision: 0.8574\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0597 - accuracy: 0.9874 - auc: 0.9963 - recall: 0.9136 - precision: 0.9449 - val_loss: 0.1074 - val_accuracy: 0.9731 - val_auc: 0.9808 - val_recall: 0.7906 - val_precision: 0.9050\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0414 - accuracy: 0.9949 - auc: 0.9988 - recall: 0.9627 - precision: 0.9801 - val_loss: 0.0890 - val_accuracy: 0.9811 - val_auc: 0.9870 - val_recall: 0.8792 - val_precision: 0.9119\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0329 - accuracy: 0.9972 - auc: 0.9996 - recall: 0.9828 - precision: 0.9867 - val_loss: 0.0992 - val_accuracy: 0.9816 - val_auc: 0.9803 - val_recall: 0.8849 - val_precision: 0.9125\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0291 - accuracy: 0.9984 - auc: 0.9997 - recall: 0.9908 - precision: 0.9913 - val_loss: 0.1220 - val_accuracy: 0.9813 - val_auc: 0.9679 - val_recall: 0.8736 - val_precision: 0.9187\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0271 - accuracy: 0.9987 - auc: 0.9999 - recall: 0.9932 - precision: 0.9923 - val_loss: 0.1309 - val_accuracy: 0.9822 - val_auc: 0.9662 - val_recall: 0.8830 - val_precision: 0.9194\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0257 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9932 - precision: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9816 - val_auc: 0.9675 - val_recall: 0.8792 - val_precision: 0.9173\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0243 - accuracy: 0.9991 - auc: 1.0000 - recall: 0.9957 - precision: 0.9947 - val_loss: 0.1586 - val_accuracy: 0.9820 - val_auc: 0.9630 - val_recall: 0.8811 - val_precision: 0.9193\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0228 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9972 - precision: 0.9970 - val_loss: 0.1606 - val_accuracy: 0.9813 - val_auc: 0.9630 - val_recall: 0.8811 - val_precision: 0.9121\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0228 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9972 - precision: 0.9960 - val_loss: 0.1626 - val_accuracy: 0.9815 - val_auc: 0.9639 - val_recall: 0.8811 - val_precision: 0.9139\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.0223 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9977 - precision: 0.9966 - val_loss: 0.1689 - val_accuracy: 0.9823 - val_auc: 0.9628 - val_recall: 0.8906 - val_precision: 0.9147\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 30s 18ms/step - loss: 0.0222 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9987 - precision: 0.9964 - val_loss: 0.1779 - val_accuracy: 0.9818 - val_auc: 0.9630 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0218 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9991 - precision: 0.9964 - val_loss: 0.1863 - val_accuracy: 0.9822 - val_auc: 0.9611 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9991 - precision: 0.9958 - val_loss: 0.1888 - val_accuracy: 0.9818 - val_auc: 0.9603 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 31s 19ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9981 - precision: 0.9966 - val_loss: 0.1881 - val_accuracy: 0.9822 - val_auc: 0.9603 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0218 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9991 - precision: 0.9960 - val_loss: 0.1897 - val_accuracy: 0.9818 - val_auc: 0.9611 - val_recall: 0.8830 - val_precision: 0.9159\n",
      "Epoch 24/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0216 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9991 - precision: 0.9970 - val_loss: 0.1914 - val_accuracy: 0.9822 - val_auc: 0.9603 - val_recall: 0.8849 - val_precision: 0.9178\n",
      "Epoch 25/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0217 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9996 - precision: 0.9968 - val_loss: 0.1942 - val_accuracy: 0.9818 - val_auc: 0.9603 - val_recall: 0.8811 - val_precision: 0.9175\n",
      "Epoch 26/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0216 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9998 - precision: 0.9966 - val_loss: 0.1926 - val_accuracy: 0.9822 - val_auc: 0.9593 - val_recall: 0.8868 - val_precision: 0.9162\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.0849 - accuracy: 0.9816 - auc: 0.9872 - recall: 0.8723 - precision: 0.9236\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. => to submit\n",
    "# predictions_CNN_prob_7\n",
    "# normally sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_7 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  8.565439e-06\n",
      "1          1  6.351068e-05\n",
      "2          2  2.352402e-05\n",
      "3          3  2.126926e-09\n",
      "4          4  1.668296e-07\n",
      "...      ...           ...\n",
      "30912  30912  1.296144e-04\n",
      "30913  30913  3.701574e-03\n",
      "30914  30914  2.170700e-01\n",
      "30915  30915  8.016825e-06\n",
      "30916  30916  2.035295e-06\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_7[0], \"predictions_CNN_prob_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 30s 17ms/step - loss: 0.2661 - accuracy: 0.9128 - auc: 0.8316 - recall: 0.2470 - precision: 0.5385 - val_loss: 0.2039 - val_accuracy: 0.9463 - val_auc: 0.9604 - val_recall: 0.4736 - val_precision: 0.8901\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 30s 19ms/step - loss: 0.1632 - accuracy: 0.9481 - auc: 0.9397 - recall: 0.5320 - precision: 0.8336 - val_loss: 0.2349 - val_accuracy: 0.9612 - val_auc: 0.9686 - val_recall: 0.7472 - val_precision: 0.8148\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.1337 - accuracy: 0.9596 - auc: 0.9597 - recall: 0.6445 - precision: 0.8759 - val_loss: 0.1656 - val_accuracy: 0.9633 - val_auc: 0.9681 - val_recall: 0.6887 - val_precision: 0.8859\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.1103 - accuracy: 0.9685 - auc: 0.9749 - recall: 0.7243 - precision: 0.9089 - val_loss: 0.2215 - val_accuracy: 0.9702 - val_auc: 0.9795 - val_recall: 0.7887 - val_precision: 0.8745\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.1054 - accuracy: 0.9700 - auc: 0.9789 - recall: 0.7432 - precision: 0.9089 - val_loss: 0.1399 - val_accuracy: 0.9645 - val_auc: 0.9751 - val_recall: 0.6660 - val_precision: 0.9265\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0941 - accuracy: 0.9752 - auc: 0.9843 - recall: 0.7941 - precision: 0.9210 - val_loss: 0.1393 - val_accuracy: 0.9707 - val_auc: 0.9850 - val_recall: 0.7321 - val_precision: 0.9349\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0849 - accuracy: 0.9781 - auc: 0.9886 - recall: 0.8235 - precision: 0.9258 - val_loss: 0.1368 - val_accuracy: 0.9754 - val_auc: 0.9844 - val_recall: 0.8245 - val_precision: 0.8992\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0838 - accuracy: 0.9798 - auc: 0.9893 - recall: 0.8384 - precision: 0.9316 - val_loss: 0.1353 - val_accuracy: 0.9770 - val_auc: 0.9895 - val_recall: 0.8528 - val_precision: 0.8915\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 33s 21ms/step - loss: 0.0771 - accuracy: 0.9818 - auc: 0.9919 - recall: 0.8584 - precision: 0.9346 - val_loss: 0.0935 - val_accuracy: 0.9763 - val_auc: 0.9857 - val_recall: 0.8415 - val_precision: 0.8938\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0733 - accuracy: 0.9837 - auc: 0.9930 - recall: 0.8750 - precision: 0.9405 - val_loss: 0.1120 - val_accuracy: 0.9773 - val_auc: 0.9837 - val_recall: 0.8528 - val_precision: 0.8950\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 35s 21ms/step - loss: 0.0679 - accuracy: 0.9853 - auc: 0.9941 - recall: 0.9067 - precision: 0.9293 - val_loss: 0.1766 - val_accuracy: 0.9543 - val_auc: 0.9579 - val_recall: 0.5264 - val_precision: 0.9555\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0704 - accuracy: 0.9859 - auc: 0.9938 - recall: 0.9102 - precision: 0.9326 - val_loss: 0.1050 - val_accuracy: 0.9735 - val_auc: 0.9881 - val_recall: 0.9038 - val_precision: 0.8244\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0645 - accuracy: 0.9870 - auc: 0.9954 - recall: 0.9176 - precision: 0.9374 - val_loss: 0.1038 - val_accuracy: 0.9754 - val_auc: 0.9855 - val_recall: 0.8038 - val_precision: 0.9181\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0643 - accuracy: 0.9879 - auc: 0.9958 - recall: 0.9189 - precision: 0.9461 - val_loss: 0.1071 - val_accuracy: 0.9745 - val_auc: 0.9791 - val_recall: 0.7925 - val_precision: 0.9190\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0477 - accuracy: 0.9933 - auc: 0.9987 - recall: 0.9606 - precision: 0.9653 - val_loss: 0.0926 - val_accuracy: 0.9802 - val_auc: 0.9869 - val_recall: 0.8792 - val_precision: 0.9031\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0399 - accuracy: 0.9963 - auc: 0.9992 - recall: 0.9804 - precision: 0.9783 - val_loss: 0.0992 - val_accuracy: 0.9811 - val_auc: 0.9828 - val_recall: 0.8811 - val_precision: 0.9103\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0360 - accuracy: 0.9969 - auc: 0.9999 - recall: 0.9855 - precision: 0.9803 - val_loss: 0.1137 - val_accuracy: 0.9799 - val_auc: 0.9806 - val_recall: 0.8887 - val_precision: 0.8920\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0336 - accuracy: 0.9977 - auc: 0.9998 - recall: 0.9902 - precision: 0.9843 - val_loss: 0.1296 - val_accuracy: 0.9809 - val_auc: 0.9767 - val_recall: 0.8925 - val_precision: 0.8992\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0328 - accuracy: 0.9979 - auc: 0.9998 - recall: 0.9898 - precision: 0.9866 - val_loss: 0.1333 - val_accuracy: 0.9801 - val_auc: 0.9733 - val_recall: 0.8849 - val_precision: 0.8967\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0308 - accuracy: 0.9981 - auc: 0.9998 - recall: 0.9949 - precision: 0.9846 - val_loss: 0.1486 - val_accuracy: 0.9813 - val_auc: 0.9663 - val_recall: 0.8830 - val_precision: 0.9105\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0291 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9970 - precision: 0.9903 - val_loss: 0.1512 - val_accuracy: 0.9815 - val_auc: 0.9673 - val_recall: 0.8868 - val_precision: 0.9091\n",
      "Epoch 22/128\n",
      "1624/1624 [==============================] - 34s 21ms/step - loss: 0.0288 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9966 - precision: 0.9894 - val_loss: 0.1557 - val_accuracy: 0.9818 - val_auc: 0.9664 - val_recall: 0.8811 - val_precision: 0.9175\n",
      "Epoch 23/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0287 - accuracy: 0.9988 - auc: 1.0000 - recall: 0.9974 - precision: 0.9894 - val_loss: 0.1615 - val_accuracy: 0.9816 - val_auc: 0.9654 - val_recall: 0.8868 - val_precision: 0.9109\n",
      "Epoch 24/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0287 - accuracy: 0.9988 - auc: 0.9999 - recall: 0.9979 - precision: 0.9892 - val_loss: 0.1694 - val_accuracy: 0.9813 - val_auc: 0.9635 - val_recall: 0.8811 - val_precision: 0.9121\n",
      "Epoch 25/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0281 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9981 - precision: 0.9901 - val_loss: 0.1731 - val_accuracy: 0.9813 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9073\n",
      "Epoch 26/128\n",
      "1624/1624 [==============================] - 32s 20ms/step - loss: 0.0281 - accuracy: 0.9989 - auc: 1.0000 - recall: 0.9979 - precision: 0.9903 - val_loss: 0.1740 - val_accuracy: 0.9816 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9109\n",
      "Epoch 27/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0283 - accuracy: 0.9990 - auc: 1.0000 - recall: 0.9977 - precision: 0.9909 - val_loss: 0.1747 - val_accuracy: 0.9815 - val_auc: 0.9635 - val_recall: 0.8868 - val_precision: 0.9091\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 11ms/step - loss: 0.0861 - accuracy: 0.9828 - auc: 0.9878 - recall: 0.8858 - precision: 0.9247\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_8\n",
    "# normally sampled\n",
    "#  0.99076\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_8 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  9.057642e-07\n",
      "1          1  5.331922e-02\n",
      "2          2  1.952135e-04\n",
      "3          3  2.256034e-07\n",
      "4          4  3.165077e-06\n",
      "...      ...           ...\n",
      "30912  30912  3.877303e-04\n",
      "30913  30913  2.209523e-03\n",
      "30914  30914  2.677908e-01\n",
      "30915  30915  1.394543e-02\n",
      "30916  30916  1.163967e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_8[0], \"predictions_CNN_prob_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "1624/1624 [==============================] - 28s 16ms/step - loss: 0.1820 - accuracy: 0.9433 - auc: 0.9088 - recall: 0.4941 - precision: 0.8031 - val_loss: 0.1577 - val_accuracy: 0.9451 - val_auc: 0.9552 - val_recall: 0.4377 - val_precision: 0.9243\n",
      "Epoch 2/128\n",
      "1624/1624 [==============================] - 27s 16ms/step - loss: 0.1187 - accuracy: 0.9649 - auc: 0.9636 - recall: 0.7081 - precision: 0.8808 - val_loss: 0.1085 - val_accuracy: 0.9660 - val_auc: 0.9758 - val_recall: 0.7434 - val_precision: 0.8678\n",
      "Epoch 3/128\n",
      "1624/1624 [==============================] - 28s 17ms/step - loss: 0.0983 - accuracy: 0.9717 - auc: 0.9778 - recall: 0.7701 - precision: 0.9024 - val_loss: 0.0996 - val_accuracy: 0.9655 - val_auc: 0.9836 - val_recall: 0.6660 - val_precision: 0.9413\n",
      "Epoch 4/128\n",
      "1624/1624 [==============================] - 29s 18ms/step - loss: 0.0877 - accuracy: 0.9766 - auc: 0.9833 - recall: 0.8126 - precision: 0.9189 - val_loss: 0.1133 - val_accuracy: 0.9693 - val_auc: 0.9770 - val_recall: 0.7717 - val_precision: 0.8796\n",
      "Epoch 5/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0791 - accuracy: 0.9788 - auc: 0.9883 - recall: 0.8324 - precision: 0.9261 - val_loss: 0.1038 - val_accuracy: 0.9726 - val_auc: 0.9860 - val_recall: 0.8075 - val_precision: 0.8843\n",
      "Epoch 6/128\n",
      "1624/1624 [==============================] - 33s 20ms/step - loss: 0.0708 - accuracy: 0.9826 - auc: 0.9927 - recall: 0.8657 - precision: 0.9371 - val_loss: 0.1017 - val_accuracy: 0.9749 - val_auc: 0.9747 - val_recall: 0.8000 - val_precision: 0.9158\n",
      "Epoch 7/128\n",
      "1624/1624 [==============================] - 35s 22ms/step - loss: 0.0676 - accuracy: 0.9851 - auc: 0.9932 - recall: 0.8882 - precision: 0.9439 - val_loss: 0.1372 - val_accuracy: 0.9579 - val_auc: 0.9864 - val_recall: 0.9094 - val_precision: 0.7120\n",
      "Epoch 8/128\n",
      "1624/1624 [==============================] - 38s 23ms/step - loss: 0.0627 - accuracy: 0.9871 - auc: 0.9941 - recall: 0.9042 - precision: 0.9507 - val_loss: 0.1030 - val_accuracy: 0.9754 - val_auc: 0.9856 - val_recall: 0.8717 - val_precision: 0.8619\n",
      "Epoch 9/128\n",
      "1624/1624 [==============================] - 41s 25ms/step - loss: 0.0428 - accuracy: 0.9941 - auc: 0.9990 - recall: 0.9585 - precision: 0.9759 - val_loss: 0.0886 - val_accuracy: 0.9835 - val_auc: 0.9858 - val_recall: 0.8962 - val_precision: 0.9223\n",
      "Epoch 10/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0345 - accuracy: 0.9967 - auc: 0.9993 - recall: 0.9785 - precision: 0.9848 - val_loss: 0.0954 - val_accuracy: 0.9839 - val_auc: 0.9824 - val_recall: 0.8925 - val_precision: 0.9293\n",
      "Epoch 11/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0297 - accuracy: 0.9979 - auc: 0.9995 - recall: 0.9851 - precision: 0.9912 - val_loss: 0.1114 - val_accuracy: 0.9830 - val_auc: 0.9779 - val_recall: 0.8981 - val_precision: 0.9154\n",
      "Epoch 12/128\n",
      "1624/1624 [==============================] - 39s 24ms/step - loss: 0.0276 - accuracy: 0.9982 - auc: 0.9997 - recall: 0.9896 - precision: 0.9906 - val_loss: 0.1139 - val_accuracy: 0.9837 - val_auc: 0.9723 - val_recall: 0.8868 - val_precision: 0.9325\n",
      "Epoch 13/128\n",
      "1624/1624 [==============================] - 45s 28ms/step - loss: 0.0256 - accuracy: 0.9987 - auc: 1.0000 - recall: 0.9932 - precision: 0.9919 - val_loss: 0.1197 - val_accuracy: 0.9841 - val_auc: 0.9687 - val_recall: 0.8774 - val_precision: 0.9451\n",
      "Epoch 14/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0247 - accuracy: 0.9986 - auc: 0.9999 - recall: 0.9921 - precision: 0.9923 - val_loss: 0.1319 - val_accuracy: 0.9830 - val_auc: 0.9649 - val_recall: 0.8792 - val_precision: 0.9320\n",
      "Epoch 15/128\n",
      "1624/1624 [==============================] - 35s 21ms/step - loss: 0.0227 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9966 - precision: 0.9949 - val_loss: 0.1354 - val_accuracy: 0.9835 - val_auc: 0.9642 - val_recall: 0.8811 - val_precision: 0.9359\n",
      "Epoch 16/128\n",
      "1624/1624 [==============================] - 36s 22ms/step - loss: 0.0223 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9983 - precision: 0.9958 - val_loss: 0.1410 - val_accuracy: 0.9839 - val_auc: 0.9632 - val_recall: 0.8811 - val_precision: 0.9396\n",
      "Epoch 17/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0219 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9979 - precision: 0.9966 - val_loss: 0.1452 - val_accuracy: 0.9832 - val_auc: 0.9640 - val_recall: 0.8849 - val_precision: 0.9287\n",
      "Epoch 18/128\n",
      "1624/1624 [==============================] - 47s 29ms/step - loss: 0.0218 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9985 - precision: 0.9958 - val_loss: 0.1487 - val_accuracy: 0.9841 - val_auc: 0.9632 - val_recall: 0.8849 - val_precision: 0.9380\n",
      "Epoch 19/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0215 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9981 - precision: 0.9966 - val_loss: 0.1547 - val_accuracy: 0.9834 - val_auc: 0.9595 - val_recall: 0.8868 - val_precision: 0.9289\n",
      "Epoch 20/128\n",
      "1624/1624 [==============================] - 40s 25ms/step - loss: 0.0213 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9985 - precision: 0.9970 - val_loss: 0.1552 - val_accuracy: 0.9834 - val_auc: 0.9605 - val_recall: 0.8868 - val_precision: 0.9289\n",
      "Epoch 21/128\n",
      "1624/1624 [==============================] - 37s 23ms/step - loss: 0.0216 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9974 - precision: 0.9955 - val_loss: 0.1561 - val_accuracy: 0.9835 - val_auc: 0.9586 - val_recall: 0.8868 - val_precision: 0.9307\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 0.0862 - accuracy: 0.9809 - auc: 0.9883 - recall: 0.8881 - precision: 0.9037\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_9\n",
    "# normally sampled\n",
    "#  Kaggle: 0.99249\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_9 = model_score(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  4.721542e-06\n",
      "1          1  8.080629e-03\n",
      "2          2  3.323448e-07\n",
      "3          3  5.033775e-09\n",
      "4          4  1.272920e-08\n",
      "...      ...           ...\n",
      "30912  30912  2.600307e-05\n",
      "30913  30913  1.119968e-02\n",
      "30914  30914  2.807036e-01\n",
      "30915  30915  9.110881e-10\n",
      "30916  30916  4.104823e-08\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_9[0], \"predictions_CNN_prob_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2954/2954 [==============================] - 63s 21ms/step - loss: 0.2408 - accuracy: 0.9091 - auc: 0.9677 - recall: 0.9155 - precision: 0.9041 - val_loss: 0.1265 - val_accuracy: 0.9596 - val_auc: 0.9703 - val_recall: 0.8000 - val_precision: 0.7786\n",
      "Epoch 2/128\n",
      "2954/2954 [==============================] - 65s 22ms/step - loss: 0.1121 - accuracy: 0.9669 - auc: 0.9932 - recall: 0.9740 - precision: 0.9604 - val_loss: 0.1452 - val_accuracy: 0.9520 - val_auc: 0.9742 - val_recall: 0.8844 - val_precision: 0.6925\n",
      "Epoch 3/128\n",
      "2954/2954 [==============================] - 62s 21ms/step - loss: 0.0858 - accuracy: 0.9791 - auc: 0.9966 - recall: 0.9842 - precision: 0.9744 - val_loss: 0.1323 - val_accuracy: 0.9629 - val_auc: 0.9699 - val_recall: 0.8752 - val_precision: 0.7657\n",
      "Epoch 4/128\n",
      "2954/2954 [==============================] - 56s 19ms/step - loss: 0.0756 - accuracy: 0.9844 - auc: 0.9977 - recall: 0.9878 - precision: 0.9811 - val_loss: 0.1678 - val_accuracy: 0.9555 - val_auc: 0.9773 - val_recall: 0.9046 - val_precision: 0.7063\n",
      "Epoch 5/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0676 - accuracy: 0.9876 - auc: 0.9986 - recall: 0.9904 - precision: 0.9850 - val_loss: 0.1874 - val_accuracy: 0.9586 - val_auc: 0.9765 - val_recall: 0.9009 - val_precision: 0.7263\n",
      "Epoch 6/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0647 - accuracy: 0.9899 - auc: 0.9986 - recall: 0.9922 - precision: 0.9878 - val_loss: 0.1289 - val_accuracy: 0.9738 - val_auc: 0.9729 - val_recall: 0.8477 - val_precision: 0.8717\n",
      "Epoch 7/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0419 - accuracy: 0.9971 - auc: 0.9998 - recall: 0.9982 - precision: 0.9960 - val_loss: 0.1507 - val_accuracy: 0.9792 - val_auc: 0.9625 - val_recall: 0.8624 - val_precision: 0.9126\n",
      "Epoch 8/128\n",
      "2954/2954 [==============================] - 59s 20ms/step - loss: 0.0347 - accuracy: 0.9987 - auc: 0.9999 - recall: 0.9990 - precision: 0.9983 - val_loss: 0.1586 - val_accuracy: 0.9808 - val_auc: 0.9625 - val_recall: 0.8936 - val_precision: 0.9019\n",
      "Epoch 9/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0319 - accuracy: 0.9991 - auc: 1.0000 - recall: 0.9996 - precision: 0.9986 - val_loss: 0.1801 - val_accuracy: 0.9811 - val_auc: 0.9558 - val_recall: 0.8697 - val_precision: 0.9258\n",
      "Epoch 10/128\n",
      "2954/2954 [==============================] - 56s 19ms/step - loss: 0.0297 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.2028 - val_accuracy: 0.9804 - val_auc: 0.9505 - val_recall: 0.8569 - val_precision: 0.9303\n",
      "Epoch 11/128\n",
      "2954/2954 [==============================] - 65s 22ms/step - loss: 0.0286 - accuracy: 0.9993 - auc: 1.0000 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.1881 - val_accuracy: 0.9801 - val_auc: 0.9537 - val_recall: 0.8679 - val_precision: 0.9167\n",
      "Epoch 12/128\n",
      "2954/2954 [==============================] - 57s 19ms/step - loss: 0.0271 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1936 - val_accuracy: 0.9797 - val_auc: 0.9521 - val_recall: 0.8569 - val_precision: 0.9229\n",
      "Epoch 13/128\n",
      "2954/2954 [==============================] - 55s 19ms/step - loss: 0.0267 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1990 - val_accuracy: 0.9802 - val_auc: 0.9504 - val_recall: 0.8550 - val_precision: 0.9301\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1244 - accuracy: 0.9575 - auc: 0.9731 - recall: 0.8063 - precision: 0.7362\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_10\n",
    "# adasyn sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_10 = model_score(model, x_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.2203 - accuracy: 0.9206 - auc: 0.9730 - recall: 0.9299 - precision: 0.9128 - val_loss: 0.1348 - val_accuracy: 0.9548 - val_auc: 0.9692 - val_recall: 0.7688 - val_precision: 0.7563\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.1031 - accuracy: 0.9718 - auc: 0.9942 - recall: 0.9769 - precision: 0.9670 - val_loss: 0.1425 - val_accuracy: 0.9591 - val_auc: 0.9657 - val_recall: 0.7284 - val_precision: 0.8186\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0822 - accuracy: 0.9811 - auc: 0.9969 - recall: 0.9847 - precision: 0.9777 - val_loss: 0.1169 - val_accuracy: 0.9678 - val_auc: 0.9759 - val_recall: 0.7927 - val_precision: 0.8554\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0707 - accuracy: 0.9869 - auc: 0.9981 - recall: 0.9893 - precision: 0.9846 - val_loss: 0.1204 - val_accuracy: 0.9731 - val_auc: 0.9713 - val_recall: 0.8220 - val_precision: 0.8854\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0670 - accuracy: 0.9883 - auc: 0.9986 - recall: 0.9904 - precision: 0.9863 - val_loss: 0.1262 - val_accuracy: 0.9679 - val_auc: 0.9844 - val_recall: 0.9083 - val_precision: 0.7857\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0627 - accuracy: 0.9907 - auc: 0.9988 - recall: 0.9917 - precision: 0.9897 - val_loss: 0.1139 - val_accuracy: 0.9757 - val_auc: 0.9758 - val_recall: 0.8220 - val_precision: 0.9124\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0599 - accuracy: 0.9917 - auc: 0.9991 - recall: 0.9925 - precision: 0.9910 - val_loss: 0.1413 - val_accuracy: 0.9719 - val_auc: 0.9695 - val_recall: 0.8495 - val_precision: 0.8527\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0580 - accuracy: 0.9925 - auc: 0.9993 - recall: 0.9936 - precision: 0.9915 - val_loss: 0.1476 - val_accuracy: 0.9745 - val_auc: 0.9684 - val_recall: 0.8514 - val_precision: 0.8755\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0560 - accuracy: 0.9935 - auc: 0.9994 - recall: 0.9940 - precision: 0.9930 - val_loss: 0.1426 - val_accuracy: 0.9726 - val_auc: 0.9711 - val_recall: 0.8624 - val_precision: 0.8499\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0560 - accuracy: 0.9937 - auc: 0.9994 - recall: 0.9946 - precision: 0.9929 - val_loss: 0.1717 - val_accuracy: 0.9652 - val_auc: 0.9739 - val_recall: 0.8991 - val_precision: 0.7704\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0540 - accuracy: 0.9944 - auc: 0.9995 - recall: 0.9956 - precision: 0.9932 - val_loss: 0.1651 - val_accuracy: 0.9671 - val_auc: 0.9715 - val_recall: 0.8917 - val_precision: 0.7877\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0415 - accuracy: 0.9983 - auc: 0.9999 - recall: 0.9988 - precision: 0.9978 - val_loss: 0.1730 - val_accuracy: 0.9804 - val_auc: 0.9581 - val_recall: 0.8661 - val_precision: 0.9219\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0369 - accuracy: 0.9992 - auc: 1.0000 - recall: 0.9995 - precision: 0.9989 - val_loss: 0.1855 - val_accuracy: 0.9809 - val_auc: 0.9571 - val_recall: 0.8642 - val_precision: 0.9290\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0347 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.1935 - val_accuracy: 0.9801 - val_auc: 0.9563 - val_recall: 0.8716 - val_precision: 0.9135\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0331 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.2230 - val_accuracy: 0.9804 - val_auc: 0.9452 - val_recall: 0.8624 - val_precision: 0.9252\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 59s 20ms/step - loss: 0.0318 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.2265 - val_accuracy: 0.9804 - val_auc: 0.9473 - val_recall: 0.8624 - val_precision: 0.9252\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0306 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9999 - precision: 0.9994 - val_loss: 0.2325 - val_accuracy: 0.9799 - val_auc: 0.9465 - val_recall: 0.8514 - val_precision: 0.9299\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0303 - accuracy: 0.9997 - auc: 1.0000 - recall: 1.0000 - precision: 0.9994 - val_loss: 0.2342 - val_accuracy: 0.9804 - val_auc: 0.9448 - val_recall: 0.8569 - val_precision: 0.9303\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1184 - accuracy: 0.9766 - auc: 0.9742 - recall: 0.8339 - precision: 0.8929\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_11\n",
    "# borderline sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_11 = model_score(model, x_train_borderline, y_train_borderline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  8.629061e-08\n",
      "1          1  1.916419e-05\n",
      "2          2  5.860349e-04\n",
      "3          3  2.802911e-07\n",
      "4          4  7.559953e-08\n",
      "...      ...           ...\n",
      "30912  30912  2.332528e-04\n",
      "30913  30913  1.318149e-02\n",
      "30914  30914  1.473697e-01\n",
      "30915  30915  8.662563e-06\n",
      "30916  30916  8.383747e-03\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_11[0], \"predictions_CNN_prob_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 60s 20ms/step - loss: 0.2020 - accuracy: 0.9265 - auc: 0.9775 - recall: 0.9234 - precision: 0.9291 - val_loss: 0.1181 - val_accuracy: 0.9622 - val_auc: 0.9772 - val_recall: 0.8349 - val_precision: 0.7804\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.1017 - accuracy: 0.9701 - auc: 0.9948 - recall: 0.9726 - precision: 0.9677 - val_loss: 0.1255 - val_accuracy: 0.9662 - val_auc: 0.9782 - val_recall: 0.8385 - val_precision: 0.8103\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0837 - accuracy: 0.9798 - auc: 0.9970 - recall: 0.9816 - precision: 0.9781 - val_loss: 0.1262 - val_accuracy: 0.9622 - val_auc: 0.9744 - val_recall: 0.8569 - val_precision: 0.7694\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0753 - accuracy: 0.9840 - auc: 0.9980 - recall: 0.9851 - precision: 0.9830 - val_loss: 0.1249 - val_accuracy: 0.9664 - val_auc: 0.9835 - val_recall: 0.8789 - val_precision: 0.7891\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0708 - accuracy: 0.9868 - auc: 0.9984 - recall: 0.9876 - precision: 0.9860 - val_loss: 0.1125 - val_accuracy: 0.9716 - val_auc: 0.9806 - val_recall: 0.8110 - val_precision: 0.8787\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0663 - accuracy: 0.9893 - auc: 0.9987 - recall: 0.9899 - precision: 0.9887 - val_loss: 0.1274 - val_accuracy: 0.9711 - val_auc: 0.9829 - val_recall: 0.8972 - val_precision: 0.8150\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0626 - accuracy: 0.9907 - auc: 0.9990 - recall: 0.9906 - precision: 0.9907 - val_loss: 0.1134 - val_accuracy: 0.9768 - val_auc: 0.9800 - val_recall: 0.8642 - val_precision: 0.8870\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0604 - accuracy: 0.9916 - auc: 0.9991 - recall: 0.9917 - precision: 0.9914 - val_loss: 0.1231 - val_accuracy: 0.9737 - val_auc: 0.9805 - val_recall: 0.8972 - val_precision: 0.8359\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0573 - accuracy: 0.9928 - auc: 0.9993 - recall: 0.9934 - precision: 0.9922 - val_loss: 0.1543 - val_accuracy: 0.9692 - val_auc: 0.9746 - val_recall: 0.8679 - val_precision: 0.8169\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0568 - accuracy: 0.9929 - auc: 0.9992 - recall: 0.9931 - precision: 0.9927 - val_loss: 0.1282 - val_accuracy: 0.9768 - val_auc: 0.9731 - val_recall: 0.8459 - val_precision: 0.9022\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0417 - accuracy: 0.9980 - auc: 0.9999 - recall: 0.9982 - precision: 0.9977 - val_loss: 0.1360 - val_accuracy: 0.9811 - val_auc: 0.9697 - val_recall: 0.8734 - val_precision: 0.9225\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0369 - accuracy: 0.9990 - auc: 0.9999 - recall: 0.9992 - precision: 0.9987 - val_loss: 0.1653 - val_accuracy: 0.9808 - val_auc: 0.9586 - val_recall: 0.8642 - val_precision: 0.9272\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0344 - accuracy: 0.9993 - auc: 0.9999 - recall: 0.9996 - precision: 0.9989 - val_loss: 0.1869 - val_accuracy: 0.9806 - val_auc: 0.9584 - val_recall: 0.8771 - val_precision: 0.9140\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0327 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9996 - precision: 0.9992 - val_loss: 0.1975 - val_accuracy: 0.9806 - val_auc: 0.9528 - val_recall: 0.8661 - val_precision: 0.9237\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0317 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9991 - val_loss: 0.1996 - val_accuracy: 0.9808 - val_auc: 0.9488 - val_recall: 0.8550 - val_precision: 0.9357\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0304 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9997 - precision: 0.9995 - val_loss: 0.1943 - val_accuracy: 0.9811 - val_auc: 0.9538 - val_recall: 0.8697 - val_precision: 0.9258\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0301 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.1967 - val_accuracy: 0.9809 - val_auc: 0.9538 - val_recall: 0.8697 - val_precision: 0.9240\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1049 - accuracy: 0.9736 - auc: 0.9851 - recall: 0.8157 - precision: 0.8757\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_12\n",
    "# svm sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_12 = model_score(model, x_train_svmsmote, y_train_svmsmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  1.182344e-03\n",
      "1          1  3.673962e-04\n",
      "2          2  1.781049e-05\n",
      "3          3  9.008203e-07\n",
      "4          4  5.624769e-05\n",
      "...      ...           ...\n",
      "30912  30912  3.286622e-03\n",
      "30913  30913  8.990210e-02\n",
      "30914  30914  1.148125e-01\n",
      "30915  30915  2.370128e-05\n",
      "30916  30916  1.280994e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_12[0], \"predictions_CNN_prob_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.2286 - accuracy: 0.9138 - auc: 0.9713 - recall: 0.9092 - precision: 0.9176 - val_loss: 0.3274 - val_accuracy: 0.9007 - val_auc: 0.9711 - val_recall: 0.9321 - val_precision: 0.4866\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.1145 - accuracy: 0.9663 - auc: 0.9932 - recall: 0.9706 - precision: 0.9624 - val_loss: 0.1495 - val_accuracy: 0.9428 - val_auc: 0.9744 - val_recall: 0.8972 - val_precision: 0.6409\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0913 - accuracy: 0.9769 - auc: 0.9963 - recall: 0.9802 - precision: 0.9737 - val_loss: 0.1258 - val_accuracy: 0.9653 - val_auc: 0.9833 - val_recall: 0.8807 - val_precision: 0.7805\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0806 - accuracy: 0.9828 - auc: 0.9976 - recall: 0.9860 - precision: 0.9796 - val_loss: 0.1250 - val_accuracy: 0.9645 - val_auc: 0.9861 - val_recall: 0.9064 - val_precision: 0.7623\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0714 - accuracy: 0.9865 - auc: 0.9984 - recall: 0.9894 - precision: 0.9836 - val_loss: 0.1242 - val_accuracy: 0.9714 - val_auc: 0.9754 - val_recall: 0.8606 - val_precision: 0.8405\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0658 - accuracy: 0.9891 - auc: 0.9988 - recall: 0.9911 - precision: 0.9872 - val_loss: 0.1244 - val_accuracy: 0.9716 - val_auc: 0.9804 - val_recall: 0.8826 - val_precision: 0.8279\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0630 - accuracy: 0.9908 - auc: 0.9989 - recall: 0.9919 - precision: 0.9896 - val_loss: 0.1226 - val_accuracy: 0.9718 - val_auc: 0.9800 - val_recall: 0.9028 - val_precision: 0.8173\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0605 - accuracy: 0.9916 - auc: 0.9991 - recall: 0.9927 - precision: 0.9905 - val_loss: 0.1264 - val_accuracy: 0.9697 - val_auc: 0.9797 - val_recall: 0.9064 - val_precision: 0.7994\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0576 - accuracy: 0.9929 - auc: 0.9993 - recall: 0.9942 - precision: 0.9917 - val_loss: 0.1382 - val_accuracy: 0.9747 - val_auc: 0.9744 - val_recall: 0.8734 - val_precision: 0.8608\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0568 - accuracy: 0.9932 - auc: 0.9994 - recall: 0.9936 - precision: 0.9929 - val_loss: 0.1475 - val_accuracy: 0.9733 - val_auc: 0.9669 - val_recall: 0.8110 - val_precision: 0.8966\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0573 - accuracy: 0.9934 - auc: 0.9993 - recall: 0.9937 - precision: 0.9932 - val_loss: 0.1439 - val_accuracy: 0.9731 - val_auc: 0.9757 - val_recall: 0.8844 - val_precision: 0.8397\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0559 - accuracy: 0.9939 - auc: 0.9994 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.1597 - val_accuracy: 0.9714 - val_auc: 0.9654 - val_recall: 0.7706 - val_precision: 0.9130\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0428 - accuracy: 0.9981 - auc: 0.9999 - recall: 0.9985 - precision: 0.9978 - val_loss: 0.1598 - val_accuracy: 0.9782 - val_auc: 0.9652 - val_recall: 0.8587 - val_precision: 0.9052\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0383 - accuracy: 0.9991 - auc: 0.9999 - recall: 0.9994 - precision: 0.9987 - val_loss: 0.1771 - val_accuracy: 0.9796 - val_auc: 0.9638 - val_recall: 0.8514 - val_precision: 0.9261\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 55s 19ms/step - loss: 0.0355 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9992 - val_loss: 0.1960 - val_accuracy: 0.9782 - val_auc: 0.9610 - val_recall: 0.8514 - val_precision: 0.9116\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0341 - accuracy: 0.9994 - auc: 1.0000 - recall: 0.9997 - precision: 0.9992 - val_loss: 0.2065 - val_accuracy: 0.9811 - val_auc: 0.9585 - val_recall: 0.8716 - val_precision: 0.9241\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0329 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.1847 - val_accuracy: 0.9801 - val_auc: 0.9666 - val_recall: 0.8881 - val_precision: 0.8996\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0317 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.1940 - val_accuracy: 0.9801 - val_auc: 0.9644 - val_recall: 0.8697 - val_precision: 0.9151\n",
      "Epoch 19/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0315 - accuracy: 0.9997 - auc: 1.0000 - recall: 1.0000 - precision: 0.9994 - val_loss: 0.1990 - val_accuracy: 0.9802 - val_auc: 0.9608 - val_recall: 0.8734 - val_precision: 0.9136\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1232 - accuracy: 0.9710 - auc: 0.9836 - recall: 0.9071 - precision: 0.7934\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_13\n",
    "# smotetomek sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_13 = model_score(model, x_train_tomek, y_train_tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2887/2887 [==============================] - 65s 22ms/step - loss: 0.2112 - accuracy: 0.9214 - auc: 0.9754 - recall: 0.9210 - precision: 0.9247 - val_loss: 0.1558 - val_accuracy: 0.9470 - val_auc: 0.9699 - val_recall: 0.8422 - val_precision: 0.6760\n",
      "Epoch 2/128\n",
      "2887/2887 [==============================] - 71s 24ms/step - loss: 0.0980 - accuracy: 0.9716 - auc: 0.9951 - recall: 0.9749 - precision: 0.9696 - val_loss: 0.1846 - val_accuracy: 0.9359 - val_auc: 0.9777 - val_recall: 0.9193 - val_precision: 0.6058\n",
      "Epoch 3/128\n",
      "2887/2887 [==============================] - 79s 27ms/step - loss: 0.0740 - accuracy: 0.9828 - auc: 0.9977 - recall: 0.9846 - precision: 0.9816 - val_loss: 0.2008 - val_accuracy: 0.9468 - val_auc: 0.9780 - val_recall: 0.9138 - val_precision: 0.6570\n",
      "Epoch 4/128\n",
      "2887/2887 [==============================] - 79s 28ms/step - loss: 0.0642 - accuracy: 0.9877 - auc: 0.9986 - recall: 0.9895 - precision: 0.9864 - val_loss: 0.1761 - val_accuracy: 0.9673 - val_auc: 0.9728 - val_recall: 0.8991 - val_precision: 0.7853\n",
      "Epoch 5/128\n",
      "2887/2887 [==============================] - 77s 27ms/step - loss: 0.0603 - accuracy: 0.9903 - auc: 0.9989 - recall: 0.9914 - precision: 0.9896 - val_loss: 0.1573 - val_accuracy: 0.9683 - val_auc: 0.9727 - val_recall: 0.8789 - val_precision: 0.8037\n",
      "Epoch 6/128\n",
      "2887/2887 [==============================] - 79s 27ms/step - loss: 0.0553 - accuracy: 0.9926 - auc: 0.9992 - recall: 0.9934 - precision: 0.9920 - val_loss: 0.2116 - val_accuracy: 0.9615 - val_auc: 0.9505 - val_recall: 0.8073 - val_precision: 0.7899\n",
      "Epoch 7/128\n",
      "2887/2887 [==============================] - 78s 27ms/step - loss: 0.0392 - accuracy: 0.9979 - auc: 0.9998 - recall: 0.9982 - precision: 0.9977 - val_loss: 0.1738 - val_accuracy: 0.9738 - val_auc: 0.9733 - val_recall: 0.8991 - val_precision: 0.8362\n",
      "Epoch 8/128\n",
      "2887/2887 [==============================] - 89s 31ms/step - loss: 0.0315 - accuracy: 0.9995 - auc: 1.0000 - recall: 0.9996 - precision: 0.9995 - val_loss: 0.2049 - val_accuracy: 0.9740 - val_auc: 0.9622 - val_recall: 0.8881 - val_precision: 0.8447\n",
      "Epoch 9/128\n",
      "2887/2887 [==============================] - 80s 28ms/step - loss: 0.0290 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.2154 - val_accuracy: 0.9733 - val_auc: 0.9574 - val_recall: 0.8789 - val_precision: 0.8448\n",
      "Epoch 10/128\n",
      "2887/2887 [==============================] - 80s 28ms/step - loss: 0.0269 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9998 - precision: 0.9997 - val_loss: 0.2415 - val_accuracy: 0.9740 - val_auc: 0.9568 - val_recall: 0.8881 - val_precision: 0.8447\n",
      "Epoch 11/128\n",
      "2887/2887 [==============================] - 69s 24ms/step - loss: 0.0252 - accuracy: 0.9998 - auc: 1.0000 - recall: 0.9998 - precision: 0.9998 - val_loss: 0.2547 - val_accuracy: 0.9738 - val_auc: 0.9547 - val_recall: 0.8826 - val_precision: 0.8468\n",
      "Epoch 12/128\n",
      "2887/2887 [==============================] - 62s 21ms/step - loss: 0.0240 - accuracy: 0.9999 - auc: 1.0000 - recall: 0.9999 - precision: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9747 - val_auc: 0.9502 - val_recall: 0.8826 - val_precision: 0.8544\n",
      "Epoch 13/128\n",
      "2887/2887 [==============================] - 58s 20ms/step - loss: 0.0237 - accuracy: 0.9999 - auc: 1.0000 - recall: 1.0000 - precision: 0.9999 - val_loss: 0.2668 - val_accuracy: 0.9742 - val_auc: 0.9502 - val_recall: 0.8844 - val_precision: 0.8486\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "226/226 [==============================] - 3s 12ms/step - loss: 0.1468 - accuracy: 0.9509 - auc: 0.9728 - recall: 0.8598 - precision: 0.6732\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_14\n",
    "# smoteen sampled\n",
    "# \n",
    "#  \n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_CNN_14 = model_score(model, x_train_smenn, y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 90s 30ms/step - loss: 0.2235 - accuracy: 0.9153 - auc: 0.9727 - recall: 0.9169 - precision: 0.9140 - val_loss: 0.1617 - val_accuracy: 0.9563 - val_auc: 0.9795 - val_recall: 0.8734 - val_precision: 0.7223\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 82s 28ms/step - loss: 0.1070 - accuracy: 0.9695 - auc: 0.9940 - recall: 0.9779 - precision: 0.9619 - val_loss: 0.1793 - val_accuracy: 0.9534 - val_auc: 0.9851 - val_recall: 0.9450 - val_precision: 0.6830\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0812 - accuracy: 0.9809 - auc: 0.9972 - recall: 0.9862 - precision: 0.9758 - val_loss: 0.1336 - val_accuracy: 0.9619 - val_auc: 0.9846 - val_recall: 0.9119 - val_precision: 0.7429\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0710 - accuracy: 0.9864 - auc: 0.9982 - recall: 0.9893 - precision: 0.9835 - val_loss: 0.2116 - val_accuracy: 0.9508 - val_auc: 0.9807 - val_recall: 0.9358 - val_precision: 0.6719\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0668 - accuracy: 0.9890 - auc: 0.9986 - recall: 0.9920 - precision: 0.9860 - val_loss: 0.1391 - val_accuracy: 0.9631 - val_auc: 0.9846 - val_recall: 0.9211 - val_precision: 0.7470\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 68s 23ms/step - loss: 0.0627 - accuracy: 0.9908 - auc: 0.9989 - recall: 0.9928 - precision: 0.9888 - val_loss: 0.1424 - val_accuracy: 0.9700 - val_auc: 0.9767 - val_recall: 0.9229 - val_precision: 0.7934\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 69s 23ms/step - loss: 0.0596 - accuracy: 0.9926 - auc: 0.9991 - recall: 0.9943 - precision: 0.9910 - val_loss: 0.1418 - val_accuracy: 0.9714 - val_auc: 0.9762 - val_recall: 0.9101 - val_precision: 0.8105\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0606 - accuracy: 0.9924 - auc: 0.9991 - recall: 0.9941 - precision: 0.9907 - val_loss: 0.1420 - val_accuracy: 0.9764 - val_auc: 0.9702 - val_recall: 0.8991 - val_precision: 0.8581\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0420 - accuracy: 0.9985 - auc: 0.9999 - recall: 0.9996 - precision: 0.9974 - val_loss: 0.1722 - val_accuracy: 0.9816 - val_auc: 0.9586 - val_recall: 0.8734 - val_precision: 0.9279\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0374 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9997 - precision: 0.9990 - val_loss: 0.1856 - val_accuracy: 0.9806 - val_auc: 0.9530 - val_recall: 0.8642 - val_precision: 0.9253\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 62s 21ms/step - loss: 0.0348 - accuracy: 0.9994 - auc: 0.9999 - recall: 0.9997 - precision: 0.9991 - val_loss: 0.2047 - val_accuracy: 0.9799 - val_auc: 0.9478 - val_recall: 0.8532 - val_precision: 0.9281\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0328 - accuracy: 0.9995 - auc: 0.9999 - recall: 0.9997 - precision: 0.9993 - val_loss: 0.1782 - val_accuracy: 0.9799 - val_auc: 0.9593 - val_recall: 0.8606 - val_precision: 0.9214\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0304 - accuracy: 0.9995 - auc: 0.9999 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.1842 - val_accuracy: 0.9808 - val_auc: 0.9489 - val_recall: 0.8532 - val_precision: 0.9375\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0292 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.1825 - val_accuracy: 0.9816 - val_auc: 0.9499 - val_recall: 0.8550 - val_precision: 0.9452\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 61s 21ms/step - loss: 0.0288 - accuracy: 0.9997 - auc: 1.0000 - recall: 0.9999 - precision: 0.9995 - val_loss: 0.1888 - val_accuracy: 0.9811 - val_auc: 0.9490 - val_recall: 0.8495 - val_precision: 0.9449\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 12ms/step - loss: 0.1329 - accuracy: 0.9622 - auc: 0.9865 - recall: 0.9134 - precision: 0.7268\n"
     ]
    }
   ],
   "source": [
    "# 5-layer on normally sampled train set. ===> submit\n",
    "# predictions_CNN_prob_15\n",
    "# random oversampled\n",
    "# \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_15 = model_score(model, x_train_oversam, y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Predicted\n",
      "0          0   0.000044\n",
      "1          1   0.000160\n",
      "2          2   0.027587\n",
      "3          3   0.000024\n",
      "4          4   0.003521\n",
      "...      ...        ...\n",
      "30912  30912   0.000028\n",
      "30913  30913   0.584994\n",
      "30914  30914   0.227613\n",
      "30915  30915   0.002541\n",
      "30916  30916   0.000012\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_15[0], \"predictions_CNN_prob_15_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MODEL BUILDING ============================================================================ \n",
      "\n",
      "Epoch 1/128\n",
      "2950/2950 [==============================] - 44s 14ms/step - loss: 0.2382 - accuracy: 0.9068 - auc: 0.9682 - recall: 0.9054 - precision: 0.9079 - val_loss: 0.1268 - val_accuracy: 0.9496 - val_auc: 0.9761 - val_recall: 0.8569 - val_precision: 0.6868\n",
      "Epoch 2/128\n",
      "2950/2950 [==============================] - 45s 15ms/step - loss: 0.1081 - accuracy: 0.9664 - auc: 0.9935 - recall: 0.9739 - precision: 0.9596 - val_loss: 0.1956 - val_accuracy: 0.9295 - val_auc: 0.9840 - val_recall: 0.9560 - val_precision: 0.5763\n",
      "Epoch 3/128\n",
      "2950/2950 [==============================] - 49s 16ms/step - loss: 0.0794 - accuracy: 0.9800 - auc: 0.9970 - recall: 0.9846 - precision: 0.9756 - val_loss: 0.1842 - val_accuracy: 0.9466 - val_auc: 0.9782 - val_recall: 0.9193 - val_precision: 0.6549\n",
      "Epoch 4/128\n",
      "2950/2950 [==============================] - 53s 18ms/step - loss: 0.0696 - accuracy: 0.9852 - auc: 0.9981 - recall: 0.9899 - precision: 0.9807 - val_loss: 0.1266 - val_accuracy: 0.9721 - val_auc: 0.9811 - val_recall: 0.9211 - val_precision: 0.8097\n",
      "Epoch 5/128\n",
      "2950/2950 [==============================] - 53s 18ms/step - loss: 0.0632 - accuracy: 0.9887 - auc: 0.9988 - recall: 0.9914 - precision: 0.9860 - val_loss: 0.1351 - val_accuracy: 0.9693 - val_auc: 0.9862 - val_recall: 0.9248 - val_precision: 0.7875\n",
      "Epoch 6/128\n",
      "2950/2950 [==============================] - 68s 23ms/step - loss: 0.0591 - accuracy: 0.9911 - auc: 0.9990 - recall: 0.9931 - precision: 0.9892 - val_loss: 0.1141 - val_accuracy: 0.9752 - val_auc: 0.9831 - val_recall: 0.8936 - val_precision: 0.8514\n",
      "Epoch 7/128\n",
      "2950/2950 [==============================] - 62s 21ms/step - loss: 0.0564 - accuracy: 0.9929 - auc: 0.9992 - recall: 0.9941 - precision: 0.9917 - val_loss: 0.1542 - val_accuracy: 0.9690 - val_auc: 0.9812 - val_recall: 0.9156 - val_precision: 0.7896\n",
      "Epoch 8/128\n",
      "2950/2950 [==============================] - 56s 19ms/step - loss: 0.0554 - accuracy: 0.9936 - auc: 0.9993 - recall: 0.9950 - precision: 0.9922 - val_loss: 0.1270 - val_accuracy: 0.9777 - val_auc: 0.9808 - val_recall: 0.9138 - val_precision: 0.8586\n",
      "Epoch 9/128\n",
      "2950/2950 [==============================] - 66s 22ms/step - loss: 0.0544 - accuracy: 0.9938 - auc: 0.9994 - recall: 0.9950 - precision: 0.9927 - val_loss: 0.1286 - val_accuracy: 0.9759 - val_auc: 0.9774 - val_recall: 0.8679 - val_precision: 0.8759\n",
      "Epoch 10/128\n",
      "2950/2950 [==============================] - 63s 21ms/step - loss: 0.0518 - accuracy: 0.9951 - auc: 0.9995 - recall: 0.9963 - precision: 0.9939 - val_loss: 0.1427 - val_accuracy: 0.9777 - val_auc: 0.9714 - val_recall: 0.9028 - val_precision: 0.8662\n",
      "Epoch 11/128\n",
      "2950/2950 [==============================] - 66s 22ms/step - loss: 0.0535 - accuracy: 0.9948 - auc: 0.9994 - recall: 0.9959 - precision: 0.9936 - val_loss: 0.1395 - val_accuracy: 0.9783 - val_auc: 0.9693 - val_recall: 0.8679 - val_precision: 0.8992\n",
      "Epoch 12/128\n",
      "2950/2950 [==============================] - 64s 22ms/step - loss: 0.0414 - accuracy: 0.9987 - auc: 0.9998 - recall: 0.9995 - precision: 0.9979 - val_loss: 0.1633 - val_accuracy: 0.9806 - val_auc: 0.9584 - val_recall: 0.8624 - val_precision: 0.9270\n",
      "Epoch 13/128\n",
      "2950/2950 [==============================] - 69s 23ms/step - loss: 0.0368 - accuracy: 0.9996 - auc: 0.9999 - recall: 0.9999 - precision: 0.9993 - val_loss: 0.2036 - val_accuracy: 0.9804 - val_auc: 0.9461 - val_recall: 0.8514 - val_precision: 0.9355\n",
      "Epoch 14/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0345 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9993 - val_loss: 0.2028 - val_accuracy: 0.9808 - val_auc: 0.9495 - val_recall: 0.8624 - val_precision: 0.9289\n",
      "Epoch 15/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0321 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.2135 - val_accuracy: 0.9804 - val_auc: 0.9513 - val_recall: 0.8642 - val_precision: 0.9235\n",
      "Epoch 16/128\n",
      "2950/2950 [==============================] - 58s 20ms/step - loss: 0.0302 - accuracy: 0.9996 - auc: 1.0000 - recall: 0.9998 - precision: 0.9994 - val_loss: 0.2205 - val_accuracy: 0.9804 - val_auc: 0.9449 - val_recall: 0.8514 - val_precision: 0.9355\n",
      "Epoch 17/128\n",
      "2950/2950 [==============================] - 57s 19ms/step - loss: 0.0288 - accuracy: 0.9998 - auc: 1.0000 - recall: 1.0000 - precision: 0.9996 - val_loss: 0.2232 - val_accuracy: 0.9808 - val_auc: 0.9458 - val_recall: 0.8550 - val_precision: 0.9357\n",
      "Epoch 18/128\n",
      "2950/2950 [==============================] - 67s 23ms/step - loss: 0.0285 - accuracy: 0.9998 - auc: 1.0000 - recall: 0.9999 - precision: 0.9996 - val_loss: 0.2274 - val_accuracy: 0.9806 - val_auc: 0.9440 - val_recall: 0.8550 - val_precision: 0.9339\n",
      "\n",
      " MODEL EVALUATION ON TEST SET ============================================================================ \n",
      "\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1079 - accuracy: 0.9777 - auc: 0.9843 - recall: 0.9008 - precision: 0.8537\n"
     ]
    }
   ],
   "source": [
    "# 4-layer on normally sampled train set. \n",
    "# predictions_CNN_prob_16\n",
    "# random over sampled\n",
    "#  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,)),\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=l2(0.00001), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dropout(0.6),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.00001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_CNN_16 = model_score(model, x_train_oversam, y_train_oversam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  1.243785e-11\n",
      "1          1  6.365884e-06\n",
      "2          2  9.675701e-10\n",
      "3          3  4.006355e-08\n",
      "4          4  1.434304e-04\n",
      "...      ...           ...\n",
      "30912  30912  1.194210e-06\n",
      "30913  30913  2.830749e-05\n",
      "30914  30914  5.575607e-01\n",
      "30915  30915  3.342547e-06\n",
      "30916  30916  1.045959e-05\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_to_csv(model_CNN_16[0], \"predictions_CNN_prob_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1443/1443 [==============================] - 27s 18ms/step - loss: 0.2865 - accuracy: 0.9114 - auc: 0.6964 - recall: 0.0551 - precision: 0.6705 - val_loss: 0.2606 - val_accuracy: 0.9179 - val_auc: 0.7582 - val_recall: 0.1430 - val_precision: 0.7784\n",
      "Epoch 2/128\n",
      "1443/1443 [==============================] - 25s 17ms/step - loss: 0.2508 - accuracy: 0.9214 - auc: 0.7710 - recall: 0.2203 - precision: 0.7259 - val_loss: 0.2435 - val_accuracy: 0.9220 - val_auc: 0.7862 - val_recall: 0.2652 - val_precision: 0.6931\n",
      "Epoch 3/128\n",
      "1443/1443 [==============================] - 29s 20ms/step - loss: 0.2395 - accuracy: 0.9251 - auc: 0.7915 - recall: 0.2665 - precision: 0.7498 - val_loss: 0.2837 - val_accuracy: 0.8982 - val_auc: 0.7946 - val_recall: 0.4214 - val_precision: 0.4410\n",
      "Epoch 4/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2344 - accuracy: 0.9261 - auc: 0.8055 - recall: 0.2964 - precision: 0.7331 - val_loss: 0.2363 - val_accuracy: 0.9198 - val_auc: 0.8206 - val_recall: 0.4148 - val_precision: 0.5871\n",
      "Epoch 5/128\n",
      "1443/1443 [==============================] - 32s 22ms/step - loss: 0.2300 - accuracy: 0.9277 - auc: 0.8157 - recall: 0.3183 - precision: 0.7402 - val_loss: 0.2392 - val_accuracy: 0.9232 - val_auc: 0.8149 - val_recall: 0.3958 - val_precision: 0.6267\n",
      "Epoch 6/128\n",
      "1443/1443 [==============================] - 32s 22ms/step - loss: 0.2278 - accuracy: 0.9288 - auc: 0.8195 - recall: 0.3321 - precision: 0.7455 - val_loss: 0.2311 - val_accuracy: 0.9270 - val_auc: 0.8352 - val_recall: 0.3258 - val_precision: 0.7257\n",
      "Epoch 7/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2242 - accuracy: 0.9295 - auc: 0.8278 - recall: 0.3435 - precision: 0.7456 - val_loss: 0.2291 - val_accuracy: 0.9288 - val_auc: 0.8293 - val_recall: 0.4129 - val_precision: 0.6834\n",
      "Epoch 8/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2196 - accuracy: 0.9313 - auc: 0.8373 - recall: 0.3489 - precision: 0.7730 - val_loss: 0.2179 - val_accuracy: 0.9301 - val_auc: 0.8460 - val_recall: 0.3381 - val_precision: 0.7677\n",
      "Epoch 9/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2162 - accuracy: 0.9329 - auc: 0.8422 - recall: 0.3729 - precision: 0.7733 - val_loss: 0.2218 - val_accuracy: 0.9300 - val_auc: 0.8425 - val_recall: 0.3703 - val_precision: 0.7322\n",
      "Epoch 10/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2142 - accuracy: 0.9329 - auc: 0.8480 - recall: 0.3779 - precision: 0.7670 - val_loss: 0.2153 - val_accuracy: 0.9322 - val_auc: 0.8521 - val_recall: 0.3286 - val_precision: 0.8262\n",
      "Epoch 11/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2114 - accuracy: 0.9337 - auc: 0.8545 - recall: 0.3758 - precision: 0.7842 - val_loss: 0.2191 - val_accuracy: 0.9299 - val_auc: 0.8497 - val_recall: 0.3741 - val_precision: 0.7274\n",
      "Epoch 12/128\n",
      "1443/1443 [==============================] - 31s 22ms/step - loss: 0.2080 - accuracy: 0.9342 - auc: 0.8606 - recall: 0.3958 - precision: 0.7705 - val_loss: 0.2116 - val_accuracy: 0.9336 - val_auc: 0.8549 - val_recall: 0.3523 - val_precision: 0.8194\n",
      "Epoch 13/128\n",
      "1443/1443 [==============================] - 30s 21ms/step - loss: 0.2073 - accuracy: 0.9343 - auc: 0.8650 - recall: 0.4019 - precision: 0.7655 - val_loss: 0.2135 - val_accuracy: 0.9313 - val_auc: 0.8629 - val_recall: 0.4242 - val_precision: 0.7077\n",
      "Epoch 14/128\n",
      "1443/1443 [==============================] - 31s 21ms/step - loss: 0.2046 - accuracy: 0.9349 - auc: 0.8706 - recall: 0.3910 - precision: 0.7878 - val_loss: 0.2107 - val_accuracy: 0.9326 - val_auc: 0.8652 - val_recall: 0.3731 - val_precision: 0.7725\n",
      "Epoch 15/128\n",
      "1443/1443 [==============================] - 34s 23ms/step - loss: 0.2053 - accuracy: 0.9348 - auc: 0.8695 - recall: 0.3953 - precision: 0.7804 - val_loss: 0.2080 - val_accuracy: 0.9337 - val_auc: 0.8654 - val_recall: 0.3816 - val_precision: 0.7825\n",
      "Epoch 16/128\n",
      "1440/1443 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9348 - auc: 0.8742 - recall: 0.4045 - precision: 0.7711"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21024/3072215185.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     20\u001b[0m     datagen.flow(x_train_r, y_train, batch_size=32,\n\u001b[0;32m     21\u001b[0m     subset='training'),\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## With Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.2)\n",
    "\n",
    "\n",
    "x_train_r = layers.Reshape(target_shape=(20, 20, 1), input_shape=(400,))(x_train)\n",
    "x_train_r.shape\n",
    "\n",
    "datagen.fit(x_train_r)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train_r, y_train, batch_size=32,\n",
    "    subset='training'),\n",
    "    validation_data=datagen.flow(x_train_r, y_train,\n",
    "    batch_size=8, subset='validation'), \n",
    "    epochs= 128, \n",
    "    batch_size = 64, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.drop('label', axis=1)\n",
    "y = ds.label.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 99.95%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.999676     0.998091  0.999532      0.998884      0.999532\n",
      "recall         0.999809     0.996759  0.999532      0.998284      0.999532\n",
      "f1-score       0.999743     0.997425  0.999532      0.998584      0.999532\n",
      "support    52465.000000  5246.000000  0.999532  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52455    10]\n",
      " [   17  5229]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.9999868619636735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(xgb, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 97.14%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.974667     0.930210  0.971444      0.952439      0.970625\n",
      "recall         0.994434     0.741616  0.971444      0.868025      0.971444\n",
      "f1-score       0.984452     0.825276  0.971444      0.904864      0.969977\n",
      "support    13116.000000  1312.000000  0.971444  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13043    73]\n",
      " [  339   973]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.9858884942706356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(xgb, x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv(\"test.csv\")\n",
    "Id = test_ds['Id'][:]\n",
    "test_ds = test_ds.drop(\"Id\", axis=1)\n",
    "test_ds = test_ds/255\n",
    "\n",
    "y_pred_proba = xgb.predict_proba(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id     Predicted\n",
      "0          0  2.899778e-06\n",
      "1          1  2.501287e-11\n",
      "2          2  5.768883e-17\n",
      "3          3  3.866564e-25\n",
      "4          4  7.860897e-16\n",
      "...      ...           ...\n",
      "30912  30912  5.064118e-09\n",
      "30913  30913  3.525026e-05\n",
      "30914  30914  3.110209e-02\n",
      "30915  30915  1.194052e-16\n",
      "30916  30916  1.857667e-12\n",
      "\n",
      "[30917 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({'Id':Id.values, 'Predicted':pred.flatten()}, columns=['Id', 'Predicted'])\n",
    "print(pred_df)\n",
    "pred_df.to_csv('predictions_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=400, Accuracy: 97.519%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.000, n=399, Accuracy: 97.449%, F1-score: 0.843, ROC_AUC: 0.989\n",
      "Thresh=0.000, n=398, Accuracy: 97.449%, F1-score: 0.843, ROC_AUC: 0.988\n",
      "Thresh=0.000, n=397, Accuracy: 97.415%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=396, Accuracy: 97.540%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=395, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=394, Accuracy: 97.463%, F1-score: 0.844, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=393, Accuracy: 97.533%, F1-score: 0.848, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=392, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=391, Accuracy: 97.526%, F1-score: 0.847, ROC_AUC: 0.990\n",
      "Thresh=0.001, n=390, Accuracy: 97.456%, F1-score: 0.844, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=389, Accuracy: 97.422%, F1-score: 0.841, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=388, Accuracy: 97.436%, F1-score: 0.841, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=387, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=386, Accuracy: 97.540%, F1-score: 0.850, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=385, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=384, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=383, Accuracy: 97.318%, F1-score: 0.834, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=382, Accuracy: 97.491%, F1-score: 0.845, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=381, Accuracy: 97.352%, F1-score: 0.836, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=380, Accuracy: 97.366%, F1-score: 0.837, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=379, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=378, Accuracy: 97.345%, F1-score: 0.836, ROC_AUC: 0.986\n",
      "Thresh=0.001, n=377, Accuracy: 97.408%, F1-score: 0.840, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=376, Accuracy: 97.387%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=375, Accuracy: 97.332%, F1-score: 0.834, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=374, Accuracy: 97.401%, F1-score: 0.839, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=373, Accuracy: 97.422%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=372, Accuracy: 97.477%, F1-score: 0.845, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=371, Accuracy: 97.304%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=370, Accuracy: 97.512%, F1-score: 0.847, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=369, Accuracy: 97.463%, F1-score: 0.844, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=368, Accuracy: 97.470%, F1-score: 0.844, ROC_AUC: 0.986\n",
      "Thresh=0.001, n=367, Accuracy: 97.345%, F1-score: 0.836, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=366, Accuracy: 97.394%, F1-score: 0.840, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=365, Accuracy: 97.394%, F1-score: 0.839, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=364, Accuracy: 97.373%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=363, Accuracy: 97.366%, F1-score: 0.837, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=362, Accuracy: 97.429%, F1-score: 0.842, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=361, Accuracy: 97.422%, F1-score: 0.840, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=360, Accuracy: 97.311%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=359, Accuracy: 97.429%, F1-score: 0.841, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=358, Accuracy: 97.449%, F1-score: 0.842, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=357, Accuracy: 97.290%, F1-score: 0.833, ROC_AUC: 0.987\n",
      "Thresh=0.001, n=356, Accuracy: 97.325%, F1-score: 0.833, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=355, Accuracy: 97.415%, F1-score: 0.841, ROC_AUC: 0.989\n",
      "Thresh=0.001, n=354, Accuracy: 97.366%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=353, Accuracy: 97.380%, F1-score: 0.838, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=352, Accuracy: 97.442%, F1-score: 0.842, ROC_AUC: 0.988\n",
      "Thresh=0.001, n=351, Accuracy: 97.526%, F1-score: 0.848, ROC_AUC: 0.986\n"
     ]
    }
   ],
   "source": [
    "thresholds = sort(xgb.feature_importances_)\n",
    "store = {}\n",
    "\n",
    "for thresh in thresholds[:50]:\n",
    "    selection = SelectFromModel(xgb, threshold=thresh, prefit=True)\n",
    "    select_x_train = selection.transform(x_train)\n",
    "    selection_model = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    selection_model.fit(select_x_train, y_train)\n",
    "    select_x_test = selection.transform(x_test)\n",
    "    predictions = selection_model.predict(select_x_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test,predictions)\n",
    "    n = select_x_train.shape[1]\n",
    "    roc_auc = roc_auc_score(y_test, selection_model.predict_proba(select_x_test)[:, 1])\n",
    "    store[n] = {\"Threshold\": thresh, \"Accuracy\": accuracy, \"F1-Score\": f1, \"ROC_AUC\": roc_auc, \"Model\": selection_model, \"Selection\": selection}\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.3f%%, F1-score: %.3f, ROC_AUC: %.3f\" % (thresh, n , accuracy*100.0, f1, roc_auc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_re = pd.DataFrame(store).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Model</th>\n",
       "      <th>Selection</th>\n",
       "      <th>Accuracy\\t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.975187</td>\n",
       "      <td>0.847530</td>\n",
       "      <td>0.988013</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.975187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.974494</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.988947</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.974494</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.988064</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.974147</td>\n",
       "      <td>0.840394</td>\n",
       "      <td>0.987188</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.974147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.975395</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>SelectFromModel(estimator=XGBClassifier(base_s...</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  Accuracy  F1-Score   ROC_AUC  \\\n",
       "400   0.000397  0.975187  0.847530  0.988013   \n",
       "399   0.000409  0.974494  0.842601  0.988947   \n",
       "398   0.000420  0.974494  0.843137  0.988064   \n",
       "397   0.000437  0.974147  0.840394  0.987188   \n",
       "396   0.000511  0.975395  0.848485  0.988470   \n",
       "\n",
       "                                                 Model  \\\n",
       "400  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "399  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "398  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "397  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "396  XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
       "\n",
       "                                             Selection  Accuracy\\t  \n",
       "400  SelectFromModel(estimator=XGBClassifier(base_s...    0.975187  \n",
       "399  SelectFromModel(estimator=XGBClassifier(base_s...    0.974494  \n",
       "398  SelectFromModel(estimator=XGBClassifier(base_s...    0.974494  \n",
       "397  SelectFromModel(estimator=XGBClassifier(base_s...    0.974147  \n",
       "396  SelectFromModel(estimator=XGBClassifier(base_s...    0.975395  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_re['ROC_AUC'] =pd.to_numeric(thresh_re['ROC_AUC'])\n",
    "thresh_re['Threshold'] =pd.to_numeric(thresh_re['Threshold'])\n",
    "thresh_re['Accuracy'] =pd.to_numeric(thresh_re['Accuracy'])\n",
    "thresh_re['F1-Score'] =pd.to_numeric(thresh_re['F1-Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Threshold                                              0.000511\n",
       "Accuracy                                               0.975395\n",
       "F1-Score                                               0.848485\n",
       "ROC_AUC                                                 0.98847\n",
       "Model         XGBClassifier(base_score=0.5, booster='gbtree'...\n",
       "Selection     SelectFromModel(estimator=XGBClassifier(base_s...\n",
       "Accuracy\\t                                             0.975395\n",
       "Name: 396, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thresh = thresh_re.loc[thresh_re['Accuracy'].idxmax()]\n",
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_select = store[391][\"Selection\"]\n",
    "best_model = store[391][\"Model\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegModel = LogisticRegression(max_iter=10000)\n",
    "logRegModel = LogisticRegression(max_iter=10000)\n",
    "logRegModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926878     0.749506  0.922216      0.838192      0.910755\n",
      "recall         0.992757     0.216737  0.922216      0.604747      0.922216\n",
      "f1-score       0.958687     0.336241  0.922216      0.647464      0.902106\n",
      "support    52465.000000  5246.000000  0.922216  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52085   380]\n",
      " [ 4109  1137]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8274844486306594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(logRegModel, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926524     0.756098  0.922165      0.841311      0.911026\n",
      "recall         0.993138     0.212652  0.922165      0.602895      0.922165\n",
      "f1-score       0.958675     0.331945  0.922165      0.645310      0.901684\n",
      "support    13116.000000  1312.000000  0.922165  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13026    90]\n",
      " [ 1033   279]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8031492500781023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(logRegModel, x_test ,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(loss='hinge', max_iter=1000000)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVM = LinearSVC(loss='hinge', dual=True,max_iter=1000000)\n",
    "linearSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0       1  accuracy     macro avg  weighted avg\n",
      "precision      0.909099     0.0  0.909099      0.454549      0.826461\n",
      "recall         1.000000     0.0  0.909099      0.500000      0.909099\n",
      "f1-score       0.952385     0.0  0.909099      0.476193      0.865812\n",
      "support    52465.000000  5246.0  0.909099  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52465     0]\n",
      " [ 5246     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(linearSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 90.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0       1  accuracy     macro avg  weighted avg\n",
      "precision      0.909066     0.0  0.909066      0.454533      0.826400\n",
      "recall         1.000000     0.0  0.909066      0.500000      0.909066\n",
      "f1-score       0.952367     0.0  0.909066      0.476184      0.865764\n",
      "support    13116.000000  1312.0  0.909066  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13116     0]\n",
      " [ 1312     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(linearSVM, x_test, y_test, auc=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel SVM¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomialSVM = SVC(kernel=\"poly\")\n",
    "polynomialSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 98.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0           1  accuracy     macro avg  weighted avg\n",
      "precision      0.989074     0.98961  0.989118      0.989342      0.989123\n",
      "recall         0.999066     0.88963  0.989118      0.944348      0.989118\n",
      "f1-score       0.994045     0.93696  0.989118      0.965503      0.988856\n",
      "support    52465.000000  5246.00000  0.989118  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52416    49]\n",
      " [  579  4667]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(polynomialSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 97.32%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.976066     0.937618  0.973246      0.956842      0.972570\n",
      "recall         0.994968     0.756098  0.973246      0.875533      0.973246\n",
      "f1-score       0.985426     0.837131  0.973246      0.911279      0.971941\n",
      "support    13116.000000  1312.000000  0.973246  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13050    66]\n",
      " [  320   992]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(polynomialSVM, x_test, y_test, auc=False)                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Kernel SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rbfSVM = SVC(kernel=\"rbf\")\n",
    "rbfSVM.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 98.06%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.980985     0.976460  0.980645      0.978722      0.980573\n",
      "recall         0.998056     0.806519  0.980645      0.902288      0.980645\n",
      "f1-score       0.989447     0.883391  0.980645      0.936419      0.979806\n",
      "support    52465.000000  5246.000000  0.980645  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52363   102]\n",
      " [ 1015  4231]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(rbfSVM, x_train, y_train, auc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 96.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.971918     0.932203  0.969157      0.952061      0.968307\n",
      "recall         0.994815     0.712652  0.969157      0.853734      0.969157\n",
      "f1-score       0.983233     0.807775  0.969157      0.895504      0.967278\n",
      "support    13116.000000  1312.000000  0.969157  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13048    68]\n",
      " [  377   935]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(rbfSVM, x_test, y_test, auc=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100,random_state=0)\n",
    "ada.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.24%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.926147     0.771631  0.922372      0.848889      0.912101\n",
      "recall         0.993863     0.207396  0.922372      0.600629      0.922372\n",
      "f1-score       0.958811     0.326923  0.922372      0.642867      0.901371\n",
      "support    52465.000000  5246.000000  0.922372  57711.000000  57711.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[52143   322]\n",
      " [ 4158  1088]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8768183054992383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_train_score(ada, x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULT:\n",
      "================================================\n",
      "ACCURACY SCORE: 92.09%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0            1  accuracy     macro avg  weighted avg\n",
      "precision      0.925702     0.735537  0.920918      0.830620      0.908410\n",
      "recall         0.992681     0.203506  0.920918      0.598093      0.920918\n",
      "f1-score       0.958022     0.318806  0.920918      0.638414      0.899895\n",
      "support    13116.000000  1312.000000  0.920918  14428.000000  14428.000000\n",
      "_______________________________________________\n",
      "CONFUSION MATRIX: \n",
      " [[13020    96]\n",
      " [ 1045   267]]\n",
      "\n",
      "_______________________________________________\n",
      "AUC Score: \n",
      " 0.8529957708514643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_test_score(ada, x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = tf.keras.Sequential([\n",
    "    #layers.InputLayer(input_shape=(None,), dtype=\"float\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "812/812 [==============================] - 7s 8ms/step - loss: 0.1121 - accuracy: 0.9625 - auc: 0.9639 - val_loss: 0.1125 - val_accuracy: 0.9550 - val_auc: 0.9710\n",
      "Epoch 2/128\n",
      "812/812 [==============================] - 9s 12ms/step - loss: 0.1083 - accuracy: 0.9643 - auc: 0.9656 - val_loss: 0.1085 - val_accuracy: 0.9589 - val_auc: 0.9686\n",
      "Epoch 3/128\n",
      "812/812 [==============================] - 10s 12ms/step - loss: 0.1112 - accuracy: 0.9642 - auc: 0.9635 - val_loss: 0.1123 - val_accuracy: 0.9582 - val_auc: 0.9728\n",
      "Epoch 4/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1070 - accuracy: 0.9641 - auc: 0.9682 - val_loss: 0.1250 - val_accuracy: 0.9581 - val_auc: 0.9691\n",
      "Epoch 5/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1052 - accuracy: 0.9649 - auc: 0.9685 - val_loss: 0.1040 - val_accuracy: 0.9641 - val_auc: 0.9698\n",
      "Epoch 6/128\n",
      "812/812 [==============================] - 11s 14ms/step - loss: 0.1055 - accuracy: 0.9648 - auc: 0.9680 - val_loss: 0.1064 - val_accuracy: 0.9591 - val_auc: 0.9750\n",
      "Epoch 7/128\n",
      "812/812 [==============================] - 13s 16ms/step - loss: 0.1003 - accuracy: 0.9658 - auc: 0.9707 - val_loss: 0.1035 - val_accuracy: 0.9666 - val_auc: 0.9725\n",
      "Epoch 8/128\n",
      "812/812 [==============================] - 12s 15ms/step - loss: 0.1056 - accuracy: 0.9645 - auc: 0.9696 - val_loss: 0.0985 - val_accuracy: 0.9648 - val_auc: 0.9747\n",
      "Epoch 9/128\n",
      "812/812 [==============================] - 9s 11ms/step - loss: 0.1021 - accuracy: 0.9670 - auc: 0.9698 - val_loss: 0.0965 - val_accuracy: 0.9650 - val_auc: 0.9747\n",
      "Epoch 10/128\n",
      "812/812 [==============================] - 12s 14ms/step - loss: 0.0994 - accuracy: 0.9666 - auc: 0.9724 - val_loss: 0.0979 - val_accuracy: 0.9634 - val_auc: 0.9759\n",
      "Epoch 11/128\n",
      "812/812 [==============================] - 15s 18ms/step - loss: 0.0955 - accuracy: 0.9677 - auc: 0.9741 - val_loss: 0.0962 - val_accuracy: 0.9652 - val_auc: 0.9786\n",
      "Epoch 12/128\n",
      "812/812 [==============================] - 12s 15ms/step - loss: 0.0989 - accuracy: 0.9675 - auc: 0.9704 - val_loss: 0.0990 - val_accuracy: 0.9652 - val_auc: 0.9772\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 128\n",
    "\n",
    "history = nn_model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9582 - auc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "score = nn_model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv(\"test.csv\")\n",
    "Id = test_ds['Id'][:]\n",
    "test_ds = test_ds.drop(\"Id\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB with 391 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform = best_select.transform(test_ds)\n",
    "predictions = best_model.predict(test_transform)\n",
    "predict_to_csv(best_model, test_transform,\"predictions_xgb_391\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB with all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_to_csv(xgb,test_ds,\"predictions_xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_to_csv(nn_model,test_ds,\"prediction_nn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"predictions_xgb_391.csv\")\n",
    "b = pd.read_csv(\"prediction_nn1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a.Predicted - b.Predicted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c61f45fa4287766d1fe49b974af5d77a1d3358a56f5db6d660bceae78d85026e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gpuEnv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
